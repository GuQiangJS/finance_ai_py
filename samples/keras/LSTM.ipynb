{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[Keras] 利用Keras建構LSTM模型，以Stock Prediction 為例 1](https://medium.com/@daniel820710/%E5%88%A9%E7%94%A8keras%E5%BB%BA%E6%A7%8Blstm%E6%A8%A1%E5%9E%8B-%E4%BB%A5stock-prediction-%E7%82%BA%E4%BE%8B-1-67456e0a0b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score # K折交叉验证模块\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import QUANTAXIS as QA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyecharts\n",
    "import talib\n",
    "\n",
    "#设定绘图的默认大小\n",
    "import matplotlib\n",
    "matplotlib.rcParams[\"figure.figsize\"]=[16,5]\n",
    "\n",
    "matplotlib.rcParams['font.family'] = 'sans-serif'\n",
    "matplotlib.rcParams['font.sans-serif'] = ['Noto Sans CJK SC','SimHei']\n",
    "matplotlib.rcParams['axes.unicode_minus']=False #用来正常显示负号\n",
    "\n",
    "#加载 seaborn，并且设置默认使用 seaborn\n",
    "import seaborn as sns\n",
    "sns.set(font=['Noto Sans CJK SC','SimHei'])\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import ExtraTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, LSTM, TimeDistributed, RepeatVector\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>amount</th>\n",
       "      <th>preclose</th>\n",
       "      <th>adj</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-10-27</th>\n",
       "      <td>601398</td>\n",
       "      <td>1.992133</td>\n",
       "      <td>2.01557</td>\n",
       "      <td>1.910104</td>\n",
       "      <td>1.921823</td>\n",
       "      <td>4.407654e+07</td>\n",
       "      <td>8.725310e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.585922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              code      open     high       low     close        volume  \\\n",
       "date                                                                      \n",
       "2006-10-27  601398  1.992133  2.01557  1.910104  1.921823  4.407654e+07   \n",
       "\n",
       "                  amount  preclose       adj  \n",
       "date                                          \n",
       "2006-10-27  8.725310e+09       NaN  0.585922  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_code='601398'\n",
    "benchmark_code='399300'\n",
    "start_time='2005-01-01'\n",
    "end_time='2018-12-31'\n",
    "\n",
    "data_raw=QA.QA_fetch_stock_day_adv(stock_code, start_time, end_time).to_qfq().data.reset_index().set_index('date')\n",
    "data_raw.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-10-27</th>\n",
       "      <td>1.992133</td>\n",
       "      <td>2.01557</td>\n",
       "      <td>1.910104</td>\n",
       "      <td>1.921823</td>\n",
       "      <td>4.407654e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                open     high       low     close        volume\n",
       "date                                                           \n",
       "2006-10-27  1.992133  2.01557  1.910104  1.921823  4.407654e+07"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data_raw.drop(columns=['code','amount','preclose','adj'])\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augment Features\n",
    "除了基本資料提供的Features(Open, High, Low, Close, Adj Close, Volume)以外，還可自己增加Features，例如星期幾、幾月、幾號等等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augFeatures(train):\n",
    "    df=train.copy()\n",
    "    df[\"year\"] = df.index.year\n",
    "    df[\"month\"] = df.index.month\n",
    "    df[\"date\"] = df.index.day\n",
    "    df[\"day\"] = df.index.dayofweek\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>date</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-10-27</th>\n",
       "      <td>1.992133</td>\n",
       "      <td>2.01557</td>\n",
       "      <td>1.910104</td>\n",
       "      <td>1.921823</td>\n",
       "      <td>4.407654e+07</td>\n",
       "      <td>2006</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                open     high       low     close        volume  year  month  \\\n",
       "date                                                                           \n",
       "2006-10-27  1.992133  2.01557  1.910104  1.921823  4.407654e+07  2006     10   \n",
       "\n",
       "            date  day  \n",
       "date                   \n",
       "2006-10-27    27    4  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=augFeatures(data)\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "將所有資料做正規化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(train):\n",
    "    return train.apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>date</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-10-27</th>\n",
       "      <td>-0.29094</td>\n",
       "      <td>-0.286786</td>\n",
       "      <td>-0.305092</td>\n",
       "      <td>-0.297378</td>\n",
       "      <td>0.947025</td>\n",
       "      <td>-0.53514</td>\n",
       "      <td>0.303308</td>\n",
       "      <td>0.362023</td>\n",
       "      <td>0.497282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               open      high       low     close    volume     year  \\\n",
       "date                                                                   \n",
       "2006-10-27 -0.29094 -0.286786 -0.305092 -0.297378  0.947025 -0.53514   \n",
       "\n",
       "               month      date       day  \n",
       "date                                      \n",
       "2006-10-27  0.303308  0.362023  0.497282  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=normalize(data)\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Training Data\n",
    "輸入X_train: 利用前30天的Open, High, Low, Close, Volume, month, year, date, day作為Features，shape為(30, 9)\n",
    "\n",
    "輸出Y_train: 利用未來5天的Close作為Features，shape為(5,1)\n",
    "\n",
    "我們須將資料做位移的展開作為Training Data，如圖(1)所示。\n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/800/1*QUwzqa1Gi0bGbsIDQqpOhw.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildTrain(train, pastDay=30, futureDay=5):\n",
    "    X_train, Y_train = [], []\n",
    "    for i in range(train.shape[0]-futureDay-pastDay):\n",
    "        X_train.append(np.array(train.iloc[i:i+pastDay]))\n",
    "        Y_train.append(np.array(train.iloc[i+pastDay:i+pastDay+futureDay][\"close\"]))\n",
    "    return np.array(X_train), np.array(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 資料亂序\n",
    "將資料打散，而非照日期排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(X,Y):\n",
    "    np.random.seed(10)\n",
    "    randomList = np.arange(X.shape[0])\n",
    "    np.random.shuffle(randomList)\n",
    "    return X[randomList], Y[randomList]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data & Validation data\n",
    "將Training Data取一部份當作Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(X,Y,rate):\n",
    "    X_train = X[int(X.shape[0]*rate):]\n",
    "    Y_train = Y[int(Y.shape[0]*rate):]\n",
    "    X_val = X[:int(X.shape[0]*rate)]\n",
    "    Y_val = Y[:int(Y.shape[0]*rate)]\n",
    "    return X_train, Y_train, X_val, Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2618, 30, 9), (2618, 5), (290, 30, 9), (290, 5))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = data_raw.drop(columns=['code','amount','preclose','adj'])\n",
    "\n",
    "# Augment the features (year, month, date, day)\n",
    "train_Aug = augFeatures(train)\n",
    "\n",
    "# Normalization\n",
    "train_norm = normalize(train_Aug)\n",
    "\n",
    "# build Data, use last 30 days to predict next 5 days\n",
    "X_train, Y_train = buildTrain(train_norm, 30, 5)\n",
    "\n",
    "# shuffle the data, and random seed is 10\n",
    "X_train, Y_train = shuffle(X_train, Y_train)\n",
    "\n",
    "# split training data and validation data\n",
    "X_train, Y_train, X_val, Y_val = splitData(X_train, Y_train, 0.1)\n",
    "X_train.shape,Y_train.shape,X_val.shape,Y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型建置\n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/800/1*bOOrk_un_DQ7k3THPeZpkA.jpeg)\n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/800/1*lCOYLu3M8tIUkNF-4ngXoA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一對一模型\n",
    "由於是一對一模型，因此return_sequences 也可設為False ，但Y_train 以及Y_val的維度需改為二維(2618,1)以及(290,1) 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildOneToOneModel(shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(10, input_length=shape[1], input_dim=shape[2],return_sequences=True))\n",
    "    # output shape: (1, 1)\n",
    "    model.add(TimeDistributed(Dense(1)))    # or use model.add(Dense(1))\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將過去的天數pastDay設為1，預測的天數futureDay也設為1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GuQiang\\AppData\\Local\\conda\\conda\\envs\\finance35\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\GuQiang\\AppData\\Local\\conda\\conda\\envs\\finance35\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(10, return_sequences=True, input_shape=(1, 9))`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 1, 10)             800       \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 1, 1)              11        \n",
      "=================================================================\n",
      "Total params: 811\n",
      "Trainable params: 811\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2647 samples, validate on 294 samples\n",
      "Epoch 1/1000\n",
      "2647/2647 [==============================] - ETA: 18s - loss: 0.04 - 1s 401us/step - loss: 0.0414 - val_loss: 0.0393\n",
      "Epoch 2/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 0.034 - 0s 17us/step - loss: 0.0339 - val_loss: 0.0321\n",
      "Epoch 3/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 0.029 - 0s 15us/step - loss: 0.0275 - val_loss: 0.0257\n",
      "Epoch 4/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 0.023 - 0s 15us/step - loss: 0.0217 - val_loss: 0.0198\n",
      "Epoch 5/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 0.018 - 0s 15us/step - loss: 0.0162 - val_loss: 0.0144\n",
      "Epoch 6/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 0.013 - 0s 15us/step - loss: 0.0113 - val_loss: 0.0098\n",
      "Epoch 7/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 0.008 - 0s 16us/step - loss: 0.0072 - val_loss: 0.0062\n",
      "Epoch 8/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 0.005 - 0s 15us/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 9/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 0.003 - 0s 15us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 10/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 0.002 - 0s 14us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 11/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 0.001 - 0s 14us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 12/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 0.001 - 0s 18us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 13/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 0.001 - 0s 17us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 14/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 0.001 - 0s 13us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 15/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 7.8924e-0 - 0s 13us/step - loss: 8.9254e-04 - val_loss: 0.0010\n",
      "Epoch 16/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 0.001 - 0s 14us/step - loss: 7.9622e-04 - val_loss: 8.8803e-04\n",
      "Epoch 17/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 5.1146e-0 - 0s 17us/step - loss: 7.0924e-04 - val_loss: 7.8266e-04\n",
      "Epoch 18/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 6.9692e-0 - 0s 15us/step - loss: 6.2909e-04 - val_loss: 6.9767e-04\n",
      "Epoch 19/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 7.3010e-0 - 0s 14us/step - loss: 5.6349e-04 - val_loss: 6.1885e-04\n",
      "Epoch 20/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 5.3785e-0 - 0s 13us/step - loss: 5.0344e-04 - val_loss: 5.5353e-04\n",
      "Epoch 21/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 3.0657e-0 - 0s 15us/step - loss: 4.5218e-04 - val_loss: 4.8858e-04\n",
      "Epoch 22/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 3.4352e-0 - 0s 15us/step - loss: 4.0785e-04 - val_loss: 4.3577e-04\n",
      "Epoch 23/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 4.0626e-0 - 0s 14us/step - loss: 3.6976e-04 - val_loss: 3.9352e-04\n",
      "Epoch 24/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 5.3009e-0 - 0s 14us/step - loss: 3.3734e-04 - val_loss: 3.5553e-04\n",
      "Epoch 25/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 2.3255e-0 - 0s 15us/step - loss: 3.0758e-04 - val_loss: 3.2032e-04\n",
      "Epoch 26/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.9102e-0 - 0s 14us/step - loss: 2.8437e-04 - val_loss: 2.9416e-04\n",
      "Epoch 27/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 3.5772e-0 - 0s 14us/step - loss: 2.6435e-04 - val_loss: 2.7254e-04\n",
      "Epoch 28/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 2.3652e-0 - 0s 16us/step - loss: 2.4680e-04 - val_loss: 2.5014e-04\n",
      "Epoch 29/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 3.5687e-0 - 0s 18us/step - loss: 2.3306e-04 - val_loss: 2.3609e-04\n",
      "Epoch 30/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 2.5445e-0 - 0s 14us/step - loss: 2.2077e-04 - val_loss: 2.1953e-04\n",
      "Epoch 31/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 2.8622e-0 - 0s 14us/step - loss: 2.1149e-04 - val_loss: 2.0932e-04\n",
      "Epoch 32/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.8549e-0 - 0s 16us/step - loss: 2.0345e-04 - val_loss: 1.9924e-04\n",
      "Epoch 33/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 2.2832e-0 - ETA: 0s - loss: 1.9207e-0 - 0s 31us/step - loss: 1.9678e-04 - val_loss: 1.9244e-04\n",
      "Epoch 34/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 2.1471e-0 - 0s 14us/step - loss: 1.9187e-04 - val_loss: 1.8390e-04\n",
      "Epoch 35/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.7864e-0 - 0s 14us/step - loss: 1.8737e-04 - val_loss: 1.8013e-04\n",
      "Epoch 36/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.4764e-0 - 0s 14us/step - loss: 1.8359e-04 - val_loss: 1.7635e-04\n",
      "Epoch 37/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.2016e-0 - 0s 15us/step - loss: 1.8185e-04 - val_loss: 1.7165e-04\n",
      "Epoch 38/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.8320e-0 - 0s 14us/step - loss: 1.7944e-04 - val_loss: 1.7042e-04\n",
      "Epoch 39/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.1748e-0 - 0s 13us/step - loss: 1.7720e-04 - val_loss: 1.6627e-04\n",
      "Epoch 40/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.1586e-0 - 0s 15us/step - loss: 1.7533e-04 - val_loss: 1.6440e-04\n",
      "Epoch 41/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.9131e-0 - 0s 15us/step - loss: 1.7424e-04 - val_loss: 1.6301e-04\n",
      "Epoch 42/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.9742e-0 - 0s 15us/step - loss: 1.7336e-04 - val_loss: 1.6110e-04\n",
      "Epoch 43/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.7355e-0 - 0s 14us/step - loss: 1.7342e-04 - val_loss: 1.6027e-04\n",
      "Epoch 44/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 2.0585e-0 - 0s 14us/step - loss: 1.7237e-04 - val_loss: 1.5966e-04\n",
      "Epoch 45/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.7775e-0 - 0s 14us/step - loss: 1.7137e-04 - val_loss: 1.5892e-04\n",
      "Epoch 46/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.5910e-0 - 0s 15us/step - loss: 1.7160e-04 - val_loss: 1.5882e-04\n",
      "Epoch 47/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.9263e-0 - 0s 17us/step - loss: 1.7105e-04 - val_loss: 1.5776e-04\n",
      "Epoch 48/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 2.1107e-0 - 0s 17us/step - loss: 1.7054e-04 - val_loss: 1.5723e-04\n",
      "Epoch 49/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.6281e-0 - 0s 19us/step - loss: 1.7018e-04 - val_loss: 1.5614e-04\n",
      "Epoch 50/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.9865e-0 - 0s 13us/step - loss: 1.6999e-04 - val_loss: 1.5712e-04\n",
      "Epoch 51/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.2279e-0 - 0s 15us/step - loss: 1.7067e-04 - val_loss: 1.5570e-04\n",
      "Epoch 52/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 2.4464e-0 - 0s 14us/step - loss: 1.6949e-04 - val_loss: 1.5595e-04\n",
      "Epoch 53/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.7861e-0 - 0s 14us/step - loss: 1.6962e-04 - val_loss: 1.5524e-04\n",
      "Epoch 54/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.3879e-0 - 0s 14us/step - loss: 1.6930e-04 - val_loss: 1.5515e-04\n",
      "Epoch 55/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2647/2647 [==============================] - ETA: 0s - loss: 1.9849e-0 - 0s 14us/step - loss: 1.6961e-04 - val_loss: 1.5457e-04\n",
      "Epoch 56/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.9825e-0 - 0s 15us/step - loss: 1.6977e-04 - val_loss: 1.5605e-04\n",
      "Epoch 57/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.9595e-0 - 0s 14us/step - loss: 1.6902e-04 - val_loss: 1.5382e-04\n",
      "Epoch 58/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.2437e-0 - 0s 15us/step - loss: 1.6871e-04 - val_loss: 1.5493e-04\n",
      "Epoch 59/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.6481e-0 - 0s 14us/step - loss: 1.6870e-04 - val_loss: 1.5467e-04\n",
      "Epoch 60/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.4874e-0 - 0s 15us/step - loss: 1.6940e-04 - val_loss: 1.5680e-04\n",
      "Epoch 61/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.6085e-0 - 0s 14us/step - loss: 1.6879e-04 - val_loss: 1.5402e-04\n",
      "Epoch 62/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.9171e-0 - 0s 23us/step - loss: 1.6859e-04 - val_loss: 1.5315e-04\n",
      "Epoch 63/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.5152e-0 - 0s 13us/step - loss: 1.6849e-04 - val_loss: 1.5399e-04\n",
      "Epoch 64/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 2.0539e-0 - 0s 14us/step - loss: 1.6804e-04 - val_loss: 1.5401e-04\n",
      "Epoch 65/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 2.2203e-0 - 0s 14us/step - loss: 1.6793e-04 - val_loss: 1.5293e-04\n",
      "Epoch 66/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 2.2604e-0 - 0s 14us/step - loss: 1.6830e-04 - val_loss: 1.5588e-04\n",
      "Epoch 67/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.4504e-0 - 0s 14us/step - loss: 1.6877e-04 - val_loss: 1.5330e-04\n",
      "Epoch 68/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.8665e-0 - 0s 14us/step - loss: 1.6898e-04 - val_loss: 1.5507e-04\n",
      "Epoch 69/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 2.0195e-0 - 0s 14us/step - loss: 1.6832e-04 - val_loss: 1.5307e-04\n",
      "Epoch 70/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.6360e-0 - 0s 15us/step - loss: 1.6787e-04 - val_loss: 1.5249e-04\n",
      "Epoch 71/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.7417e-0 - 0s 14us/step - loss: 1.6769e-04 - val_loss: 1.5306e-04\n",
      "Epoch 72/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.8220e-0 - 0s 17us/step - loss: 1.6723e-04 - val_loss: 1.5275e-04\n",
      "Epoch 73/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 3.3413e-0 - 0s 13us/step - loss: 1.6848e-04 - val_loss: 1.5195e-04\n",
      "Epoch 74/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.5334e-0 - 0s 14us/step - loss: 1.6671e-04 - val_loss: 1.5234e-04\n",
      "Epoch 75/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 9.9695e-0 - 0s 14us/step - loss: 1.6700e-04 - val_loss: 1.5101e-04\n",
      "Epoch 76/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 2.0185e-0 - 0s 14us/step - loss: 1.6681e-04 - val_loss: 1.5261e-04\n",
      "Epoch 77/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.6408e-0 - 0s 14us/step - loss: 1.6738e-04 - val_loss: 1.5170e-04\n",
      "Epoch 78/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.6972e-0 - 0s 13us/step - loss: 1.6689e-04 - val_loss: 1.5314e-04\n",
      "Epoch 79/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 2.7301e-0 - 0s 13us/step - loss: 1.6736e-04 - val_loss: 1.5239e-04\n",
      "Epoch 80/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.8054e-0 - 0s 15us/step - loss: 1.6699e-04 - val_loss: 1.5206e-04\n",
      "Epoch 81/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.5621e-0 - 0s 14us/step - loss: 1.6647e-04 - val_loss: 1.5173e-04\n",
      "Epoch 82/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.8927e-0 - 0s 14us/step - loss: 1.6601e-04 - val_loss: 1.5187e-04\n",
      "Epoch 83/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.4477e-0 - 0s 14us/step - loss: 1.6655e-04 - val_loss: 1.5129e-04\n",
      "Epoch 84/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 2.8228e-0 - 0s 15us/step - loss: 1.6692e-04 - val_loss: 1.5266e-04\n",
      "Epoch 85/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.3813e-0 - 0s 14us/step - loss: 1.6730e-04 - val_loss: 1.5101e-04\n",
      "Epoch 86/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 2.3884e-0 - 0s 15us/step - loss: 1.6674e-04 - val_loss: 1.5195e-04\n",
      "Epoch 87/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 2.9340e-0 - 0s 14us/step - loss: 1.6579e-04 - val_loss: 1.5105e-04\n",
      "Epoch 88/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.5114e-0 - 0s 14us/step - loss: 1.6632e-04 - val_loss: 1.5099e-04\n",
      "Epoch 89/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.4608e-0 - 0s 13us/step - loss: 1.6540e-04 - val_loss: 1.4977e-04\n",
      "Epoch 90/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 2.1271e-0 - 0s 15us/step - loss: 1.6555e-04 - val_loss: 1.5176e-04\n",
      "Epoch 91/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.3770e-0 - 0s 14us/step - loss: 1.6574e-04 - val_loss: 1.5265e-04\n",
      "Epoch 92/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.0067e-0 - 0s 15us/step - loss: 1.6579e-04 - val_loss: 1.4949e-04\n",
      "Epoch 93/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.3818e-0 - 0s 14us/step - loss: 1.6663e-04 - val_loss: 1.5069e-04\n",
      "Epoch 94/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.2633e-0 - 0s 16us/step - loss: 1.6521e-04 - val_loss: 1.4968e-04\n",
      "Epoch 95/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.3528e-0 - 0s 13us/step - loss: 1.6580e-04 - val_loss: 1.5097e-04\n",
      "Epoch 96/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 2.2889e-0 - 0s 15us/step - loss: 1.6458e-04 - val_loss: 1.5012e-04\n",
      "Epoch 97/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.4087e-0 - 0s 14us/step - loss: 1.6479e-04 - val_loss: 1.5032e-04\n",
      "Epoch 98/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.1711e-0 - 0s 14us/step - loss: 1.6557e-04 - val_loss: 1.4911e-04\n",
      "Epoch 99/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.2066e-0 - 0s 15us/step - loss: 1.6596e-04 - val_loss: 1.5089e-04\n",
      "Epoch 100/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.2660e-0 - 0s 15us/step - loss: 1.6515e-04 - val_loss: 1.5102e-04\n",
      "Epoch 101/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.0803e-0 - 0s 14us/step - loss: 1.6563e-04 - val_loss: 1.5059e-04\n",
      "Epoch 102/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.2754e-0 - 0s 15us/step - loss: 1.6423e-04 - val_loss: 1.4913e-04\n",
      "Epoch 103/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 9.3343e-0 - 0s 13us/step - loss: 1.6445e-04 - val_loss: 1.4995e-04\n",
      "Epoch 104/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.5300e-0 - 0s 15us/step - loss: 1.6491e-04 - val_loss: 1.4958e-04\n",
      "Epoch 105/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.3908e-0 - 0s 15us/step - loss: 1.6492e-04 - val_loss: 1.5001e-04\n",
      "Epoch 106/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.4330e-0 - 0s 15us/step - loss: 1.6416e-04 - val_loss: 1.4932e-04\n",
      "Epoch 107/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.4732e-0 - 0s 16us/step - loss: 1.6500e-04 - val_loss: 1.5052e-04\n",
      "Epoch 108/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.9504e-0 - ETA: 0s - loss: 1.6655e-0 - 0s 25us/step - loss: 1.6607e-04 - val_loss: 1.5083e-04\n",
      "Epoch 109/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 2.0732e-0 - 0s 18us/step - loss: 1.6391e-04 - val_loss: 1.4848e-04\n",
      "Epoch 110/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.7508e-0 - 0s 25us/step - loss: 1.6380e-04 - val_loss: 1.4949e-04\n",
      "Epoch 111/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.6125e-0 - 0s 21us/step - loss: 1.6380e-04 - val_loss: 1.5219e-04\n",
      "Epoch 112/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2647/2647 [==============================] - ETA: 0s - loss: 1.0888e-0 - ETA: 0s - loss: 1.5669e-0 - 0s 33us/step - loss: 1.6433e-04 - val_loss: 1.5061e-04\n",
      "Epoch 113/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.4083e-0 - ETA: 0s - loss: 1.7548e-0 - 0s 34us/step - loss: 1.6302e-04 - val_loss: 1.4912e-04\n",
      "Epoch 114/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.6647e-0 - 0s 15us/step - loss: 1.6365e-04 - val_loss: 1.4898e-04\n",
      "Epoch 115/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.3769e-0 - 0s 15us/step - loss: 1.6375e-04 - val_loss: 1.5475e-04\n",
      "Epoch 116/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 2.4738e-0 - 0s 15us/step - loss: 1.6424e-04 - val_loss: 1.4895e-04\n",
      "Epoch 117/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.5787e-0 - 0s 14us/step - loss: 1.6310e-04 - val_loss: 1.4841e-04\n",
      "Epoch 118/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.6417e-0 - 0s 16us/step - loss: 1.6284e-04 - val_loss: 1.4848e-04\n",
      "Epoch 119/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.3056e-0 - 0s 17us/step - loss: 1.6330e-04 - val_loss: 1.4863e-04\n",
      "Epoch 120/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.2095e-0 - ETA: 0s - loss: 1.5914e-0 - 0s 32us/step - loss: 1.6334e-04 - val_loss: 1.4853e-04\n",
      "Epoch 121/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 2.0220e-0 - 0s 22us/step - loss: 1.6260e-04 - val_loss: 1.4804e-04\n",
      "Epoch 122/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.3503e-0 - 0s 21us/step - loss: 1.6250e-04 - val_loss: 1.4967e-04\n",
      "Epoch 123/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.0974e-0 - 0s 17us/step - loss: 1.6312e-04 - val_loss: 1.4667e-04\n",
      "Epoch 124/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 8.0820e-0 - 0s 16us/step - loss: 1.6215e-04 - val_loss: 1.4915e-04\n",
      "Epoch 125/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.1030e-0 - 0s 15us/step - loss: 1.6233e-04 - val_loss: 1.4692e-04\n",
      "Epoch 126/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.8256e-0 - 0s 15us/step - loss: 1.6207e-04 - val_loss: 1.4789e-04\n",
      "Epoch 127/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.6613e-0 - 0s 15us/step - loss: 1.6174e-04 - val_loss: 1.4894e-04\n",
      "Epoch 128/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.3870e-0 - 0s 14us/step - loss: 1.6309e-04 - val_loss: 1.4861e-04\n",
      "Epoch 129/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.3721e-0 - 0s 16us/step - loss: 1.6200e-04 - val_loss: 1.4718e-04\n",
      "Epoch 130/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.3018e-0 - 0s 16us/step - loss: 1.6266e-04 - val_loss: 1.4840e-04\n",
      "Epoch 131/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.5534e-0 - 0s 15us/step - loss: 1.6233e-04 - val_loss: 1.4853e-04\n",
      "Epoch 132/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 2.2685e-0 - 0s 19us/step - loss: 1.6347e-04 - val_loss: 1.4613e-04\n",
      "Epoch 133/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.1960e-0 - 0s 14us/step - loss: 1.6153e-04 - val_loss: 1.4765e-04\n",
      "Epoch 134/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.7467e-0 - 0s 16us/step - loss: 1.6338e-04 - val_loss: 1.4744e-04\n",
      "Epoch 135/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.2437e-0 - 0s 14us/step - loss: 1.6165e-04 - val_loss: 1.4741e-04\n",
      "Epoch 136/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.0951e-0 - 0s 14us/step - loss: 1.6151e-04 - val_loss: 1.4564e-04\n",
      "Epoch 137/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.4034e-0 - 0s 14us/step - loss: 1.6132e-04 - val_loss: 1.4786e-04\n",
      "Epoch 138/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.5451e-0 - 0s 15us/step - loss: 1.6372e-04 - val_loss: 1.5149e-04\n",
      "Epoch 139/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.7926e-0 - 0s 14us/step - loss: 1.6383e-04 - val_loss: 1.4642e-04\n",
      "Epoch 140/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.4887e-0 - 0s 17us/step - loss: 1.6169e-04 - val_loss: 1.4779e-04\n",
      "Epoch 141/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.1340e-0 - 0s 16us/step - loss: 1.6235e-04 - val_loss: 1.4526e-04\n",
      "Epoch 142/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 9.9351e-0 - 0s 14us/step - loss: 1.6175e-04 - val_loss: 1.4685e-04\n",
      "Epoch 143/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.5409e-0 - 0s 17us/step - loss: 1.6039e-04 - val_loss: 1.4656e-04\n",
      "Epoch 144/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 2.1922e-0 - 0s 14us/step - loss: 1.6032e-04 - val_loss: 1.4744e-04\n",
      "Epoch 145/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 9.0032e-0 - 0s 14us/step - loss: 1.6085e-04 - val_loss: 1.4603e-04\n",
      "Epoch 146/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.7503e-0 - 0s 14us/step - loss: 1.6154e-04 - val_loss: 1.4686e-04\n",
      "Epoch 147/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 2.0085e-0 - 0s 15us/step - loss: 1.6109e-04 - val_loss: 1.4578e-04\n",
      "Epoch 148/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.3949e-0 - 0s 14us/step - loss: 1.6168e-04 - val_loss: 1.4839e-04\n",
      "Epoch 149/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 2.7316e-0 - 0s 15us/step - loss: 1.6079e-04 - val_loss: 1.4835e-04\n",
      "Epoch 150/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 2.3488e-0 - 0s 15us/step - loss: 1.6055e-04 - val_loss: 1.4493e-04\n",
      "Epoch 151/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.0198e-0 - 0s 14us/step - loss: 1.6074e-04 - val_loss: 1.4634e-04\n",
      "Epoch 152/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.5735e-0 - 0s 15us/step - loss: 1.6070e-04 - val_loss: 1.4638e-04\n",
      "Epoch 153/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.5370e-0 - 0s 14us/step - loss: 1.6131e-04 - val_loss: 1.4812e-04\n",
      "Epoch 154/1000\n",
      "2647/2647 [==============================] - ETA: 0s - loss: 1.1465e-0 - 0s 16us/step - loss: 1.6070e-04 - val_loss: 1.4627e-04\n",
      "Epoch 00154: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a514b40e48>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = data_raw.drop(columns=['code','amount','preclose','adj'])\n",
    "train_Aug = augFeatures(train)\n",
    "train_norm = normalize(train_Aug)\n",
    "# change the last day and next day \n",
    "X_train, Y_train = buildTrain(train_norm, 1, 1)\n",
    "X_train, Y_train = shuffle(X_train, Y_train)\n",
    "X_train, Y_train, X_val, Y_val = splitData(X_train, Y_train, 0.1)\n",
    "\n",
    "# from 2 dimmension to 3 dimension\n",
    "Y_train = Y_train[:,np.newaxis]\n",
    "Y_val = Y_val[:,np.newaxis]\n",
    "\n",
    "model = buildOneToOneModel(X_train.shape)\n",
    "callback = EarlyStopping(monitor=\"loss\", patience=10, verbose=1, mode=\"auto\")\n",
    "model.fit(X_train, Y_train, epochs=1000, batch_size=128, validation_data=(X_val, Y_val), callbacks=[callback])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多對一模型\n",
    "LSTM參數return_sequences=False ，未設定時default也為False，而且不可使用TimeDistribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildManyToOneModel(shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(10, input_length=shape[1], input_dim=shape[2]))\n",
    "    # output shape: (1, 1)\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要設定的有pastDay=30、future=1 ，且注意Y_train 的維度需為二維"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GuQiang\\AppData\\Local\\conda\\conda\\envs\\finance35\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\GuQiang\\AppData\\Local\\conda\\conda\\envs\\finance35\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(10, input_shape=(30, 9))`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 10)                800       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 811\n",
      "Trainable params: 811\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2621 samples, validate on 291 samples\n",
      "Epoch 1/1000\n",
      "2621/2621 [==============================] - ETA: 14s - loss: 0.09 - ETA: 1s - loss: 0.0758 - ETA: 0s - loss: 0.069 - ETA: 0s - loss: 0.061 - 1s 387us/step - loss: 0.0562 - val_loss: 0.0323\n",
      "Epoch 2/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 0.029 - ETA: 0s - loss: 0.028 - ETA: 0s - loss: 0.026 - ETA: 0s - loss: 0.022 - 0s 82us/step - loss: 0.0217 - val_loss: 0.0143\n",
      "Epoch 3/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 0.011 - ETA: 0s - loss: 0.010 - ETA: 0s - loss: 0.010 - ETA: 0s - loss: 0.009 - 0s 81us/step - loss: 0.0091 - val_loss: 0.0078\n",
      "Epoch 4/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 0.005 - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.005 - ETA: 0s - loss: 0.005 - 0s 82us/step - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 5/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 0.005 - ETA: 0s - loss: 0.003 - ETA: 0s - loss: 0.003 - ETA: 0s - loss: 0.003 - 0s 81us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 6/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 0.002 - ETA: 0s - loss: 0.002 - ETA: 0s - loss: 0.002 - ETA: 0s - loss: 0.002 - 0s 79us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 7/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 0.001 - ETA: 0s - loss: 0.002 - ETA: 0s - loss: 0.002 - ETA: 0s - loss: 0.001 - 0s 84us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 8/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 0.001 - ETA: 0s - loss: 0.001 - ETA: 0s - loss: 0.001 - ETA: 0s - loss: 0.001 - 0s 83us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 9/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 0.001 - ETA: 0s - loss: 0.001 - ETA: 0s - loss: 0.001 - ETA: 0s - loss: 0.001 - 0s 79us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 10/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 0.001 - ETA: 0s - loss: 0.001 - ETA: 0s - loss: 0.001 - ETA: 0s - loss: 0.001 - 0s 84us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 11/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 9.4568e-0 - ETA: 0s - loss: 0.0011    - ETA: 0s - loss: 0.001 - ETA: 0s - loss: 0.001 - 0s 87us/step - loss: 0.0011 - val_loss: 9.4379e-04\n",
      "Epoch 12/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 8.5449e-0 - ETA: 0s - loss: 9.8520e-0 - ETA: 0s - loss: 0.0010    - ETA: 0s - loss: 9.6879e-0 - 0s 89us/step - loss: 9.7789e-04 - val_loss: 8.7530e-04\n",
      "Epoch 13/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 9.9400e-0 - ETA: 0s - loss: 8.8275e-0 - ETA: 0s - loss: 8.3673e-0 - ETA: 0s - loss: 8.6633e-0 - 0s 90us/step - loss: 8.9889e-04 - val_loss: 8.1675e-04\n",
      "Epoch 14/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 9.1005e-0 - ETA: 0s - loss: 0.0010    - ETA: 0s - loss: 9.2680e-0 - ETA: 0s - loss: 8.5885e-0 - 0s 82us/step - loss: 8.3911e-04 - val_loss: 7.7956e-04\n",
      "Epoch 15/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 7.1356e-0 - ETA: 0s - loss: 7.4657e-0 - ETA: 0s - loss: 7.6258e-0 - ETA: 0s - loss: 7.6727e-0 - 0s 87us/step - loss: 7.8857e-04 - val_loss: 7.4296e-04\n",
      "Epoch 16/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 6.0741e-0 - ETA: 0s - loss: 7.3404e-0 - ETA: 0s - loss: 7.6281e-0 - ETA: 0s - loss: 7.3149e-0 - 0s 85us/step - loss: 7.4128e-04 - val_loss: 7.1022e-04\n",
      "Epoch 17/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 6.1591e-0 - ETA: 0s - loss: 6.7895e-0 - ETA: 0s - loss: 7.2258e-0 - ETA: 0s - loss: 7.3736e-0 - 0s 89us/step - loss: 7.0882e-04 - val_loss: 6.8553e-04\n",
      "Epoch 18/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 7.1170e-0 - ETA: 0s - loss: 6.6786e-0 - ETA: 0s - loss: 6.8380e-0 - ETA: 0s - loss: 6.7825e-0 - 0s 95us/step - loss: 6.7644e-04 - val_loss: 6.6468e-04\n",
      "Epoch 19/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 4.4642e-0 - ETA: 0s - loss: 6.2095e-0 - ETA: 0s - loss: 6.3621e-0 - ETA: 0s - loss: 6.6172e-0 - 0s 85us/step - loss: 6.4765e-04 - val_loss: 6.4554e-04\n",
      "Epoch 20/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 6.3512e-0 - ETA: 0s - loss: 6.3726e-0 - ETA: 0s - loss: 6.0186e-0 - ETA: 0s - loss: 5.9615e-0 - 0s 89us/step - loss: 6.2336e-04 - val_loss: 6.3090e-04\n",
      "Epoch 21/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 5.9195e-0 - ETA: 0s - loss: 5.7662e-0 - ETA: 0s - loss: 6.1436e-0 - ETA: 0s - loss: 6.1873e-0 - 0s 84us/step - loss: 6.0407e-04 - val_loss: 6.2034e-04\n",
      "Epoch 22/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 5.8996e-0 - ETA: 0s - loss: 5.9469e-0 - ETA: 0s - loss: 6.0091e-0 - ETA: 0s - loss: 5.7473e-0 - 0s 83us/step - loss: 5.8461e-04 - val_loss: 5.9450e-04\n",
      "Epoch 23/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 5.8670e-0 - ETA: 0s - loss: 6.0258e-0 - ETA: 0s - loss: 5.8773e-0 - ETA: 0s - loss: 5.7308e-0 - 0s 72us/step - loss: 5.6734e-04 - val_loss: 5.8118e-04\n",
      "Epoch 24/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 4.8960e-0 - ETA: 0s - loss: 5.9345e-0 - ETA: 0s - loss: 5.5233e-0 - ETA: 0s - loss: 5.5702e-0 - 0s 70us/step - loss: 5.5298e-04 - val_loss: 5.7689e-04\n",
      "Epoch 25/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 7.4497e-0 - ETA: 0s - loss: 5.4663e-0 - ETA: 0s - loss: 5.4097e-0 - 0s 68us/step - loss: 5.3610e-04 - val_loss: 5.6300e-04\n",
      "Epoch 26/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 7.4162e-0 - ETA: 0s - loss: 6.0070e-0 - ETA: 0s - loss: 5.6568e-0 - ETA: 0s - loss: 5.3979e-0 - 0s 76us/step - loss: 5.2253e-04 - val_loss: 5.5352e-04\n",
      "Epoch 27/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 4.6949e-0 - ETA: 0s - loss: 5.2428e-0 - ETA: 0s - loss: 5.2004e-0 - ETA: 0s - loss: 5.2348e-0 - 0s 72us/step - loss: 5.1062e-04 - val_loss: 5.4284e-04\n",
      "Epoch 28/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 3.5308e-0 - ETA: 0s - loss: 4.3587e-0 - ETA: 0s - loss: 4.6969e-0 - 0s 69us/step - loss: 5.0005e-04 - val_loss: 5.2960e-04\n",
      "Epoch 29/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 7.0615e-0 - ETA: 0s - loss: 4.7766e-0 - ETA: 0s - loss: 4.8281e-0 - 0s 68us/step - loss: 4.8836e-04 - val_loss: 5.2653e-04\n",
      "Epoch 30/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 6.1616e-0 - ETA: 0s - loss: 4.6320e-0 - ETA: 0s - loss: 4.5717e-0 - 0s 69us/step - loss: 4.7917e-04 - val_loss: 5.1858e-04\n",
      "Epoch 31/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 5.3111e-0 - ETA: 0s - loss: 4.8991e-0 - ETA: 0s - loss: 4.7934e-0 - 0s 70us/step - loss: 4.6852e-04 - val_loss: 5.1277e-04\n",
      "Epoch 32/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 4.3618e-0 - ETA: 0s - loss: 4.1876e-0 - ETA: 0s - loss: 4.5619e-0 - 0s 67us/step - loss: 4.6211e-04 - val_loss: 5.1107e-04\n",
      "Epoch 33/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 5.5636e-0 - ETA: 0s - loss: 4.6686e-0 - ETA: 0s - loss: 4.6190e-0 - ETA: 0s - loss: 4.5989e-0 - 0s 75us/step - loss: 4.5258e-04 - val_loss: 4.9297e-04\n",
      "Epoch 34/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 3.7671e-0 - ETA: 0s - loss: 3.9510e-0 - ETA: 0s - loss: 4.3549e-0 - 0s 68us/step - loss: 4.4737e-04 - val_loss: 4.8830e-04\n",
      "Epoch 35/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 4.6646e-0 - ETA: 0s - loss: 4.1114e-0 - ETA: 0s - loss: 4.5116e-0 - 0s 69us/step - loss: 4.3746e-04 - val_loss: 4.9133e-04\n",
      "Epoch 36/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2621/2621 [==============================] - ETA: 0s - loss: 4.2651e-0 - ETA: 0s - loss: 4.1415e-0 - ETA: 0s - loss: 4.4560e-0 - 0s 68us/step - loss: 4.3267e-04 - val_loss: 4.9267e-04\n",
      "Epoch 37/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 3.0916e-0 - ETA: 0s - loss: 4.0657e-0 - ETA: 0s - loss: 4.2453e-0 - 0s 67us/step - loss: 4.2787e-04 - val_loss: 4.7106e-04\n",
      "Epoch 38/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 4.8645e-0 - ETA: 0s - loss: 3.9806e-0 - ETA: 0s - loss: 4.1627e-0 - ETA: 0s - loss: 4.1686e-0 - 0s 74us/step - loss: 4.2018e-04 - val_loss: 4.7445e-04\n",
      "Epoch 39/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.8200e-0 - ETA: 0s - loss: 4.3501e-0 - ETA: 0s - loss: 4.2370e-0 - ETA: 0s - loss: 4.1591e-0 - 0s 76us/step - loss: 4.1369e-04 - val_loss: 4.5887e-04\n",
      "Epoch 40/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 6.1214e-0 - ETA: 0s - loss: 4.1064e-0 - ETA: 0s - loss: 4.1778e-0 - ETA: 0s - loss: 4.0148e-0 - 0s 81us/step - loss: 4.0964e-04 - val_loss: 4.6263e-04\n",
      "Epoch 41/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 3.9192e-0 - ETA: 0s - loss: 4.2727e-0 - ETA: 0s - loss: 4.1309e-0 - ETA: 0s - loss: 4.1248e-0 - 0s 82us/step - loss: 4.0292e-04 - val_loss: 4.5299e-04\n",
      "Epoch 42/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.4299e-0 - ETA: 0s - loss: 4.3145e-0 - ETA: 0s - loss: 4.0614e-0 - ETA: 0s - loss: 4.1121e-0 - 0s 92us/step - loss: 3.9804e-04 - val_loss: 4.5618e-04\n",
      "Epoch 43/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 5.3518e-0 - ETA: 0s - loss: 3.6916e-0 - ETA: 0s - loss: 3.8436e-0 - ETA: 0s - loss: 3.8608e-0 - 0s 82us/step - loss: 3.9238e-04 - val_loss: 4.4153e-04\n",
      "Epoch 44/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 3.4236e-0 - ETA: 0s - loss: 3.5412e-0 - ETA: 0s - loss: 3.7565e-0 - ETA: 0s - loss: 3.8663e-0 - 0s 75us/step - loss: 3.8598e-04 - val_loss: 4.4542e-04\n",
      "Epoch 45/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 3.1583e-0 - ETA: 0s - loss: 4.2370e-0 - ETA: 0s - loss: 3.9348e-0 - ETA: 0s - loss: 3.7853e-0 - 0s 73us/step - loss: 3.8459e-04 - val_loss: 4.3215e-04\n",
      "Epoch 46/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 3.0534e-0 - ETA: 0s - loss: 3.3307e-0 - ETA: 0s - loss: 3.8715e-0 - ETA: 0s - loss: 3.8580e-0 - 0s 89us/step - loss: 3.7806e-04 - val_loss: 4.3549e-04\n",
      "Epoch 47/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 3.4581e-0 - ETA: 0s - loss: 3.6493e-0 - ETA: 0s - loss: 3.7929e-0 - ETA: 0s - loss: 3.7589e-0 - 0s 93us/step - loss: 3.7453e-04 - val_loss: 4.2830e-04\n",
      "Epoch 48/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.8765e-0 - ETA: 0s - loss: 3.6569e-0 - ETA: 0s - loss: 3.5197e-0 - ETA: 0s - loss: 3.6536e-0 - 0s 80us/step - loss: 3.7189e-04 - val_loss: 4.2762e-04\n",
      "Epoch 49/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 3.8810e-0 - ETA: 0s - loss: 3.9918e-0 - ETA: 0s - loss: 3.8388e-0 - ETA: 0s - loss: 3.7453e-0 - 0s 83us/step - loss: 3.6717e-04 - val_loss: 4.2918e-04\n",
      "Epoch 50/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 3.0864e-0 - ETA: 0s - loss: 3.5464e-0 - ETA: 0s - loss: 3.8775e-0 - ETA: 0s - loss: 3.8279e-0 - 0s 95us/step - loss: 3.6746e-04 - val_loss: 4.2282e-04\n",
      "Epoch 51/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.4700e-0 - ETA: 0s - loss: 3.3504e-0 - ETA: 0s - loss: 3.6316e-0 - ETA: 0s - loss: 3.5065e-0 - 0s 75us/step - loss: 3.6030e-04 - val_loss: 4.1234e-04\n",
      "Epoch 52/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 3.5700e-0 - ETA: 0s - loss: 3.3972e-0 - ETA: 0s - loss: 3.5382e-0 - ETA: 0s - loss: 3.5778e-0 - 0s 79us/step - loss: 3.5693e-04 - val_loss: 4.0960e-04\n",
      "Epoch 53/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.6951e-0 - ETA: 0s - loss: 3.2902e-0 - ETA: 0s - loss: 3.4785e-0 - ETA: 0s - loss: 3.5746e-0 - 0s 81us/step - loss: 3.5393e-04 - val_loss: 4.1454e-04\n",
      "Epoch 54/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 3.2532e-0 - ETA: 0s - loss: 3.7104e-0 - ETA: 0s - loss: 3.2872e-0 - ETA: 0s - loss: 3.5119e-0 - 0s 76us/step - loss: 3.4905e-04 - val_loss: 4.0960e-04\n",
      "Epoch 55/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.2576e-0 - ETA: 0s - loss: 3.5072e-0 - ETA: 0s - loss: 3.4064e-0 - ETA: 0s - loss: 3.5440e-0 - 0s 75us/step - loss: 3.4717e-04 - val_loss: 4.0229e-04\n",
      "Epoch 56/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.7122e-0 - ETA: 0s - loss: 3.2188e-0 - ETA: 0s - loss: 3.2523e-0 - ETA: 0s - loss: 3.5220e-0 - 0s 78us/step - loss: 3.4512e-04 - val_loss: 4.0655e-04\n",
      "Epoch 57/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.5852e-0 - ETA: 0s - loss: 3.3493e-0 - ETA: 0s - loss: 3.5831e-0 - ETA: 0s - loss: 3.5119e-0 - 0s 81us/step - loss: 3.4253e-04 - val_loss: 3.9918e-04\n",
      "Epoch 58/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.3794e-0 - ETA: 0s - loss: 3.3016e-0 - ETA: 0s - loss: 3.4992e-0 - 0s 71us/step - loss: 3.3786e-04 - val_loss: 3.9350e-04\n",
      "Epoch 59/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 3.3428e-0 - ETA: 0s - loss: 3.6709e-0 - ETA: 0s - loss: 3.4773e-0 - 0s 67us/step - loss: 3.3698e-04 - val_loss: 4.0001e-04\n",
      "Epoch 60/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.5761e-0 - ETA: 0s - loss: 3.2223e-0 - ETA: 0s - loss: 3.3484e-0 - ETA: 0s - loss: 3.3718e-0 - 0s 72us/step - loss: 3.3644e-04 - val_loss: 3.8606e-04\n",
      "Epoch 61/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.5622e-0 - ETA: 0s - loss: 3.5657e-0 - ETA: 0s - loss: 3.4199e-0 - 0s 67us/step - loss: 3.3086e-04 - val_loss: 3.9162e-04\n",
      "Epoch 62/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.2806e-0 - ETA: 0s - loss: 3.3647e-0 - ETA: 0s - loss: 3.1016e-0 - 0s 67us/step - loss: 3.2938e-04 - val_loss: 3.8752e-04\n",
      "Epoch 63/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 3.3339e-0 - ETA: 0s - loss: 3.2231e-0 - ETA: 0s - loss: 3.2298e-0 - 0s 68us/step - loss: 3.2577e-04 - val_loss: 3.7984e-04\n",
      "Epoch 64/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.6587e-0 - ETA: 0s - loss: 2.9295e-0 - ETA: 0s - loss: 3.3976e-0 - 0s 67us/step - loss: 3.2529e-04 - val_loss: 3.8037e-04\n",
      "Epoch 65/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.8133e-0 - ETA: 0s - loss: 3.4641e-0 - ETA: 0s - loss: 3.3876e-0 - ETA: 0s - loss: 3.2543e-0 - 0s 72us/step - loss: 3.2130e-04 - val_loss: 3.8051e-04\n",
      "Epoch 66/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.3655e-0 - ETA: 0s - loss: 3.2037e-0 - ETA: 0s - loss: 3.1976e-0 - 0s 66us/step - loss: 3.1853e-04 - val_loss: 3.8699e-04\n",
      "Epoch 67/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 4.1722e-0 - ETA: 0s - loss: 3.4555e-0 - ETA: 0s - loss: 3.2457e-0 - 0s 68us/step - loss: 3.1947e-04 - val_loss: 3.7505e-04\n",
      "Epoch 68/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 3.2488e-0 - ETA: 0s - loss: 2.9173e-0 - ETA: 0s - loss: 3.0420e-0 - 0s 67us/step - loss: 3.1670e-04 - val_loss: 3.8219e-04\n",
      "Epoch 69/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.9113e-0 - ETA: 0s - loss: 3.2882e-0 - ETA: 0s - loss: 3.2746e-0 - ETA: 0s - loss: 3.1832e-0 - 0s 72us/step - loss: 3.1797e-04 - val_loss: 3.8355e-04\n",
      "Epoch 70/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 4.8739e-0 - ETA: 0s - loss: 3.0974e-0 - ETA: 0s - loss: 3.0866e-0 - ETA: 0s - loss: 3.1338e-0 - 0s 72us/step - loss: 3.1539e-04 - val_loss: 3.6884e-04\n",
      "Epoch 71/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 4.3837e-0 - ETA: 0s - loss: 3.1087e-0 - ETA: 0s - loss: 3.1257e-0 - ETA: 0s - loss: 3.1053e-0 - 0s 72us/step - loss: 3.1131e-04 - val_loss: 3.6731e-04\n",
      "Epoch 72/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 3.4947e-0 - ETA: 0s - loss: 3.3267e-0 - ETA: 0s - loss: 3.2276e-0 - 0s 69us/step - loss: 3.0715e-04 - val_loss: 3.6798e-04\n",
      "Epoch 73/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.9860e-0 - ETA: 0s - loss: 2.9972e-0 - ETA: 0s - loss: 2.8641e-0 - ETA: 0s - loss: 3.0111e-0 - 0s 76us/step - loss: 3.0488e-04 - val_loss: 3.6341e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 4.9478e-0 - ETA: 0s - loss: 3.5605e-0 - ETA: 0s - loss: 3.2923e-0 - ETA: 0s - loss: 3.1497e-0 - 0s 77us/step - loss: 3.0493e-04 - val_loss: 3.6500e-04\n",
      "Epoch 75/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.6201e-0 - ETA: 0s - loss: 2.9022e-0 - ETA: 0s - loss: 2.9765e-0 - ETA: 0s - loss: 3.0543e-0 - 0s 72us/step - loss: 3.0464e-04 - val_loss: 3.6087e-04\n",
      "Epoch 76/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.5646e-0 - ETA: 0s - loss: 2.7243e-0 - ETA: 0s - loss: 3.1167e-0 - ETA: 0s - loss: 3.0190e-0 - 0s 75us/step - loss: 3.0100e-04 - val_loss: 3.6091e-04\n",
      "Epoch 77/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.5351e-0 - ETA: 0s - loss: 2.9229e-0 - ETA: 0s - loss: 2.8335e-0 - 0s 68us/step - loss: 3.0017e-04 - val_loss: 3.5817e-04\n",
      "Epoch 78/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.3347e-0 - ETA: 0s - loss: 2.7615e-0 - ETA: 0s - loss: 2.7535e-0 - ETA: 0s - loss: 2.9081e-0 - 0s 90us/step - loss: 3.0203e-04 - val_loss: 3.5195e-04\n",
      "Epoch 79/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.5364e-0 - ETA: 0s - loss: 3.0298e-0 - ETA: 0s - loss: 3.0156e-0 - ETA: 0s - loss: 2.9932e-0 - 0s 78us/step - loss: 2.9768e-04 - val_loss: 3.5320e-04\n",
      "Epoch 80/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 3.8317e-0 - ETA: 0s - loss: 3.3749e-0 - ETA: 0s - loss: 2.9691e-0 - ETA: 0s - loss: 2.8906e-0 - 0s 87us/step - loss: 2.9469e-04 - val_loss: 3.6238e-04\n",
      "Epoch 81/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.5141e-0 - ETA: 0s - loss: 2.9396e-0 - ETA: 0s - loss: 2.9894e-0 - ETA: 0s - loss: 2.9753e-0 - 0s 84us/step - loss: 2.9741e-04 - val_loss: 3.6801e-04\n",
      "Epoch 82/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.9625e-0 - ETA: 0s - loss: 2.9145e-0 - ETA: 0s - loss: 3.0078e-0 - ETA: 0s - loss: 2.9132e-0 - 0s 87us/step - loss: 2.9453e-04 - val_loss: 3.4825e-04\n",
      "Epoch 83/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.2313e-0 - ETA: 0s - loss: 2.9972e-0 - ETA: 0s - loss: 3.0263e-0 - ETA: 0s - loss: 3.0514e-0 - 0s 89us/step - loss: 2.9152e-04 - val_loss: 3.5137e-04\n",
      "Epoch 84/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.7293e-0 - ETA: 0s - loss: 2.6256e-0 - ETA: 0s - loss: 2.8642e-0 - ETA: 0s - loss: 2.7910e-0 - 0s 92us/step - loss: 2.8940e-04 - val_loss: 3.4252e-04\n",
      "Epoch 85/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 3.9434e-0 - ETA: 0s - loss: 3.0247e-0 - ETA: 0s - loss: 2.7557e-0 - ETA: 0s - loss: 2.8060e-0 - 0s 82us/step - loss: 2.8762e-04 - val_loss: 3.4803e-04\n",
      "Epoch 86/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.5451e-0 - ETA: 0s - loss: 2.3614e-0 - ETA: 0s - loss: 2.7637e-0 - ETA: 0s - loss: 2.8399e-0 - 0s 79us/step - loss: 2.8604e-04 - val_loss: 3.4293e-04\n",
      "Epoch 87/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.4885e-0 - ETA: 0s - loss: 2.6726e-0 - ETA: 0s - loss: 2.8215e-0 - ETA: 0s - loss: 2.8528e-0 - 0s 77us/step - loss: 2.8496e-04 - val_loss: 3.4018e-04\n",
      "Epoch 88/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.3164e-0 - ETA: 0s - loss: 2.5401e-0 - ETA: 0s - loss: 2.6823e-0 - ETA: 0s - loss: 2.8298e-0 - 0s 77us/step - loss: 2.8348e-04 - val_loss: 3.3976e-04\n",
      "Epoch 89/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.3241e-0 - ETA: 0s - loss: 2.8346e-0 - ETA: 0s - loss: 2.7472e-0 - ETA: 0s - loss: 2.7762e-0 - 0s 79us/step - loss: 2.8387e-04 - val_loss: 3.4444e-04\n",
      "Epoch 90/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.6225e-0 - ETA: 0s - loss: 3.2541e-0 - ETA: 0s - loss: 2.9841e-0 - ETA: 0s - loss: 2.8609e-0 - 0s 81us/step - loss: 2.8405e-04 - val_loss: 3.3870e-04\n",
      "Epoch 91/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.4529e-0 - ETA: 0s - loss: 2.9504e-0 - ETA: 0s - loss: 2.8239e-0 - ETA: 0s - loss: 2.8652e-0 - 0s 80us/step - loss: 2.8095e-04 - val_loss: 3.3879e-04\n",
      "Epoch 92/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.2005e-0 - ETA: 0s - loss: 2.6139e-0 - ETA: 0s - loss: 2.8024e-0 - ETA: 0s - loss: 2.8311e-0 - 0s 78us/step - loss: 2.8160e-04 - val_loss: 3.3408e-04\n",
      "Epoch 93/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 3.6650e-0 - ETA: 0s - loss: 2.7357e-0 - ETA: 0s - loss: 2.8345e-0 - ETA: 0s - loss: 2.7856e-0 - 0s 74us/step - loss: 2.7803e-04 - val_loss: 3.3341e-04\n",
      "Epoch 94/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 4.1162e-0 - ETA: 0s - loss: 2.8331e-0 - ETA: 0s - loss: 2.8566e-0 - ETA: 0s - loss: 2.7673e-0 - 0s 84us/step - loss: 2.7596e-04 - val_loss: 3.3922e-04\n",
      "Epoch 95/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 3.1620e-0 - ETA: 0s - loss: 2.8309e-0 - ETA: 0s - loss: 2.7433e-0 - ETA: 0s - loss: 2.5607e-0 - 0s 79us/step - loss: 2.7758e-04 - val_loss: 3.3635e-04\n",
      "Epoch 96/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.8327e-0 - ETA: 0s - loss: 2.8325e-0 - ETA: 0s - loss: 2.8308e-0 - ETA: 0s - loss: 2.7452e-0 - 0s 76us/step - loss: 2.7686e-04 - val_loss: 3.3118e-04\n",
      "Epoch 97/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.9671e-0 - ETA: 0s - loss: 2.7492e-0 - ETA: 0s - loss: 2.7155e-0 - ETA: 0s - loss: 2.7771e-0 - 0s 82us/step - loss: 2.7687e-04 - val_loss: 3.3323e-04\n",
      "Epoch 98/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.7997e-0 - ETA: 0s - loss: 3.1961e-0 - ETA: 0s - loss: 2.8107e-0 - ETA: 0s - loss: 2.7373e-0 - 0s 87us/step - loss: 2.7369e-04 - val_loss: 3.3113e-04\n",
      "Epoch 99/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 3.0609e-0 - ETA: 0s - loss: 2.9059e-0 - ETA: 0s - loss: 2.6094e-0 - ETA: 0s - loss: 2.6817e-0 - 0s 80us/step - loss: 2.7019e-04 - val_loss: 3.2556e-04\n",
      "Epoch 100/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.9191e-0 - ETA: 0s - loss: 3.2067e-0 - ETA: 0s - loss: 2.7936e-0 - ETA: 0s - loss: 2.6769e-0 - 0s 82us/step - loss: 2.7154e-04 - val_loss: 3.2588e-04\n",
      "Epoch 101/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.4952e-0 - ETA: 0s - loss: 2.5013e-0 - ETA: 0s - loss: 2.7512e-0 - ETA: 0s - loss: 2.7018e-0 - 0s 81us/step - loss: 2.6947e-04 - val_loss: 3.2965e-04\n",
      "Epoch 102/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 4.1765e-0 - ETA: 0s - loss: 3.0520e-0 - ETA: 0s - loss: 2.7186e-0 - ETA: 0s - loss: 2.6608e-0 - 0s 79us/step - loss: 2.6766e-04 - val_loss: 3.2339e-04\n",
      "Epoch 103/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.4425e-0 - ETA: 0s - loss: 2.5417e-0 - ETA: 0s - loss: 2.5622e-0 - ETA: 0s - loss: 2.5868e-0 - 0s 83us/step - loss: 2.6682e-04 - val_loss: 3.2901e-04\n",
      "Epoch 104/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 3.1801e-0 - ETA: 0s - loss: 2.6277e-0 - ETA: 0s - loss: 2.5620e-0 - ETA: 0s - loss: 2.6915e-0 - 0s 81us/step - loss: 2.6959e-04 - val_loss: 3.2820e-04\n",
      "Epoch 105/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.8398e-0 - ETA: 0s - loss: 2.6437e-0 - ETA: 0s - loss: 2.6998e-0 - ETA: 0s - loss: 2.5981e-0 - 0s 78us/step - loss: 2.6713e-04 - val_loss: 3.1465e-04\n",
      "Epoch 106/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.3504e-0 - ETA: 0s - loss: 2.3506e-0 - ETA: 0s - loss: 2.5495e-0 - ETA: 0s - loss: 2.6994e-0 - 0s 82us/step - loss: 2.6606e-04 - val_loss: 3.1786e-04\n",
      "Epoch 107/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.5932e-0 - ETA: 0s - loss: 2.2374e-0 - ETA: 0s - loss: 2.4311e-0 - ETA: 0s - loss: 2.6394e-0 - 0s 74us/step - loss: 2.6464e-04 - val_loss: 3.1928e-04\n",
      "Epoch 108/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 3.3099e-0 - ETA: 0s - loss: 2.5563e-0 - ETA: 0s - loss: 2.7844e-0 - ETA: 0s - loss: 2.7463e-0 - 0s 80us/step - loss: 2.6434e-04 - val_loss: 3.1376e-04\n",
      "Epoch 109/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.4139e-0 - ETA: 0s - loss: 2.3582e-0 - ETA: 0s - loss: 2.5011e-0 - ETA: 0s - loss: 2.5524e-0 - 0s 79us/step - loss: 2.6037e-04 - val_loss: 3.1599e-04\n",
      "Epoch 110/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2621/2621 [==============================] - ETA: 0s - loss: 2.9859e-0 - ETA: 0s - loss: 2.8876e-0 - ETA: 0s - loss: 2.5300e-0 - ETA: 0s - loss: 2.5396e-0 - 0s 85us/step - loss: 2.5875e-04 - val_loss: 3.0810e-04\n",
      "Epoch 111/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.6124e-0 - ETA: 0s - loss: 2.4113e-0 - ETA: 0s - loss: 2.5886e-0 - ETA: 0s - loss: 2.5780e-0 - 0s 79us/step - loss: 2.5930e-04 - val_loss: 3.1181e-04\n",
      "Epoch 112/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 3.6501e-0 - ETA: 0s - loss: 2.6554e-0 - ETA: 0s - loss: 2.7077e-0 - ETA: 0s - loss: 2.6488e-0 - 0s 80us/step - loss: 2.6058e-04 - val_loss: 3.0823e-04\n",
      "Epoch 113/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.7529e-0 - ETA: 0s - loss: 2.5928e-0 - ETA: 0s - loss: 2.6961e-0 - ETA: 0s - loss: 2.6636e-0 - 0s 80us/step - loss: 2.5916e-04 - val_loss: 3.1206e-04\n",
      "Epoch 114/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.9286e-0 - ETA: 0s - loss: 2.7273e-0 - ETA: 0s - loss: 2.5799e-0 - ETA: 0s - loss: 2.6294e-0 - 0s 81us/step - loss: 2.5892e-04 - val_loss: 3.0635e-04\n",
      "Epoch 115/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.2078e-0 - ETA: 0s - loss: 2.1499e-0 - ETA: 0s - loss: 2.3817e-0 - ETA: 0s - loss: 2.5687e-0 - 0s 77us/step - loss: 2.5548e-04 - val_loss: 3.0510e-04\n",
      "Epoch 116/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.4722e-0 - ETA: 0s - loss: 2.6679e-0 - ETA: 0s - loss: 2.6129e-0 - ETA: 0s - loss: 2.5283e-0 - 0s 82us/step - loss: 2.5747e-04 - val_loss: 3.1223e-04\n",
      "Epoch 117/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 3.2853e-0 - ETA: 0s - loss: 2.7513e-0 - ETA: 0s - loss: 2.6286e-0 - ETA: 0s - loss: 2.6603e-0 - 0s 81us/step - loss: 2.6068e-04 - val_loss: 3.0633e-04\n",
      "Epoch 118/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.7154e-0 - ETA: 0s - loss: 2.5519e-0 - ETA: 0s - loss: 2.5875e-0 - ETA: 0s - loss: 2.5596e-0 - 0s 79us/step - loss: 2.5730e-04 - val_loss: 3.0186e-04\n",
      "Epoch 119/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.0454e-0 - ETA: 0s - loss: 2.4449e-0 - ETA: 0s - loss: 2.5736e-0 - ETA: 0s - loss: 2.4472e-0 - 0s 92us/step - loss: 2.5184e-04 - val_loss: 3.0791e-04\n",
      "Epoch 120/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.0179e-0 - ETA: 0s - loss: 2.6120e-0 - ETA: 0s - loss: 2.3697e-0 - ETA: 0s - loss: 2.6439e-0 - 0s 87us/step - loss: 2.5404e-04 - val_loss: 3.0808e-04\n",
      "Epoch 121/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.4273e-0 - ETA: 0s - loss: 2.5793e-0 - ETA: 0s - loss: 2.6088e-0 - ETA: 0s - loss: 2.5181e-0 - 0s 89us/step - loss: 2.5422e-04 - val_loss: 3.1180e-04\n",
      "Epoch 122/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.7452e-0 - ETA: 0s - loss: 2.4158e-0 - ETA: 0s - loss: 2.3523e-0 - ETA: 0s - loss: 2.3835e-0 - ETA: 0s - loss: 2.5157e-0 - 0s 92us/step - loss: 2.4901e-04 - val_loss: 3.0427e-04\n",
      "Epoch 123/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 3.6405e-0 - ETA: 0s - loss: 2.8034e-0 - ETA: 0s - loss: 2.5900e-0 - ETA: 0s - loss: 2.5479e-0 - 0s 85us/step - loss: 2.5201e-04 - val_loss: 3.0712e-04\n",
      "Epoch 124/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 3.3773e-0 - ETA: 0s - loss: 2.9442e-0 - ETA: 0s - loss: 2.7004e-0 - ETA: 0s - loss: 2.5579e-0 - 0s 81us/step - loss: 2.5245e-04 - val_loss: 2.9889e-04\n",
      "Epoch 125/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.3467e-0 - ETA: 0s - loss: 2.3867e-0 - ETA: 0s - loss: 2.4224e-0 - ETA: 0s - loss: 2.5314e-0 - 0s 84us/step - loss: 2.4799e-04 - val_loss: 3.0216e-04\n",
      "Epoch 126/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.9840e-0 - ETA: 0s - loss: 2.2278e-0 - ETA: 0s - loss: 2.4202e-0 - ETA: 0s - loss: 2.4687e-0 - 0s 74us/step - loss: 2.4740e-04 - val_loss: 2.9505e-04\n",
      "Epoch 127/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 3.6725e-0 - ETA: 0s - loss: 2.8633e-0 - ETA: 0s - loss: 2.6890e-0 - ETA: 0s - loss: 2.4740e-0 - 0s 75us/step - loss: 2.4485e-04 - val_loss: 2.9588e-04\n",
      "Epoch 128/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.3864e-0 - ETA: 0s - loss: 2.5522e-0 - ETA: 0s - loss: 2.3504e-0 - ETA: 0s - loss: 2.4486e-0 - 0s 77us/step - loss: 2.4434e-04 - val_loss: 2.9899e-04\n",
      "Epoch 129/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.1219e-0 - ETA: 0s - loss: 2.6124e-0 - ETA: 0s - loss: 2.5393e-0 - ETA: 0s - loss: 2.4723e-0 - 0s 70us/step - loss: 2.4558e-04 - val_loss: 2.9847e-04\n",
      "Epoch 130/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.9307e-0 - ETA: 0s - loss: 2.6122e-0 - ETA: 0s - loss: 2.4972e-0 - 0s 68us/step - loss: 2.4369e-04 - val_loss: 2.9999e-04\n",
      "Epoch 131/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.7095e-0 - ETA: 0s - loss: 2.2602e-0 - ETA: 0s - loss: 2.3665e-0 - ETA: 0s - loss: 2.4488e-0 - 0s 74us/step - loss: 2.4150e-04 - val_loss: 2.8804e-04\n",
      "Epoch 132/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.8984e-0 - ETA: 0s - loss: 2.4570e-0 - ETA: 0s - loss: 2.5830e-0 - ETA: 0s - loss: 2.4991e-0 - 0s 79us/step - loss: 2.4374e-04 - val_loss: 2.9085e-04\n",
      "Epoch 133/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 3.7998e-0 - ETA: 0s - loss: 2.5483e-0 - ETA: 0s - loss: 2.5589e-0 - ETA: 0s - loss: 2.4657e-0 - 0s 74us/step - loss: 2.4369e-04 - val_loss: 2.8873e-04\n",
      "Epoch 134/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.6421e-0 - ETA: 0s - loss: 2.2120e-0 - ETA: 0s - loss: 2.3864e-0 - ETA: 0s - loss: 2.3950e-0 - 0s 71us/step - loss: 2.3889e-04 - val_loss: 2.8857e-04\n",
      "Epoch 135/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 3.1967e-0 - ETA: 0s - loss: 2.4479e-0 - ETA: 0s - loss: 2.4572e-0 - ETA: 0s - loss: 2.4474e-0 - 0s 71us/step - loss: 2.3877e-04 - val_loss: 2.9449e-04\n",
      "Epoch 136/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.7527e-0 - ETA: 0s - loss: 2.2710e-0 - ETA: 0s - loss: 2.3147e-0 - ETA: 0s - loss: 2.4783e-0 - 0s 81us/step - loss: 2.4186e-04 - val_loss: 3.1138e-04\n",
      "Epoch 137/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 3.1960e-0 - ETA: 0s - loss: 2.5790e-0 - ETA: 0s - loss: 2.4660e-0 - ETA: 0s - loss: 2.4182e-0 - 0s 78us/step - loss: 2.4216e-04 - val_loss: 2.9753e-04\n",
      "Epoch 138/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.2945e-0 - ETA: 0s - loss: 2.3400e-0 - ETA: 0s - loss: 2.3300e-0 - ETA: 0s - loss: 2.4283e-0 - 0s 91us/step - loss: 2.4166e-04 - val_loss: 3.0031e-04\n",
      "Epoch 139/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.0251e-0 - ETA: 0s - loss: 2.2498e-0 - ETA: 0s - loss: 2.3490e-0 - ETA: 0s - loss: 2.3068e-0 - 0s 87us/step - loss: 2.3724e-04 - val_loss: 2.8469e-04\n",
      "Epoch 140/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.9124e-0 - ETA: 0s - loss: 2.4760e-0 - ETA: 0s - loss: 2.4482e-0 - ETA: 0s - loss: 2.3802e-0 - 0s 84us/step - loss: 2.3830e-04 - val_loss: 2.8396e-04\n",
      "Epoch 141/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.2329e-0 - ETA: 0s - loss: 2.2026e-0 - ETA: 0s - loss: 2.1949e-0 - ETA: 0s - loss: 2.2353e-0 - 0s 80us/step - loss: 2.3487e-04 - val_loss: 2.8575e-04\n",
      "Epoch 142/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.2982e-0 - ETA: 0s - loss: 2.1216e-0 - ETA: 0s - loss: 2.4511e-0 - ETA: 0s - loss: 2.4336e-0 - 0s 83us/step - loss: 2.3555e-04 - val_loss: 2.8145e-04\n",
      "Epoch 143/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 3.0006e-0 - ETA: 0s - loss: 2.8460e-0 - ETA: 0s - loss: 2.4712e-0 - ETA: 0s - loss: 2.3263e-0 - 0s 82us/step - loss: 2.3315e-04 - val_loss: 2.9213e-04\n",
      "Epoch 144/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.1938e-0 - ETA: 0s - loss: 2.3341e-0 - ETA: 0s - loss: 2.2776e-0 - ETA: 0s - loss: 2.3567e-0 - 0s 87us/step - loss: 2.3484e-04 - val_loss: 2.9323e-04\n",
      "Epoch 145/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.7170e-0 - ETA: 0s - loss: 2.1696e-0 - ETA: 0s - loss: 2.4236e-0 - ETA: 0s - loss: 2.2976e-0 - 0s 85us/step - loss: 2.3781e-04 - val_loss: 2.8832e-04\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2621/2621 [==============================] - ETA: 0s - loss: 2.3387e-0 - ETA: 0s - loss: 2.4803e-0 - ETA: 0s - loss: 2.4592e-0 - ETA: 0s - loss: 2.3716e-0 - 0s 77us/step - loss: 2.3539e-04 - val_loss: 2.9199e-04\n",
      "Epoch 147/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.5427e-0 - ETA: 0s - loss: 2.3049e-0 - ETA: 0s - loss: 2.3077e-0 - ETA: 0s - loss: 2.2800e-0 - 0s 79us/step - loss: 2.3325e-04 - val_loss: 2.8721e-04\n",
      "Epoch 148/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.2221e-0 - ETA: 0s - loss: 2.5415e-0 - ETA: 0s - loss: 2.4711e-0 - ETA: 0s - loss: 2.3030e-0 - 0s 84us/step - loss: 2.3165e-04 - val_loss: 2.8806e-04\n",
      "Epoch 149/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.7126e-0 - ETA: 0s - loss: 2.0942e-0 - ETA: 0s - loss: 2.1908e-0 - ETA: 0s - loss: 2.2884e-0 - 0s 82us/step - loss: 2.3001e-04 - val_loss: 2.7578e-04\n",
      "Epoch 150/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 3.0816e-0 - ETA: 0s - loss: 2.5203e-0 - ETA: 0s - loss: 2.4014e-0 - ETA: 0s - loss: 2.3523e-0 - 0s 79us/step - loss: 2.2840e-04 - val_loss: 2.8105e-04\n",
      "Epoch 151/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.0084e-0 - ETA: 0s - loss: 1.8779e-0 - ETA: 0s - loss: 1.9144e-0 - ETA: 0s - loss: 2.1826e-0 - 0s 83us/step - loss: 2.2689e-04 - val_loss: 2.7870e-04\n",
      "Epoch 152/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.0780e-0 - ETA: 0s - loss: 2.2623e-0 - ETA: 0s - loss: 2.2131e-0 - ETA: 0s - loss: 2.2401e-0 - 0s 84us/step - loss: 2.2520e-04 - val_loss: 2.7795e-04\n",
      "Epoch 153/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.6658e-0 - ETA: 0s - loss: 2.1657e-0 - ETA: 0s - loss: 2.0867e-0 - ETA: 0s - loss: 2.2605e-0 - 0s 82us/step - loss: 2.2667e-04 - val_loss: 2.7679e-04\n",
      "Epoch 154/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 3.6938e-0 - ETA: 0s - loss: 2.3177e-0 - ETA: 0s - loss: 2.2987e-0 - ETA: 0s - loss: 2.2913e-0 - 0s 81us/step - loss: 2.2472e-04 - val_loss: 2.7230e-04\n",
      "Epoch 155/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.6856e-0 - ETA: 0s - loss: 2.4728e-0 - ETA: 0s - loss: 2.3067e-0 - ETA: 0s - loss: 2.2577e-0 - 0s 81us/step - loss: 2.2478e-04 - val_loss: 2.7457e-04\n",
      "Epoch 156/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.3160e-0 - ETA: 0s - loss: 2.1821e-0 - ETA: 0s - loss: 2.2430e-0 - ETA: 0s - loss: 2.2444e-0 - 0s 81us/step - loss: 2.2702e-04 - val_loss: 2.7696e-04\n",
      "Epoch 157/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.6693e-0 - ETA: 0s - loss: 2.1305e-0 - ETA: 0s - loss: 2.1531e-0 - ETA: 0s - loss: 2.2557e-0 - 0s 80us/step - loss: 2.2335e-04 - val_loss: 2.8069e-04\n",
      "Epoch 158/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.1162e-0 - ETA: 0s - loss: 2.1635e-0 - ETA: 0s - loss: 2.2506e-0 - ETA: 0s - loss: 2.3069e-0 - 0s 87us/step - loss: 2.2073e-04 - val_loss: 2.7393e-04\n",
      "Epoch 159/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.9970e-0 - ETA: 0s - loss: 2.1081e-0 - ETA: 0s - loss: 2.2676e-0 - ETA: 0s - loss: 2.2445e-0 - 0s 79us/step - loss: 2.2157e-04 - val_loss: 2.7090e-04\n",
      "Epoch 160/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.4259e-0 - ETA: 0s - loss: 2.2178e-0 - ETA: 0s - loss: 2.2030e-0 - ETA: 0s - loss: 2.2350e-0 - 0s 78us/step - loss: 2.2224e-04 - val_loss: 2.6747e-04\n",
      "Epoch 161/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.2182e-0 - ETA: 0s - loss: 2.2035e-0 - ETA: 0s - loss: 2.2922e-0 - ETA: 0s - loss: 2.2559e-0 - 0s 80us/step - loss: 2.2003e-04 - val_loss: 2.7179e-04\n",
      "Epoch 162/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.4163e-0 - ETA: 0s - loss: 2.4652e-0 - ETA: 0s - loss: 2.1735e-0 - ETA: 0s - loss: 2.2592e-0 - 0s 80us/step - loss: 2.2183e-04 - val_loss: 2.6530e-04\n",
      "Epoch 163/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.4334e-0 - ETA: 0s - loss: 2.1011e-0 - ETA: 0s - loss: 2.0453e-0 - ETA: 0s - loss: 2.1386e-0 - 0s 82us/step - loss: 2.2207e-04 - val_loss: 2.7157e-04\n",
      "Epoch 164/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.9627e-0 - ETA: 0s - loss: 1.9347e-0 - ETA: 0s - loss: 2.1478e-0 - ETA: 0s - loss: 2.2258e-0 - 0s 74us/step - loss: 2.1977e-04 - val_loss: 2.6599e-04\n",
      "Epoch 165/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.8561e-0 - ETA: 0s - loss: 2.0861e-0 - ETA: 0s - loss: 2.1236e-0 - ETA: 0s - loss: 2.1336e-0 - 0s 81us/step - loss: 2.1762e-04 - val_loss: 2.6647e-04\n",
      "Epoch 166/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.9909e-0 - ETA: 0s - loss: 2.4417e-0 - ETA: 0s - loss: 2.2671e-0 - ETA: 0s - loss: 2.2253e-0 - 0s 77us/step - loss: 2.1726e-04 - val_loss: 2.6235e-04\n",
      "Epoch 167/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.1260e-0 - ETA: 0s - loss: 1.9268e-0 - ETA: 0s - loss: 2.0727e-0 - ETA: 0s - loss: 2.1314e-0 - 0s 77us/step - loss: 2.1495e-04 - val_loss: 2.7314e-04\n",
      "Epoch 168/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.1078e-0 - ETA: 0s - loss: 1.7788e-0 - ETA: 0s - loss: 1.8688e-0 - ETA: 0s - loss: 2.0113e-0 - 0s 87us/step - loss: 2.1565e-04 - val_loss: 2.7124e-04\n",
      "Epoch 169/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.7001e-0 - ETA: 0s - loss: 2.1248e-0 - ETA: 0s - loss: 2.1965e-0 - ETA: 0s - loss: 2.1788e-0 - 0s 76us/step - loss: 2.1624e-04 - val_loss: 2.6033e-04\n",
      "Epoch 170/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.9766e-0 - ETA: 0s - loss: 1.9390e-0 - ETA: 0s - loss: 1.8618e-0 - ETA: 0s - loss: 2.0748e-0 - 0s 80us/step - loss: 2.1301e-04 - val_loss: 2.7037e-04\n",
      "Epoch 171/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.6547e-0 - ETA: 0s - loss: 2.1727e-0 - ETA: 0s - loss: 2.1197e-0 - ETA: 0s - loss: 2.0975e-0 - 0s 88us/step - loss: 2.1820e-04 - val_loss: 2.7989e-04\n",
      "Epoch 172/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.5545e-0 - ETA: 0s - loss: 2.1077e-0 - ETA: 0s - loss: 2.0899e-0 - ETA: 0s - loss: 2.0508e-0 - 0s 84us/step - loss: 2.1325e-04 - val_loss: 2.6838e-04\n",
      "Epoch 173/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 3.0003e-0 - ETA: 0s - loss: 2.3730e-0 - ETA: 0s - loss: 2.1776e-0 - ETA: 0s - loss: 2.0791e-0 - 0s 81us/step - loss: 2.1180e-04 - val_loss: 2.6246e-04\n",
      "Epoch 174/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.0068e-0 - ETA: 0s - loss: 2.1106e-0 - ETA: 0s - loss: 2.1807e-0 - ETA: 0s - loss: 2.1590e-0 - 0s 79us/step - loss: 2.1280e-04 - val_loss: 2.5729e-04\n",
      "Epoch 175/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.4714e-0 - ETA: 0s - loss: 2.0389e-0 - ETA: 0s - loss: 2.1061e-0 - ETA: 0s - loss: 2.1701e-0 - 0s 77us/step - loss: 2.1423e-04 - val_loss: 2.6165e-04\n",
      "Epoch 176/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.9635e-0 - ETA: 0s - loss: 2.1269e-0 - ETA: 0s - loss: 2.1522e-0 - ETA: 0s - loss: 2.1288e-0 - 0s 83us/step - loss: 2.1348e-04 - val_loss: 2.5916e-04\n",
      "Epoch 177/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.8454e-0 - ETA: 0s - loss: 2.3449e-0 - ETA: 0s - loss: 2.2768e-0 - ETA: 0s - loss: 2.1782e-0 - 0s 82us/step - loss: 2.0793e-04 - val_loss: 2.5744e-04\n",
      "Epoch 178/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 3.0258e-0 - ETA: 0s - loss: 2.1494e-0 - ETA: 0s - loss: 2.2095e-0 - ETA: 0s - loss: 2.1323e-0 - 0s 81us/step - loss: 2.1054e-04 - val_loss: 2.6332e-04\n",
      "Epoch 179/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.1582e-0 - ETA: 0s - loss: 2.3308e-0 - ETA: 0s - loss: 2.2092e-0 - ETA: 0s - loss: 2.1175e-0 - 0s 89us/step - loss: 2.0821e-04 - val_loss: 2.5463e-04\n",
      "Epoch 180/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.5136e-0 - ETA: 0s - loss: 2.0100e-0 - ETA: 0s - loss: 2.0500e-0 - ETA: 0s - loss: 2.0416e-0 - 0s 83us/step - loss: 2.0728e-04 - val_loss: 2.5796e-04\n",
      "Epoch 181/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.0084e-0 - ETA: 0s - loss: 2.0527e-0 - ETA: 0s - loss: 2.1041e-0 - ETA: 0s - loss: 2.0759e-0 - 0s 89us/step - loss: 2.0856e-04 - val_loss: 2.5376e-04\n",
      "Epoch 182/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2621/2621 [==============================] - ETA: 0s - loss: 1.8767e-0 - ETA: 0s - loss: 1.8662e-0 - ETA: 0s - loss: 2.1243e-0 - ETA: 0s - loss: 2.1472e-0 - ETA: 0s - loss: 2.0733e-0 - 0s 95us/step - loss: 2.0670e-04 - val_loss: 2.5111e-04\n",
      "Epoch 183/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.9855e-0 - ETA: 0s - loss: 2.0673e-0 - ETA: 0s - loss: 1.9982e-0 - ETA: 0s - loss: 2.0585e-0 - 0s 86us/step - loss: 2.0668e-04 - val_loss: 2.5197e-04\n",
      "Epoch 184/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.3314e-0 - ETA: 0s - loss: 2.2410e-0 - ETA: 0s - loss: 2.1339e-0 - ETA: 0s - loss: 2.0379e-0 - 0s 79us/step - loss: 2.0523e-04 - val_loss: 2.5462e-04\n",
      "Epoch 185/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.4373e-0 - ETA: 0s - loss: 1.8115e-0 - ETA: 0s - loss: 1.7257e-0 - ETA: 0s - loss: 1.9647e-0 - ETA: 0s - loss: 2.0342e-0 - 0s 95us/step - loss: 2.0313e-04 - val_loss: 2.4921e-04\n",
      "Epoch 186/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.4734e-0 - ETA: 0s - loss: 1.8591e-0 - ETA: 0s - loss: 2.0672e-0 - ETA: 0s - loss: 2.0015e-0 - 0s 86us/step - loss: 2.0538e-04 - val_loss: 2.5221e-04\n",
      "Epoch 187/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.6257e-0 - ETA: 0s - loss: 2.0085e-0 - ETA: 0s - loss: 2.1233e-0 - ETA: 0s - loss: 2.0503e-0 - 0s 81us/step - loss: 2.0464e-04 - val_loss: 2.5146e-04\n",
      "Epoch 188/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.3460e-0 - ETA: 0s - loss: 1.8884e-0 - ETA: 0s - loss: 2.0414e-0 - ETA: 0s - loss: 2.0447e-0 - 0s 77us/step - loss: 2.0428e-04 - val_loss: 2.6642e-04\n",
      "Epoch 189/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.2808e-0 - ETA: 0s - loss: 1.9288e-0 - ETA: 0s - loss: 2.0103e-0 - ETA: 0s - loss: 2.0551e-0 - 0s 77us/step - loss: 2.0434e-04 - val_loss: 2.5713e-04\n",
      "Epoch 190/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.7055e-0 - ETA: 0s - loss: 1.9291e-0 - ETA: 0s - loss: 1.9482e-0 - ETA: 0s - loss: 2.0120e-0 - 0s 85us/step - loss: 2.0301e-04 - val_loss: 2.5789e-04\n",
      "Epoch 191/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.6167e-0 - ETA: 0s - loss: 2.2691e-0 - ETA: 0s - loss: 2.0910e-0 - ETA: 0s - loss: 2.0184e-0 - 0s 76us/step - loss: 2.0363e-04 - val_loss: 2.5934e-04\n",
      "Epoch 192/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.1822e-0 - ETA: 0s - loss: 1.8012e-0 - ETA: 0s - loss: 1.9636e-0 - ETA: 0s - loss: 1.9315e-0 - 0s 79us/step - loss: 2.0030e-04 - val_loss: 2.4663e-04\n",
      "Epoch 193/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.0075e-0 - ETA: 0s - loss: 1.9937e-0 - ETA: 0s - loss: 2.0841e-0 - ETA: 0s - loss: 2.0819e-0 - 0s 79us/step - loss: 2.0347e-04 - val_loss: 2.5494e-04\n",
      "Epoch 194/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.4404e-0 - ETA: 0s - loss: 2.1400e-0 - ETA: 0s - loss: 2.0928e-0 - ETA: 0s - loss: 2.0350e-0 - 0s 74us/step - loss: 2.0287e-04 - val_loss: 2.4718e-04\n",
      "Epoch 195/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.2517e-0 - ETA: 0s - loss: 2.0717e-0 - ETA: 0s - loss: 1.9953e-0 - ETA: 0s - loss: 1.9607e-0 - 0s 78us/step - loss: 1.9649e-04 - val_loss: 2.4987e-04\n",
      "Epoch 196/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.0349e-0 - ETA: 0s - loss: 2.3944e-0 - ETA: 0s - loss: 2.0597e-0 - ETA: 0s - loss: 1.9861e-0 - 0s 85us/step - loss: 1.9928e-04 - val_loss: 2.4363e-04\n",
      "Epoch 197/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.4322e-0 - ETA: 0s - loss: 2.1706e-0 - ETA: 0s - loss: 2.0216e-0 - ETA: 0s - loss: 2.0164e-0 - 0s 83us/step - loss: 2.0153e-04 - val_loss: 2.4257e-04\n",
      "Epoch 198/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.0524e-0 - ETA: 0s - loss: 2.2300e-0 - ETA: 0s - loss: 2.2166e-0 - ETA: 0s - loss: 2.1360e-0 - 0s 89us/step - loss: 2.0316e-04 - val_loss: 2.4335e-04\n",
      "Epoch 199/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.7139e-0 - ETA: 0s - loss: 2.0479e-0 - ETA: 0s - loss: 1.8574e-0 - ETA: 0s - loss: 1.9278e-0 - 0s 87us/step - loss: 1.9692e-04 - val_loss: 2.4866e-04\n",
      "Epoch 200/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.8333e-0 - ETA: 0s - loss: 1.8598e-0 - ETA: 0s - loss: 1.9124e-0 - ETA: 0s - loss: 1.9254e-0 - 0s 82us/step - loss: 1.9477e-04 - val_loss: 2.4380e-04\n",
      "Epoch 201/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.3923e-0 - ETA: 0s - loss: 1.9393e-0 - ETA: 0s - loss: 2.0909e-0 - ETA: 0s - loss: 1.9754e-0 - 0s 84us/step - loss: 1.9654e-04 - val_loss: 2.3774e-04\n",
      "Epoch 202/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.2221e-0 - ETA: 0s - loss: 1.8444e-0 - ETA: 0s - loss: 1.8796e-0 - ETA: 0s - loss: 1.9134e-0 - 0s 84us/step - loss: 1.9606e-04 - val_loss: 2.4395e-04\n",
      "Epoch 203/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.8662e-0 - ETA: 0s - loss: 2.3123e-0 - ETA: 0s - loss: 2.0178e-0 - ETA: 0s - loss: 1.9787e-0 - 0s 85us/step - loss: 1.9617e-04 - val_loss: 2.3902e-04\n",
      "Epoch 204/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.1637e-0 - ETA: 0s - loss: 1.9939e-0 - ETA: 0s - loss: 1.8918e-0 - ETA: 0s - loss: 2.0628e-0 - 0s 89us/step - loss: 1.9495e-04 - val_loss: 2.3908e-04\n",
      "Epoch 205/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.8145e-0 - ETA: 0s - loss: 1.8855e-0 - ETA: 0s - loss: 1.9599e-0 - ETA: 0s - loss: 1.9292e-0 - 0s 78us/step - loss: 1.9461e-04 - val_loss: 2.3543e-04\n",
      "Epoch 206/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 3.0326e-0 - ETA: 0s - loss: 1.9251e-0 - ETA: 0s - loss: 1.9628e-0 - ETA: 0s - loss: 1.9359e-0 - 0s 77us/step - loss: 1.9205e-04 - val_loss: 2.4037e-04\n",
      "Epoch 207/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.9526e-0 - ETA: 0s - loss: 1.8243e-0 - ETA: 0s - loss: 1.8184e-0 - ETA: 0s - loss: 1.8724e-0 - 0s 82us/step - loss: 1.9612e-04 - val_loss: 2.4097e-04\n",
      "Epoch 208/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.4173e-0 - ETA: 0s - loss: 2.3731e-0 - ETA: 0s - loss: 2.0483e-0 - ETA: 0s - loss: 1.9521e-0 - 0s 87us/step - loss: 1.9219e-04 - val_loss: 2.3936e-04\n",
      "Epoch 209/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 3.1344e-0 - ETA: 0s - loss: 1.7297e-0 - ETA: 0s - loss: 1.8142e-0 - ETA: 0s - loss: 1.9723e-0 - 0s 82us/step - loss: 1.9147e-04 - val_loss: 2.3919e-04\n",
      "Epoch 210/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.0030e-0 - ETA: 0s - loss: 1.9281e-0 - ETA: 0s - loss: 1.9388e-0 - ETA: 0s - loss: 1.9502e-0 - 0s 77us/step - loss: 1.9390e-04 - val_loss: 2.4275e-04\n",
      "Epoch 211/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.5995e-0 - ETA: 0s - loss: 1.9445e-0 - ETA: 0s - loss: 1.9733e-0 - ETA: 0s - loss: 1.9692e-0 - 0s 81us/step - loss: 1.9646e-04 - val_loss: 2.3886e-04\n",
      "Epoch 212/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.7886e-0 - ETA: 0s - loss: 1.8893e-0 - ETA: 0s - loss: 1.9307e-0 - ETA: 0s - loss: 1.8963e-0 - 0s 84us/step - loss: 1.8903e-04 - val_loss: 2.3334e-04\n",
      "Epoch 213/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.8055e-0 - ETA: 0s - loss: 1.7893e-0 - ETA: 0s - loss: 1.8258e-0 - ETA: 0s - loss: 1.8317e-0 - 0s 81us/step - loss: 1.9161e-04 - val_loss: 2.2615e-04\n",
      "Epoch 214/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.2196e-0 - ETA: 0s - loss: 2.0127e-0 - ETA: 0s - loss: 1.8046e-0 - ETA: 0s - loss: 1.8519e-0 - 0s 83us/step - loss: 1.8786e-04 - val_loss: 2.3775e-04\n",
      "Epoch 215/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.3172e-0 - ETA: 0s - loss: 1.7489e-0 - ETA: 0s - loss: 1.9334e-0 - ETA: 0s - loss: 1.9291e-0 - 0s 85us/step - loss: 1.9232e-04 - val_loss: 2.3555e-04\n",
      "Epoch 216/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.8772e-0 - ETA: 0s - loss: 1.8538e-0 - ETA: 0s - loss: 1.8657e-0 - ETA: 0s - loss: 1.8641e-0 - 0s 84us/step - loss: 1.9065e-04 - val_loss: 2.3583e-04\n",
      "Epoch 217/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.0309e-0 - ETA: 0s - loss: 1.8427e-0 - ETA: 0s - loss: 1.8246e-0 - ETA: 0s - loss: 1.9195e-0 - 0s 80us/step - loss: 1.8659e-04 - val_loss: 2.2409e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 218/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.4020e-0 - ETA: 0s - loss: 1.9408e-0 - ETA: 0s - loss: 1.8929e-0 - ETA: 0s - loss: 1.8954e-0 - 0s 79us/step - loss: 1.8691e-04 - val_loss: 2.2768e-04\n",
      "Epoch 219/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.9352e-0 - ETA: 0s - loss: 1.8817e-0 - ETA: 0s - loss: 1.8949e-0 - ETA: 0s - loss: 1.9194e-0 - 0s 88us/step - loss: 1.8475e-04 - val_loss: 2.3588e-04\n",
      "Epoch 220/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.7863e-0 - ETA: 0s - loss: 1.5890e-0 - ETA: 0s - loss: 1.6986e-0 - ETA: 0s - loss: 1.8765e-0 - 0s 79us/step - loss: 1.8856e-04 - val_loss: 2.3098e-04\n",
      "Epoch 221/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.0952e-0 - ETA: 0s - loss: 1.7646e-0 - ETA: 0s - loss: 1.7552e-0 - ETA: 0s - loss: 1.7564e-0 - 0s 91us/step - loss: 1.8550e-04 - val_loss: 2.3436e-04\n",
      "Epoch 222/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.6018e-0 - ETA: 0s - loss: 1.8691e-0 - ETA: 0s - loss: 1.7552e-0 - ETA: 0s - loss: 1.8679e-0 - 0s 85us/step - loss: 1.8855e-04 - val_loss: 2.2935e-04\n",
      "Epoch 223/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.9419e-0 - ETA: 0s - loss: 1.7151e-0 - ETA: 0s - loss: 1.8467e-0 - ETA: 0s - loss: 1.9171e-0 - 0s 82us/step - loss: 1.8226e-04 - val_loss: 2.2465e-04\n",
      "Epoch 224/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.2312e-0 - ETA: 0s - loss: 1.7648e-0 - ETA: 0s - loss: 1.8211e-0 - ETA: 0s - loss: 1.8275e-0 - 0s 73us/step - loss: 1.8219e-04 - val_loss: 2.2776e-04\n",
      "Epoch 225/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.4499e-0 - ETA: 0s - loss: 1.8841e-0 - ETA: 0s - loss: 1.7504e-0 - ETA: 0s - loss: 1.7651e-0 - 0s 84us/step - loss: 1.8299e-04 - val_loss: 2.2164e-04\n",
      "Epoch 226/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.1197e-0 - ETA: 0s - loss: 1.6926e-0 - ETA: 0s - loss: 1.7511e-0 - ETA: 0s - loss: 1.8172e-0 - 0s 89us/step - loss: 1.8465e-04 - val_loss: 2.2207e-04\n",
      "Epoch 227/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.9871e-0 - ETA: 0s - loss: 1.9758e-0 - ETA: 0s - loss: 1.8434e-0 - ETA: 0s - loss: 1.8098e-0 - 0s 81us/step - loss: 1.8321e-04 - val_loss: 2.2222e-04\n",
      "Epoch 228/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.3789e-0 - ETA: 0s - loss: 1.8381e-0 - ETA: 0s - loss: 1.8997e-0 - ETA: 0s - loss: 1.8118e-0 - 0s 81us/step - loss: 1.8171e-04 - val_loss: 2.1822e-04\n",
      "Epoch 229/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.2274e-0 - ETA: 0s - loss: 1.7726e-0 - ETA: 0s - loss: 1.8473e-0 - ETA: 0s - loss: 1.8386e-0 - 0s 81us/step - loss: 1.8077e-04 - val_loss: 2.2122e-04\n",
      "Epoch 230/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.0742e-0 - ETA: 0s - loss: 1.9781e-0 - ETA: 0s - loss: 1.7876e-0 - ETA: 0s - loss: 1.8538e-0 - 0s 92us/step - loss: 1.8490e-04 - val_loss: 2.3794e-04\n",
      "Epoch 231/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.9518e-0 - ETA: 0s - loss: 1.7565e-0 - ETA: 0s - loss: 1.8067e-0 - ETA: 0s - loss: 1.8424e-0 - 0s 88us/step - loss: 1.8193e-04 - val_loss: 2.2829e-04\n",
      "Epoch 232/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.8192e-0 - ETA: 0s - loss: 2.1088e-0 - ETA: 0s - loss: 1.9173e-0 - ETA: 0s - loss: 1.8382e-0 - 0s 82us/step - loss: 1.8297e-04 - val_loss: 2.1979e-04\n",
      "Epoch 233/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.1457e-0 - ETA: 0s - loss: 1.8069e-0 - ETA: 0s - loss: 1.9627e-0 - ETA: 0s - loss: 1.8920e-0 - 0s 81us/step - loss: 1.8119e-04 - val_loss: 2.2731e-04\n",
      "Epoch 234/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.7929e-0 - ETA: 0s - loss: 1.9289e-0 - ETA: 0s - loss: 1.8943e-0 - 0s 69us/step - loss: 1.9065e-04 - val_loss: 2.1476e-04\n",
      "Epoch 235/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.3386e-0 - ETA: 0s - loss: 1.8048e-0 - ETA: 0s - loss: 1.8179e-0 - ETA: 0s - loss: 1.7866e-0 - 0s 75us/step - loss: 1.7848e-04 - val_loss: 2.1714e-04\n",
      "Epoch 236/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.5290e-0 - ETA: 0s - loss: 1.8374e-0 - ETA: 0s - loss: 1.8013e-0 - ETA: 0s - loss: 1.7881e-0 - 0s 75us/step - loss: 1.7806e-04 - val_loss: 2.1843e-04\n",
      "Epoch 237/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.0923e-0 - ETA: 0s - loss: 1.9877e-0 - ETA: 0s - loss: 1.8577e-0 - 0s 66us/step - loss: 1.8116e-04 - val_loss: 2.1137e-04\n",
      "Epoch 238/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.5813e-0 - ETA: 0s - loss: 1.7229e-0 - ETA: 0s - loss: 1.7271e-0 - ETA: 0s - loss: 1.7554e-0 - 0s 72us/step - loss: 1.7640e-04 - val_loss: 2.1374e-04\n",
      "Epoch 239/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.4212e-0 - ETA: 0s - loss: 1.8314e-0 - ETA: 0s - loss: 1.8624e-0 - ETA: 0s - loss: 1.8274e-0 - 0s 78us/step - loss: 1.7771e-04 - val_loss: 2.0959e-04\n",
      "Epoch 240/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.9045e-0 - ETA: 0s - loss: 1.8424e-0 - ETA: 0s - loss: 1.7708e-0 - ETA: 0s - loss: 1.7336e-0 - 0s 74us/step - loss: 1.7867e-04 - val_loss: 2.1503e-04\n",
      "Epoch 241/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.2694e-0 - ETA: 0s - loss: 1.7104e-0 - ETA: 0s - loss: 1.7581e-0 - ETA: 0s - loss: 1.7676e-0 - 0s 72us/step - loss: 1.7651e-04 - val_loss: 2.1845e-04\n",
      "Epoch 242/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.4363e-0 - ETA: 0s - loss: 1.6912e-0 - ETA: 0s - loss: 1.7635e-0 - ETA: 0s - loss: 1.7919e-0 - 0s 71us/step - loss: 1.7750e-04 - val_loss: 2.1024e-04\n",
      "Epoch 243/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.7360e-0 - ETA: 0s - loss: 1.6051e-0 - ETA: 0s - loss: 1.7283e-0 - ETA: 0s - loss: 1.7618e-0 - 0s 73us/step - loss: 1.7642e-04 - val_loss: 2.0963e-04\n",
      "Epoch 244/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.8042e-0 - ETA: 0s - loss: 1.9460e-0 - ETA: 0s - loss: 1.7157e-0 - 0s 69us/step - loss: 1.7532e-04 - val_loss: 2.0941e-04\n",
      "Epoch 245/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 9.8079e-0 - ETA: 0s - loss: 1.6862e-0 - ETA: 0s - loss: 1.7696e-0 - ETA: 0s - loss: 1.7188e-0 - 0s 72us/step - loss: 1.7368e-04 - val_loss: 2.0894e-04\n",
      "Epoch 246/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.0263e-0 - ETA: 0s - loss: 1.7926e-0 - ETA: 0s - loss: 1.8754e-0 - ETA: 0s - loss: 1.7667e-0 - 0s 76us/step - loss: 1.7534e-04 - val_loss: 2.0866e-04\n",
      "Epoch 247/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.0820e-0 - ETA: 0s - loss: 1.6829e-0 - ETA: 0s - loss: 1.8331e-0 - ETA: 0s - loss: 1.7781e-0 - 0s 83us/step - loss: 1.7775e-04 - val_loss: 2.0768e-04\n",
      "Epoch 248/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.2432e-0 - ETA: 0s - loss: 1.6147e-0 - ETA: 0s - loss: 1.8090e-0 - ETA: 0s - loss: 1.7610e-0 - 0s 79us/step - loss: 1.7491e-04 - val_loss: 2.0539e-04\n",
      "Epoch 249/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.1404e-0 - ETA: 0s - loss: 1.5548e-0 - ETA: 0s - loss: 1.7168e-0 - ETA: 0s - loss: 1.7515e-0 - 0s 78us/step - loss: 1.7581e-04 - val_loss: 2.0573e-04\n",
      "Epoch 250/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.4734e-0 - ETA: 0s - loss: 1.8026e-0 - ETA: 0s - loss: 1.8148e-0 - ETA: 0s - loss: 1.7826e-0 - 0s 73us/step - loss: 1.7741e-04 - val_loss: 2.0656e-04\n",
      "Epoch 251/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.3902e-0 - ETA: 0s - loss: 1.6130e-0 - ETA: 0s - loss: 1.7768e-0 - 0s 69us/step - loss: 1.7616e-04 - val_loss: 2.0617e-04\n",
      "Epoch 252/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.1782e-0 - ETA: 0s - loss: 1.7071e-0 - ETA: 0s - loss: 1.7559e-0 - 0s 69us/step - loss: 1.7194e-04 - val_loss: 2.0422e-04\n",
      "Epoch 253/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.8644e-0 - ETA: 0s - loss: 1.7839e-0 - ETA: 0s - loss: 1.8328e-0 - ETA: 0s - loss: 1.7161e-0 - 0s 77us/step - loss: 1.7197e-04 - val_loss: 2.0679e-04\n",
      "Epoch 254/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2621/2621 [==============================] - ETA: 0s - loss: 1.1600e-0 - ETA: 0s - loss: 1.5920e-0 - ETA: 0s - loss: 1.7401e-0 - ETA: 0s - loss: 1.6586e-0 - 0s 78us/step - loss: 1.6959e-04 - val_loss: 2.0736e-04\n",
      "Epoch 255/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.8419e-0 - ETA: 0s - loss: 1.7766e-0 - ETA: 0s - loss: 1.7166e-0 - ETA: 0s - loss: 1.6383e-0 - 0s 90us/step - loss: 1.7289e-04 - val_loss: 2.0476e-04\n",
      "Epoch 256/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.6285e-0 - ETA: 0s - loss: 1.8699e-0 - ETA: 0s - loss: 1.6699e-0 - ETA: 0s - loss: 1.7152e-0 - 0s 84us/step - loss: 1.6913e-04 - val_loss: 1.9981e-04\n",
      "Epoch 257/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.2594e-0 - ETA: 0s - loss: 1.7549e-0 - ETA: 0s - loss: 1.7727e-0 - ETA: 0s - loss: 1.7934e-0 - 0s 88us/step - loss: 1.7061e-04 - val_loss: 2.0211e-04\n",
      "Epoch 258/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.1822e-0 - ETA: 0s - loss: 1.6817e-0 - ETA: 0s - loss: 1.7895e-0 - ETA: 0s - loss: 1.7142e-0 - 0s 79us/step - loss: 1.6884e-04 - val_loss: 1.9898e-04\n",
      "Epoch 259/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.9608e-0 - ETA: 0s - loss: 1.7694e-0 - ETA: 0s - loss: 1.8677e-0 - ETA: 0s - loss: 1.7457e-0 - 0s 83us/step - loss: 1.7003e-04 - val_loss: 1.9872e-04\n",
      "Epoch 260/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.4647e-0 - ETA: 0s - loss: 2.0407e-0 - ETA: 0s - loss: 1.7460e-0 - ETA: 0s - loss: 1.6473e-0 - 0s 83us/step - loss: 1.6910e-04 - val_loss: 1.9745e-04\n",
      "Epoch 261/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.5071e-0 - ETA: 0s - loss: 1.4322e-0 - ETA: 0s - loss: 1.5873e-0 - ETA: 0s - loss: 1.7401e-0 - 0s 79us/step - loss: 1.6950e-04 - val_loss: 2.1794e-04\n",
      "Epoch 262/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.8936e-0 - ETA: 0s - loss: 1.7354e-0 - ETA: 0s - loss: 1.7004e-0 - ETA: 0s - loss: 1.7043e-0 - 0s 82us/step - loss: 1.7153e-04 - val_loss: 1.9909e-04\n",
      "Epoch 263/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.4884e-0 - ETA: 0s - loss: 1.6143e-0 - ETA: 0s - loss: 1.6035e-0 - ETA: 0s - loss: 1.6737e-0 - 0s 81us/step - loss: 1.6787e-04 - val_loss: 2.0076e-04\n",
      "Epoch 264/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.4049e-0 - ETA: 0s - loss: 1.4862e-0 - ETA: 0s - loss: 1.6058e-0 - ETA: 0s - loss: 1.5712e-0 - ETA: 0s - loss: 1.6443e-0 - 0s 91us/step - loss: 1.6739e-04 - val_loss: 2.0079e-04\n",
      "Epoch 265/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.0786e-0 - ETA: 0s - loss: 1.6574e-0 - ETA: 0s - loss: 1.6620e-0 - ETA: 0s - loss: 1.6951e-0 - 0s 77us/step - loss: 1.6763e-04 - val_loss: 1.9540e-04\n",
      "Epoch 266/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.0764e-0 - ETA: 0s - loss: 1.7896e-0 - ETA: 0s - loss: 1.8492e-0 - ETA: 0s - loss: 1.6856e-0 - 0s 89us/step - loss: 1.6593e-04 - val_loss: 1.9620e-04\n",
      "Epoch 267/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.6187e-0 - ETA: 0s - loss: 1.6221e-0 - ETA: 0s - loss: 1.6439e-0 - ETA: 0s - loss: 1.6854e-0 - 0s 83us/step - loss: 1.6846e-04 - val_loss: 1.9551e-04\n",
      "Epoch 268/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.0936e-0 - ETA: 0s - loss: 1.5869e-0 - ETA: 0s - loss: 1.7243e-0 - ETA: 0s - loss: 1.7418e-0 - 0s 85us/step - loss: 1.6876e-04 - val_loss: 2.0556e-04\n",
      "Epoch 269/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.7497e-0 - ETA: 0s - loss: 1.4616e-0 - ETA: 0s - loss: 1.6390e-0 - ETA: 0s - loss: 1.6217e-0 - 0s 83us/step - loss: 1.6575e-04 - val_loss: 2.0643e-04\n",
      "Epoch 270/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.5452e-0 - ETA: 0s - loss: 1.7146e-0 - ETA: 0s - loss: 1.6620e-0 - ETA: 0s - loss: 1.7474e-0 - 0s 79us/step - loss: 1.6880e-04 - val_loss: 2.0211e-04\n",
      "Epoch 271/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.5086e-0 - ETA: 0s - loss: 1.8989e-0 - ETA: 0s - loss: 1.7683e-0 - ETA: 0s - loss: 1.7107e-0 - 0s 81us/step - loss: 1.6882e-04 - val_loss: 1.9007e-04\n",
      "Epoch 272/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 9.7115e-0 - ETA: 0s - loss: 1.5999e-0 - ETA: 0s - loss: 1.5677e-0 - ETA: 0s - loss: 1.6111e-0 - 0s 80us/step - loss: 1.6473e-04 - val_loss: 1.9300e-04\n",
      "Epoch 273/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.8893e-0 - ETA: 0s - loss: 1.7127e-0 - ETA: 0s - loss: 1.6156e-0 - ETA: 0s - loss: 1.6371e-0 - 0s 90us/step - loss: 1.6185e-04 - val_loss: 1.9590e-04\n",
      "Epoch 274/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.3425e-0 - ETA: 0s - loss: 1.7601e-0 - ETA: 0s - loss: 1.6351e-0 - ETA: 0s - loss: 1.7179e-0 - 0s 80us/step - loss: 1.6677e-04 - val_loss: 1.9050e-04\n",
      "Epoch 275/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.0553e-0 - ETA: 0s - loss: 1.4202e-0 - ETA: 0s - loss: 1.5398e-0 - ETA: 0s - loss: 1.6765e-0 - 0s 84us/step - loss: 1.6313e-04 - val_loss: 1.9688e-04\n",
      "Epoch 276/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.1724e-0 - ETA: 0s - loss: 1.8819e-0 - ETA: 0s - loss: 1.7383e-0 - ETA: 0s - loss: 1.6668e-0 - 0s 82us/step - loss: 1.6393e-04 - val_loss: 1.9223e-04\n",
      "Epoch 277/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.3939e-0 - ETA: 0s - loss: 1.7145e-0 - ETA: 0s - loss: 1.5520e-0 - ETA: 0s - loss: 1.6113e-0 - 0s 88us/step - loss: 1.6777e-04 - val_loss: 1.9408e-04\n",
      "Epoch 278/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.7100e-0 - ETA: 0s - loss: 1.6960e-0 - ETA: 0s - loss: 1.6305e-0 - ETA: 0s - loss: 1.6815e-0 - 0s 81us/step - loss: 1.6539e-04 - val_loss: 1.8899e-04\n",
      "Epoch 279/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.3405e-0 - ETA: 0s - loss: 1.7401e-0 - ETA: 0s - loss: 1.6895e-0 - ETA: 0s - loss: 1.7172e-0 - 0s 86us/step - loss: 1.6720e-04 - val_loss: 1.8865e-04\n",
      "Epoch 280/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.8443e-0 - ETA: 0s - loss: 1.5650e-0 - ETA: 0s - loss: 1.6994e-0 - ETA: 0s - loss: 1.6891e-0 - ETA: 0s - loss: 1.6351e-0 - 0s 93us/step - loss: 1.6171e-04 - val_loss: 1.9410e-04\n",
      "Epoch 281/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.5411e-0 - ETA: 0s - loss: 1.5405e-0 - ETA: 0s - loss: 1.6202e-0 - ETA: 0s - loss: 1.6664e-0 - 0s 82us/step - loss: 1.6750e-04 - val_loss: 1.8922e-04\n",
      "Epoch 282/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.4884e-0 - ETA: 0s - loss: 1.7358e-0 - ETA: 0s - loss: 1.7275e-0 - ETA: 0s - loss: 1.6037e-0 - 0s 84us/step - loss: 1.6065e-04 - val_loss: 2.0282e-04\n",
      "Epoch 283/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.0576e-0 - ETA: 0s - loss: 1.6785e-0 - ETA: 0s - loss: 1.7189e-0 - ETA: 0s - loss: 1.6351e-0 - 0s 83us/step - loss: 1.6222e-04 - val_loss: 1.9333e-04\n",
      "Epoch 284/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.1765e-0 - ETA: 0s - loss: 1.6425e-0 - ETA: 0s - loss: 1.7760e-0 - ETA: 0s - loss: 1.6331e-0 - 0s 77us/step - loss: 1.6222e-04 - val_loss: 1.9013e-04\n",
      "Epoch 285/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.7106e-0 - ETA: 0s - loss: 1.4506e-0 - ETA: 0s - loss: 1.6996e-0 - ETA: 0s - loss: 1.6005e-0 - 0s 75us/step - loss: 1.6057e-04 - val_loss: 1.8673e-04\n",
      "Epoch 286/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.2871e-0 - ETA: 0s - loss: 1.6100e-0 - ETA: 0s - loss: 1.6570e-0 - ETA: 0s - loss: 1.5654e-0 - 0s 77us/step - loss: 1.5938e-04 - val_loss: 1.8795e-04\n",
      "Epoch 287/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.4528e-0 - ETA: 0s - loss: 1.6726e-0 - ETA: 0s - loss: 1.6702e-0 - ETA: 0s - loss: 1.6159e-0 - 0s 75us/step - loss: 1.6348e-04 - val_loss: 1.9383e-04\n",
      "Epoch 288/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.5291e-0 - ETA: 0s - loss: 1.5888e-0 - ETA: 0s - loss: 1.6051e-0 - ETA: 0s - loss: 1.6017e-0 - 0s 79us/step - loss: 1.6085e-04 - val_loss: 1.8498e-04\n",
      "Epoch 289/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.6960e-0 - ETA: 0s - loss: 1.7610e-0 - ETA: 0s - loss: 1.6652e-0 - ETA: 0s - loss: 1.5651e-0 - 0s 77us/step - loss: 1.6032e-04 - val_loss: 1.9250e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 290/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.3966e-0 - ETA: 0s - loss: 1.2824e-0 - ETA: 0s - loss: 1.4684e-0 - ETA: 0s - loss: 1.5947e-0 - 0s 81us/step - loss: 1.6064e-04 - val_loss: 2.0101e-04\n",
      "Epoch 291/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.4399e-0 - ETA: 0s - loss: 1.6275e-0 - ETA: 0s - loss: 1.6479e-0 - ETA: 0s - loss: 1.6608e-0 - 0s 82us/step - loss: 1.6265e-04 - val_loss: 1.8337e-04\n",
      "Epoch 292/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.7208e-0 - ETA: 0s - loss: 1.6653e-0 - ETA: 0s - loss: 1.6524e-0 - ETA: 0s - loss: 1.6146e-0 - 0s 83us/step - loss: 1.6300e-04 - val_loss: 1.8475e-04\n",
      "Epoch 293/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.6599e-0 - ETA: 0s - loss: 1.6951e-0 - ETA: 0s - loss: 1.6665e-0 - ETA: 0s - loss: 1.5440e-0 - 0s 81us/step - loss: 1.5803e-04 - val_loss: 1.8557e-04\n",
      "Epoch 294/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.0537e-0 - ETA: 0s - loss: 1.4175e-0 - ETA: 0s - loss: 1.5472e-0 - ETA: 0s - loss: 1.5727e-0 - 0s 77us/step - loss: 1.5836e-04 - val_loss: 1.8429e-04\n",
      "Epoch 295/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.6611e-0 - ETA: 0s - loss: 1.8092e-0 - ETA: 0s - loss: 1.7461e-0 - ETA: 0s - loss: 1.6449e-0 - 0s 83us/step - loss: 1.5889e-04 - val_loss: 1.8679e-04\n",
      "Epoch 296/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.0809e-0 - ETA: 0s - loss: 1.3004e-0 - ETA: 0s - loss: 1.4161e-0 - ETA: 0s - loss: 1.6153e-0 - 0s 80us/step - loss: 1.5835e-04 - val_loss: 1.8092e-04\n",
      "Epoch 297/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.3858e-0 - ETA: 0s - loss: 1.7410e-0 - ETA: 0s - loss: 1.6821e-0 - ETA: 0s - loss: 1.5769e-0 - 0s 77us/step - loss: 1.5664e-04 - val_loss: 1.8255e-04\n",
      "Epoch 298/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.6066e-0 - ETA: 0s - loss: 1.5299e-0 - ETA: 0s - loss: 1.5895e-0 - ETA: 0s - loss: 1.6160e-0 - 0s 79us/step - loss: 1.5692e-04 - val_loss: 1.8521e-04\n",
      "Epoch 299/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.0364e-0 - ETA: 0s - loss: 1.6398e-0 - ETA: 0s - loss: 1.6612e-0 - ETA: 0s - loss: 1.6329e-0 - 0s 85us/step - loss: 1.6081e-04 - val_loss: 1.9714e-04\n",
      "Epoch 300/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.5705e-0 - ETA: 0s - loss: 1.5376e-0 - ETA: 0s - loss: 1.6902e-0 - ETA: 0s - loss: 1.6457e-0 - 0s 80us/step - loss: 1.6118e-04 - val_loss: 1.8064e-04\n",
      "Epoch 301/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 8.8188e-0 - ETA: 0s - loss: 1.3620e-0 - ETA: 0s - loss: 1.4413e-0 - ETA: 0s - loss: 1.5820e-0 - 0s 76us/step - loss: 1.5609e-04 - val_loss: 1.8694e-04\n",
      "Epoch 302/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.3557e-0 - ETA: 0s - loss: 1.4785e-0 - ETA: 0s - loss: 1.4446e-0 - ETA: 0s - loss: 1.5472e-0 - 0s 88us/step - loss: 1.5805e-04 - val_loss: 1.8122e-04\n",
      "Epoch 303/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.7465e-0 - ETA: 0s - loss: 1.5356e-0 - ETA: 0s - loss: 1.5034e-0 - ETA: 0s - loss: 1.5149e-0 - 0s 86us/step - loss: 1.5550e-04 - val_loss: 1.8350e-04\n",
      "Epoch 304/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.8714e-0 - ETA: 0s - loss: 1.5531e-0 - ETA: 0s - loss: 1.4766e-0 - ETA: 0s - loss: 1.5671e-0 - ETA: 0s - loss: 1.5695e-0 - 0s 98us/step - loss: 1.5671e-04 - val_loss: 1.8552e-04\n",
      "Epoch 305/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.0990e-0 - ETA: 0s - loss: 1.5572e-0 - ETA: 0s - loss: 1.5575e-0 - ETA: 0s - loss: 1.5643e-0 - 0s 82us/step - loss: 1.5572e-04 - val_loss: 1.8025e-04\n",
      "Epoch 306/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.2943e-0 - ETA: 0s - loss: 1.4244e-0 - ETA: 0s - loss: 1.5377e-0 - ETA: 0s - loss: 1.5445e-0 - 0s 78us/step - loss: 1.5450e-04 - val_loss: 1.8370e-04\n",
      "Epoch 307/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.0829e-0 - ETA: 0s - loss: 1.4003e-0 - ETA: 0s - loss: 1.6016e-0 - ETA: 0s - loss: 1.6184e-0 - 0s 82us/step - loss: 1.5741e-04 - val_loss: 1.7856e-04\n",
      "Epoch 308/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.5912e-0 - ETA: 0s - loss: 1.5615e-0 - ETA: 0s - loss: 1.6346e-0 - 0s 71us/step - loss: 1.5992e-04 - val_loss: 1.8991e-04\n",
      "Epoch 309/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.1949e-0 - ETA: 0s - loss: 1.5546e-0 - ETA: 0s - loss: 1.6879e-0 - 0s 70us/step - loss: 1.6347e-04 - val_loss: 1.8209e-04\n",
      "Epoch 310/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.3892e-0 - ETA: 0s - loss: 1.4628e-0 - ETA: 0s - loss: 1.5614e-0 - 0s 70us/step - loss: 1.5753e-04 - val_loss: 1.9611e-04\n",
      "Epoch 311/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.4586e-0 - ETA: 0s - loss: 1.7531e-0 - ETA: 0s - loss: 1.7490e-0 - ETA: 0s - loss: 1.7079e-0 - 0s 81us/step - loss: 1.6191e-04 - val_loss: 1.8267e-04\n",
      "Epoch 312/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.8743e-0 - ETA: 0s - loss: 1.5271e-0 - ETA: 0s - loss: 1.5001e-0 - ETA: 0s - loss: 1.5675e-0 - 0s 73us/step - loss: 1.5567e-04 - val_loss: 1.8177e-04\n",
      "Epoch 313/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.2020e-0 - ETA: 0s - loss: 1.4749e-0 - ETA: 0s - loss: 1.5262e-0 - 0s 67us/step - loss: 1.5578e-04 - val_loss: 1.8894e-04\n",
      "Epoch 314/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.7435e-0 - ETA: 0s - loss: 1.6702e-0 - ETA: 0s - loss: 1.5716e-0 - ETA: 0s - loss: 1.5274e-0 - 0s 74us/step - loss: 1.5413e-04 - val_loss: 1.8185e-04\n",
      "Epoch 315/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.9444e-0 - ETA: 0s - loss: 1.6591e-0 - ETA: 0s - loss: 1.6051e-0 - ETA: 0s - loss: 1.5597e-0 - 0s 81us/step - loss: 1.5797e-04 - val_loss: 1.8449e-04\n",
      "Epoch 316/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.0159e-0 - ETA: 0s - loss: 1.4975e-0 - ETA: 0s - loss: 1.6167e-0 - ETA: 0s - loss: 1.5635e-0 - 0s 77us/step - loss: 1.5468e-04 - val_loss: 1.7892e-04\n",
      "Epoch 317/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.8443e-0 - ETA: 0s - loss: 1.5321e-0 - ETA: 0s - loss: 1.5428e-0 - 0s 66us/step - loss: 1.5275e-04 - val_loss: 1.8256e-04\n",
      "Epoch 318/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.5462e-0 - ETA: 0s - loss: 1.4360e-0 - ETA: 0s - loss: 1.5856e-0 - 0s 67us/step - loss: 1.5499e-04 - val_loss: 1.7834e-04\n",
      "Epoch 319/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.2605e-0 - ETA: 0s - loss: 1.5700e-0 - ETA: 0s - loss: 1.5831e-0 - 0s 69us/step - loss: 1.5520e-04 - val_loss: 1.7864e-04\n",
      "Epoch 320/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.5714e-0 - ETA: 0s - loss: 1.6191e-0 - ETA: 0s - loss: 1.5992e-0 - ETA: 0s - loss: 1.5600e-0 - 0s 78us/step - loss: 1.5430e-04 - val_loss: 1.8059e-04\n",
      "Epoch 321/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 8.3650e-0 - ETA: 0s - loss: 1.6133e-0 - ETA: 0s - loss: 1.6014e-0 - ETA: 0s - loss: 1.5653e-0 - 0s 80us/step - loss: 1.5317e-04 - val_loss: 1.7958e-04\n",
      "Epoch 322/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.0700e-0 - ETA: 0s - loss: 1.7845e-0 - ETA: 0s - loss: 1.6222e-0 - ETA: 0s - loss: 1.5458e-0 - 0s 71us/step - loss: 1.5316e-04 - val_loss: 1.7791e-04\n",
      "Epoch 323/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 2.0903e-0 - ETA: 0s - loss: 1.4542e-0 - ETA: 0s - loss: 1.5208e-0 - 0s 67us/step - loss: 1.5427e-04 - val_loss: 1.7708e-04\n",
      "Epoch 324/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 8.8637e-0 - ETA: 0s - loss: 1.5421e-0 - ETA: 0s - loss: 1.4661e-0 - ETA: 0s - loss: 1.5692e-0 - 0s 83us/step - loss: 1.5430e-04 - val_loss: 1.8165e-04\n",
      "Epoch 325/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.5371e-0 - ETA: 0s - loss: 1.5089e-0 - ETA: 0s - loss: 1.5177e-0 - ETA: 0s - loss: 1.6024e-0 - 0s 79us/step - loss: 1.5964e-04 - val_loss: 1.7719e-04\n",
      "Epoch 326/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.7414e-0 - ETA: 0s - loss: 1.6664e-0 - ETA: 0s - loss: 1.5019e-0 - ETA: 0s - loss: 1.5555e-0 - 0s 76us/step - loss: 1.5486e-04 - val_loss: 1.7988e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 327/1000\n",
      "2621/2621 [==============================] - ETA: 0s - loss: 1.0758e-0 - ETA: 0s - loss: 1.4554e-0 - ETA: 0s - loss: 1.5352e-0 - ETA: 0s - loss: 1.5375e-0 - 0s 74us/step - loss: 1.5342e-04 - val_loss: 1.8129e-04\n",
      "Epoch 00327: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a516e6e1d0>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = data_raw.drop(columns=['code','amount','preclose','adj'])\n",
    "train_Aug = augFeatures(train)\n",
    "train_norm = normalize(train_Aug)\n",
    "# change the last day and next day \n",
    "X_train, Y_train = buildTrain(train_norm, 30, 1)\n",
    "X_train, Y_train = shuffle(X_train, Y_train)\n",
    "# because no return sequence, Y_train and Y_val shape must be 2 dimension\n",
    "X_train, Y_train, X_val, Y_val = splitData(X_train, Y_train, 0.1)\n",
    "\n",
    "model = buildManyToOneModel(X_train.shape)\n",
    "callback = EarlyStopping(monitor=\"loss\", patience=10, verbose=1, mode=\"auto\")\n",
    "model.fit(X_train, Y_train, epochs=1000, batch_size=128, validation_data=(X_val, Y_val), callbacks=[callback])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一對多模型\n",
    "因為是一對多模型Timesteps只有1，因此return_sequences=False 才可執行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildOneToManyModel(shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(10, input_length=shape[1], input_dim=shape[2]))\n",
    "    # output shape: (5, 1)\n",
    "    model.add(Dense(1))\n",
    "    model.add(RepeatVector(5))\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將pastDay 設為1, futureDay 設為5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GuQiang\\AppData\\Local\\conda\\conda\\envs\\finance35\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\GuQiang\\AppData\\Local\\conda\\conda\\envs\\finance35\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(10, input_shape=(1, 9))`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 10)                800       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 11        \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 5, 1)              0         \n",
      "=================================================================\n",
      "Total params: 811\n",
      "Trainable params: 811\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2644 samples, validate on 293 samples\n",
      "Epoch 1/1000\n",
      "2644/2644 [==============================] - ETA: 17s - loss: 0.05 - 1s 377us/step - loss: 0.0421 - val_loss: 0.0330\n",
      "Epoch 2/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 0.040 - 0s 17us/step - loss: 0.0345 - val_loss: 0.0270\n",
      "Epoch 3/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 0.023 - 0s 18us/step - loss: 0.0280 - val_loss: 0.0220\n",
      "Epoch 4/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 0.018 - 0s 15us/step - loss: 0.0222 - val_loss: 0.0171\n",
      "Epoch 5/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 0.016 - 0s 15us/step - loss: 0.0166 - val_loss: 0.0126\n",
      "Epoch 6/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 0.012 - 0s 17us/step - loss: 0.0117 - val_loss: 0.0088\n",
      "Epoch 7/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 0.007 - 0s 17us/step - loss: 0.0075 - val_loss: 0.0058\n",
      "Epoch 8/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 0.005 - 0s 16us/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 9/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 0.004 - 0s 18us/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 10/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 0.002 - 0s 15us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 11/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 0.002 - 0s 17us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 12/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 0.002 - 0s 16us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 13/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 0.002 - 0s 16us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 14/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 0.001 - 0s 18us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 15/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 0.001 - 0s 20us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 16/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 9.5066e-0 - 0s 19us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 17/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 9.3447e-0 - 0s 19us/step - loss: 9.8142e-04 - val_loss: 9.4440e-04\n",
      "Epoch 18/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 9.9938e-0 - 0s 16us/step - loss: 9.0673e-04 - val_loss: 8.5007e-04\n",
      "Epoch 19/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 7.2153e-0 - 0s 15us/step - loss: 8.4130e-04 - val_loss: 7.7464e-04\n",
      "Epoch 20/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 0.001 - 0s 15us/step - loss: 7.8332e-04 - val_loss: 7.0716e-04\n",
      "Epoch 21/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 5.7861e-0 - 0s 16us/step - loss: 7.3529e-04 - val_loss: 6.4835e-04\n",
      "Epoch 22/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 6.0720e-0 - 0s 16us/step - loss: 6.8945e-04 - val_loss: 5.9626e-04\n",
      "Epoch 23/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 6.9133e-0 - 0s 15us/step - loss: 6.5449e-04 - val_loss: 5.5343e-04\n",
      "Epoch 24/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 8.1199e-0 - 0s 18us/step - loss: 6.2005e-04 - val_loss: 5.1302e-04\n",
      "Epoch 25/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 5.2225e-0 - 0s 18us/step - loss: 5.9241e-04 - val_loss: 4.7960e-04\n",
      "Epoch 26/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 6.2375e-0 - 0s 16us/step - loss: 5.6757e-04 - val_loss: 4.5333e-04\n",
      "Epoch 27/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 6.4304e-0 - 0s 15us/step - loss: 5.4925e-04 - val_loss: 4.3137e-04\n",
      "Epoch 28/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 5.6824e-0 - 0s 16us/step - loss: 5.3307e-04 - val_loss: 4.1105e-04\n",
      "Epoch 29/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 5.2138e-0 - 0s 19us/step - loss: 5.1562e-04 - val_loss: 3.9358e-04\n",
      "Epoch 30/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 6.3126e-0 - 0s 16us/step - loss: 5.0395e-04 - val_loss: 3.8119e-04\n",
      "Epoch 31/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 6.8011e-0 - 0s 16us/step - loss: 4.9557e-04 - val_loss: 3.7331e-04\n",
      "Epoch 32/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 5.7410e-0 - 0s 16us/step - loss: 4.8692e-04 - val_loss: 3.6098e-04\n",
      "Epoch 33/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.8701e-0 - 0s 16us/step - loss: 4.8060e-04 - val_loss: 3.5256e-04\n",
      "Epoch 34/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.6296e-0 - 0s 15us/step - loss: 4.7377e-04 - val_loss: 3.4482e-04\n",
      "Epoch 35/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.3361e-0 - 0s 15us/step - loss: 4.7060e-04 - val_loss: 3.3985e-04\n",
      "Epoch 36/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.4555e-0 - 0s 16us/step - loss: 4.6716e-04 - val_loss: 3.3723e-04\n",
      "Epoch 37/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.1773e-0 - 0s 14us/step - loss: 4.6307e-04 - val_loss: 3.3351e-04\n",
      "Epoch 38/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.2930e-0 - 0s 15us/step - loss: 4.6083e-04 - val_loss: 3.2902e-04\n",
      "Epoch 39/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.2319e-0 - 0s 15us/step - loss: 4.5817e-04 - val_loss: 3.2676e-04\n",
      "Epoch 40/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.0392e-0 - 0s 14us/step - loss: 4.5643e-04 - val_loss: 3.2562e-04\n",
      "Epoch 41/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.8714e-0 - 0s 15us/step - loss: 4.5556e-04 - val_loss: 3.2527e-04\n",
      "Epoch 42/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.4286e-0 - 0s 15us/step - loss: 4.5479e-04 - val_loss: 3.2090e-04\n",
      "Epoch 43/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.5212e-0 - 0s 14us/step - loss: 4.5338e-04 - val_loss: 3.2137e-04\n",
      "Epoch 44/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.5292e-0 - 0s 14us/step - loss: 4.5319e-04 - val_loss: 3.2003e-04\n",
      "Epoch 45/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.0933e-0 - 0s 14us/step - loss: 4.5255e-04 - val_loss: 3.1974e-04\n",
      "Epoch 46/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.0263e-0 - 0s 14us/step - loss: 4.5242e-04 - val_loss: 3.1907e-04\n",
      "Epoch 47/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.5217e-0 - 0s 16us/step - loss: 4.5168e-04 - val_loss: 3.1859e-04\n",
      "Epoch 48/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.4205e-0 - 0s 15us/step - loss: 4.5110e-04 - val_loss: 3.1763e-04\n",
      "Epoch 49/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.7704e-0 - 0s 14us/step - loss: 4.5195e-04 - val_loss: 3.1768e-04\n",
      "Epoch 50/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 6.1112e-0 - 0s 15us/step - loss: 4.5113e-04 - val_loss: 3.1824e-04\n",
      "Epoch 51/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.1004e-0 - 0s 19us/step - loss: 4.5066e-04 - val_loss: 3.1646e-04\n",
      "Epoch 52/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.5854e-0 - 0s 16us/step - loss: 4.5027e-04 - val_loss: 3.1803e-04\n",
      "Epoch 53/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.4592e-0 - 0s 17us/step - loss: 4.5152e-04 - val_loss: 3.1549e-04\n",
      "Epoch 54/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 6.7111e-0 - 0s 16us/step - loss: 4.5053e-04 - val_loss: 3.1683e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 5.0226e-0 - 0s 15us/step - loss: 4.4949e-04 - val_loss: 3.1567e-04\n",
      "Epoch 56/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.8920e-0 - 0s 14us/step - loss: 4.5042e-04 - val_loss: 3.1992e-04\n",
      "Epoch 57/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 5.3401e-0 - 0s 15us/step - loss: 4.4955e-04 - val_loss: 3.1474e-04\n",
      "Epoch 58/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 6.0013e-0 - 0s 15us/step - loss: 4.5002e-04 - val_loss: 3.1478e-04\n",
      "Epoch 59/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.7781e-0 - 0s 14us/step - loss: 4.5007e-04 - val_loss: 3.1507e-04\n",
      "Epoch 60/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.3784e-0 - 0s 15us/step - loss: 4.4975e-04 - val_loss: 3.1625e-04\n",
      "Epoch 61/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 6.1759e-0 - 0s 15us/step - loss: 4.4834e-04 - val_loss: 3.1376e-04\n",
      "Epoch 62/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.0150e-0 - 0s 14us/step - loss: 4.4949e-04 - val_loss: 3.1473e-04\n",
      "Epoch 63/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 5.1562e-0 - 0s 15us/step - loss: 4.5102e-04 - val_loss: 3.1563e-04\n",
      "Epoch 64/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.0217e-0 - 0s 15us/step - loss: 4.5477e-04 - val_loss: 3.1302e-04\n",
      "Epoch 65/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 5.1237e-0 - 0s 15us/step - loss: 4.4945e-04 - val_loss: 3.1315e-04\n",
      "Epoch 66/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 6.2864e-0 - 0s 16us/step - loss: 4.4841e-04 - val_loss: 3.1765e-04\n",
      "Epoch 67/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 2.8390e-0 - 0s 14us/step - loss: 4.4929e-04 - val_loss: 3.1261e-04\n",
      "Epoch 68/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.4988e-0 - 0s 12us/step - loss: 4.4807e-04 - val_loss: 3.1371e-04\n",
      "Epoch 69/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.3039e-0 - 0s 12us/step - loss: 4.4834e-04 - val_loss: 3.1250e-04\n",
      "Epoch 70/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.4871e-0 - 0s 12us/step - loss: 4.4866e-04 - val_loss: 3.1236e-04\n",
      "Epoch 71/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.2543e-0 - 0s 16us/step - loss: 4.4866e-04 - val_loss: 3.1603e-04\n",
      "Epoch 72/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.5463e-0 - 0s 14us/step - loss: 4.4841e-04 - val_loss: 3.1110e-04\n",
      "Epoch 73/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.3195e-0 - 0s 21us/step - loss: 4.4741e-04 - val_loss: 3.1264e-04\n",
      "Epoch 74/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.4211e-0 - 0s 17us/step - loss: 4.4775e-04 - val_loss: 3.1166e-04\n",
      "Epoch 75/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.7765e-0 - 0s 15us/step - loss: 4.4714e-04 - val_loss: 3.1198e-04\n",
      "Epoch 76/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 5.6690e-0 - 0s 15us/step - loss: 4.4800e-04 - val_loss: 3.1272e-04\n",
      "Epoch 77/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.4048e-0 - 0s 15us/step - loss: 4.4815e-04 - val_loss: 3.1172e-04\n",
      "Epoch 78/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.3559e-0 - 0s 14us/step - loss: 4.4701e-04 - val_loss: 3.1262e-04\n",
      "Epoch 79/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.4466e-0 - 0s 14us/step - loss: 4.4688e-04 - val_loss: 3.1082e-04\n",
      "Epoch 80/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.8534e-0 - 0s 15us/step - loss: 4.4843e-04 - val_loss: 3.1168e-04\n",
      "Epoch 81/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.1731e-0 - 0s 19us/step - loss: 4.4669e-04 - val_loss: 3.1114e-04\n",
      "Epoch 82/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.6762e-0 - 0s 16us/step - loss: 4.4747e-04 - val_loss: 3.1059e-04\n",
      "Epoch 83/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.2313e-0 - 0s 15us/step - loss: 4.4637e-04 - val_loss: 3.1602e-04\n",
      "Epoch 84/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.7839e-0 - 0s 16us/step - loss: 4.4828e-04 - val_loss: 3.1095e-04\n",
      "Epoch 85/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 6.2021e-0 - 0s 15us/step - loss: 4.4702e-04 - val_loss: 3.1041e-04\n",
      "Epoch 86/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.0528e-0 - 0s 16us/step - loss: 4.4602e-04 - val_loss: 3.1018e-04\n",
      "Epoch 87/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.3079e-0 - 0s 15us/step - loss: 4.4552e-04 - val_loss: 3.1018e-04\n",
      "Epoch 88/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.0910e-0 - 0s 17us/step - loss: 4.4775e-04 - val_loss: 3.1298e-04\n",
      "Epoch 89/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 6.0095e-0 - 0s 14us/step - loss: 4.4969e-04 - val_loss: 3.1283e-04\n",
      "Epoch 90/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.2876e-0 - 0s 18us/step - loss: 4.4904e-04 - val_loss: 3.1000e-04\n",
      "Epoch 91/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.6097e-0 - 0s 16us/step - loss: 4.5054e-04 - val_loss: 3.0944e-04\n",
      "Epoch 92/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.9228e-0 - 0s 15us/step - loss: 4.4780e-04 - val_loss: 3.0956e-04\n",
      "Epoch 93/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.4656e-0 - 0s 19us/step - loss: 4.4581e-04 - val_loss: 3.0918e-04\n",
      "Epoch 94/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 5.3635e-0 - 0s 17us/step - loss: 4.4495e-04 - val_loss: 3.1031e-04\n",
      "Epoch 95/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.9667e-0 - 0s 16us/step - loss: 4.4704e-04 - val_loss: 3.1142e-04\n",
      "Epoch 96/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.8421e-0 - 0s 16us/step - loss: 4.4877e-04 - val_loss: 3.0905e-04\n",
      "Epoch 97/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.2740e-0 - 0s 16us/step - loss: 4.4779e-04 - val_loss: 3.1009e-04\n",
      "Epoch 98/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.1327e-0 - 0s 16us/step - loss: 4.4644e-04 - val_loss: 3.0759e-04\n",
      "Epoch 99/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.5535e-0 - 0s 16us/step - loss: 4.4444e-04 - val_loss: 3.1199e-04\n",
      "Epoch 100/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.3213e-0 - 0s 17us/step - loss: 4.4606e-04 - val_loss: 3.0773e-04\n",
      "Epoch 101/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.6952e-0 - 0s 16us/step - loss: 4.4519e-04 - val_loss: 3.0945e-04\n",
      "Epoch 102/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.6716e-0 - 0s 15us/step - loss: 4.4507e-04 - val_loss: 3.0923e-04\n",
      "Epoch 103/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.1426e-0 - 0s 15us/step - loss: 4.4469e-04 - val_loss: 3.0805e-04\n",
      "Epoch 104/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 2.8975e-0 - 0s 17us/step - loss: 4.4590e-04 - val_loss: 3.0864e-04\n",
      "Epoch 105/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.5586e-0 - 0s 18us/step - loss: 4.4647e-04 - val_loss: 3.1188e-04\n",
      "Epoch 106/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.8975e-0 - 0s 17us/step - loss: 4.4626e-04 - val_loss: 3.0902e-04\n",
      "Epoch 107/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.0266e-0 - 0s 21us/step - loss: 4.4529e-04 - val_loss: 3.0846e-04\n",
      "Epoch 108/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.4020e-0 - 0s 17us/step - loss: 4.4410e-04 - val_loss: 3.0835e-04\n",
      "Epoch 109/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.4790e-0 - 0s 17us/step - loss: 4.4535e-04 - val_loss: 3.0877e-04\n",
      "Epoch 110/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.4793e-0 - 0s 14us/step - loss: 4.4407e-04 - val_loss: 3.1645e-04\n",
      "Epoch 111/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.7562e-0 - 0s 14us/step - loss: 4.4778e-04 - val_loss: 3.1159e-04\n",
      "Epoch 112/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.8413e-0 - 0s 15us/step - loss: 4.4476e-04 - val_loss: 3.0815e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.0911e-0 - 0s 20us/step - loss: 4.4452e-04 - val_loss: 3.0774e-04\n",
      "Epoch 114/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.7252e-0 - 0s 16us/step - loss: 4.4652e-04 - val_loss: 3.0839e-04\n",
      "Epoch 115/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.2530e-0 - 0s 16us/step - loss: 4.4378e-04 - val_loss: 3.0790e-04\n",
      "Epoch 116/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.4228e-0 - 0s 16us/step - loss: 4.4300e-04 - val_loss: 3.0722e-04\n",
      "Epoch 117/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 5.1890e-0 - 0s 14us/step - loss: 4.4282e-04 - val_loss: 3.0802e-04\n",
      "Epoch 118/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 5.4918e-0 - 0s 14us/step - loss: 4.4388e-04 - val_loss: 3.0742e-04\n",
      "Epoch 119/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 6.8873e-0 - 0s 14us/step - loss: 4.4298e-04 - val_loss: 3.0952e-04\n",
      "Epoch 120/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.6326e-0 - 0s 14us/step - loss: 4.4333e-04 - val_loss: 3.0791e-04\n",
      "Epoch 121/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.6302e-0 - 0s 14us/step - loss: 4.4401e-04 - val_loss: 3.0832e-04\n",
      "Epoch 122/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.4116e-0 - 0s 14us/step - loss: 4.4278e-04 - val_loss: 3.0774e-04\n",
      "Epoch 123/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.2732e-0 - 0s 13us/step - loss: 4.4325e-04 - val_loss: 3.1111e-04\n",
      "Epoch 124/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.0589e-0 - 0s 13us/step - loss: 4.4292e-04 - val_loss: 3.1265e-04\n",
      "Epoch 125/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.8502e-0 - 0s 13us/step - loss: 4.4366e-04 - val_loss: 3.0834e-04\n",
      "Epoch 126/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 5.3410e-0 - 0s 13us/step - loss: 4.4335e-04 - val_loss: 3.0989e-04\n",
      "Epoch 127/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 5.2433e-0 - 0s 14us/step - loss: 4.4355e-04 - val_loss: 3.0645e-04\n",
      "Epoch 128/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.2746e-0 - 0s 13us/step - loss: 4.4126e-04 - val_loss: 3.0854e-04\n",
      "Epoch 129/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.5181e-0 - 0s 14us/step - loss: 4.4235e-04 - val_loss: 3.0676e-04\n",
      "Epoch 130/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.4944e-0 - 0s 14us/step - loss: 4.4248e-04 - val_loss: 3.0675e-04\n",
      "Epoch 131/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.0286e-0 - 0s 14us/step - loss: 4.4437e-04 - val_loss: 3.0663e-04\n",
      "Epoch 132/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 5.5331e-0 - 0s 13us/step - loss: 4.4416e-04 - val_loss: 3.0768e-04\n",
      "Epoch 133/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.5216e-0 - 0s 13us/step - loss: 4.4231e-04 - val_loss: 3.0763e-04\n",
      "Epoch 134/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 5.1510e-0 - 0s 15us/step - loss: 4.4120e-04 - val_loss: 3.0718e-04\n",
      "Epoch 135/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.1014e-0 - 0s 13us/step - loss: 4.4237e-04 - val_loss: 3.0644e-04\n",
      "Epoch 136/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 5.4924e-0 - 0s 17us/step - loss: 4.4157e-04 - val_loss: 3.0595e-04\n",
      "Epoch 137/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.9089e-0 - 0s 13us/step - loss: 4.4117e-04 - val_loss: 3.0735e-04\n",
      "Epoch 138/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 5.4172e-0 - 0s 14us/step - loss: 4.4138e-04 - val_loss: 3.0670e-04\n",
      "Epoch 139/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.1555e-0 - 0s 13us/step - loss: 4.4191e-04 - val_loss: 3.0886e-04\n",
      "Epoch 140/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.0984e-0 - 0s 14us/step - loss: 4.4264e-04 - val_loss: 3.0689e-04\n",
      "Epoch 141/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 2.7976e-0 - 0s 13us/step - loss: 4.4113e-04 - val_loss: 3.0802e-04\n",
      "Epoch 142/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 5.1569e-0 - 0s 12us/step - loss: 4.4201e-04 - val_loss: 3.0743e-04\n",
      "Epoch 143/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.6043e-0 - 0s 12us/step - loss: 4.4262e-04 - val_loss: 3.0742e-04\n",
      "Epoch 144/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.7218e-0 - 0s 13us/step - loss: 4.4118e-04 - val_loss: 3.0616e-04\n",
      "Epoch 145/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 5.4129e-0 - 0s 13us/step - loss: 4.4399e-04 - val_loss: 3.0547e-04\n",
      "Epoch 146/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.7668e-0 - 0s 12us/step - loss: 4.4114e-04 - val_loss: 3.0580e-04\n",
      "Epoch 147/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 5.8906e-0 - 0s 13us/step - loss: 4.4104e-04 - val_loss: 3.0492e-04\n",
      "Epoch 148/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.4715e-0 - 0s 13us/step - loss: 4.4009e-04 - val_loss: 3.0561e-04\n",
      "Epoch 149/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.4431e-0 - 0s 13us/step - loss: 4.3995e-04 - val_loss: 3.0445e-04\n",
      "Epoch 150/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 5.9727e-0 - 0s 13us/step - loss: 4.4204e-04 - val_loss: 3.1046e-04\n",
      "Epoch 151/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.1883e-0 - 0s 14us/step - loss: 4.4131e-04 - val_loss: 3.0738e-04\n",
      "Epoch 152/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.1459e-0 - 0s 15us/step - loss: 4.3997e-04 - val_loss: 3.0362e-04\n",
      "Epoch 153/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.6312e-0 - 0s 15us/step - loss: 4.3999e-04 - val_loss: 3.0863e-04\n",
      "Epoch 154/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 6.4161e-0 - 0s 14us/step - loss: 4.4135e-04 - val_loss: 3.0804e-04\n",
      "Epoch 155/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.6697e-0 - 0s 15us/step - loss: 4.3993e-04 - val_loss: 3.0574e-04\n",
      "Epoch 156/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.7744e-0 - 0s 14us/step - loss: 4.3886e-04 - val_loss: 3.0516e-04\n",
      "Epoch 157/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.3391e-0 - 0s 15us/step - loss: 4.3972e-04 - val_loss: 3.0412e-04\n",
      "Epoch 158/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 2.9966e-0 - 0s 15us/step - loss: 4.3863e-04 - val_loss: 3.0589e-04\n",
      "Epoch 159/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 5.0683e-0 - 0s 15us/step - loss: 4.3944e-04 - val_loss: 3.0430e-04\n",
      "Epoch 160/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 5.1480e-0 - 0s 17us/step - loss: 4.4061e-04 - val_loss: 3.0658e-04\n",
      "Epoch 161/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 5.0039e-0 - 0s 16us/step - loss: 4.3885e-04 - val_loss: 3.0522e-04\n",
      "Epoch 162/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.3987e-0 - 0s 20us/step - loss: 4.3787e-04 - val_loss: 3.0537e-04\n",
      "Epoch 163/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.5231e-0 - 0s 14us/step - loss: 4.3851e-04 - val_loss: 3.0575e-04\n",
      "Epoch 164/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.0792e-0 - 0s 15us/step - loss: 4.3915e-04 - val_loss: 3.0357e-04\n",
      "Epoch 165/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 5.4748e-0 - 0s 16us/step - loss: 4.4090e-04 - val_loss: 3.0811e-04\n",
      "Epoch 166/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.4580e-0 - 0s 15us/step - loss: 4.3763e-04 - val_loss: 3.0361e-04\n",
      "Epoch 167/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.3259e-0 - 0s 15us/step - loss: 4.3746e-04 - val_loss: 3.0597e-04\n",
      "Epoch 168/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 5.6284e-0 - 0s 20us/step - loss: 4.3984e-04 - val_loss: 3.0592e-04\n",
      "Epoch 169/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.1849e-0 - 0s 17us/step - loss: 4.3921e-04 - val_loss: 3.1242e-04\n",
      "Epoch 170/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2644/2644 [==============================] - ETA: 0s - loss: 5.7088e-0 - 0s 13us/step - loss: 4.4052e-04 - val_loss: 3.0523e-04\n",
      "Epoch 171/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.9846e-0 - 0s 18us/step - loss: 4.3787e-04 - val_loss: 3.0453e-04\n",
      "Epoch 172/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.1920e-0 - 0s 16us/step - loss: 4.3774e-04 - val_loss: 3.0531e-04\n",
      "Epoch 173/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.8203e-0 - 0s 13us/step - loss: 4.3719e-04 - val_loss: 3.0643e-04\n",
      "Epoch 174/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.5730e-0 - 0s 11us/step - loss: 4.3928e-04 - val_loss: 3.0456e-04\n",
      "Epoch 175/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.3830e-0 - 0s 17us/step - loss: 4.3718e-04 - val_loss: 3.0455e-04\n",
      "Epoch 176/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 5.3980e-0 - 0s 16us/step - loss: 4.3749e-04 - val_loss: 3.0444e-04\n",
      "Epoch 177/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.7108e-0 - 0s 16us/step - loss: 4.3687e-04 - val_loss: 3.0618e-04\n",
      "Epoch 178/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 2.8135e-0 - 0s 16us/step - loss: 4.3772e-04 - val_loss: 3.0333e-04\n",
      "Epoch 179/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.4900e-0 - 0s 16us/step - loss: 4.3809e-04 - val_loss: 3.0222e-04\n",
      "Epoch 180/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.9181e-0 - 0s 19us/step - loss: 4.3715e-04 - val_loss: 3.0391e-04\n",
      "Epoch 181/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 6.3765e-0 - 0s 16us/step - loss: 4.3653e-04 - val_loss: 3.0379e-04\n",
      "Epoch 182/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 6.1667e-0 - 0s 15us/step - loss: 4.3892e-04 - val_loss: 3.0583e-04\n",
      "Epoch 183/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 5.2169e-0 - 0s 16us/step - loss: 4.3624e-04 - val_loss: 3.0400e-04\n",
      "Epoch 184/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.5672e-0 - 0s 15us/step - loss: 4.3888e-04 - val_loss: 3.0823e-04\n",
      "Epoch 185/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 5.2068e-0 - 0s 16us/step - loss: 4.3800e-04 - val_loss: 3.0413e-04\n",
      "Epoch 186/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.0418e-0 - 0s 15us/step - loss: 4.3743e-04 - val_loss: 3.1787e-04\n",
      "Epoch 187/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.5764e-0 - 0s 16us/step - loss: 4.4341e-04 - val_loss: 3.0524e-04\n",
      "Epoch 188/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.5901e-0 - 0s 15us/step - loss: 4.3779e-04 - val_loss: 3.0632e-04\n",
      "Epoch 189/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 3.4124e-0 - 0s 15us/step - loss: 4.3949e-04 - val_loss: 3.0775e-04\n",
      "Epoch 190/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 5.8485e-0 - 0s 14us/step - loss: 4.4230e-04 - val_loss: 3.1188e-04\n",
      "Epoch 191/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 5.6894e-0 - 0s 15us/step - loss: 4.3860e-04 - val_loss: 3.0670e-04\n",
      "Epoch 192/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.7078e-0 - 0s 17us/step - loss: 4.3833e-04 - val_loss: 3.0274e-04\n",
      "Epoch 193/1000\n",
      "2644/2644 [==============================] - ETA: 0s - loss: 4.4931e-0 - 0s 15us/step - loss: 4.3762e-04 - val_loss: 3.0670e-04\n",
      "Epoch 00193: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a519880c88>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = data_raw.drop(columns=['code','amount','preclose','adj'])\n",
    "train_Aug = augFeatures(train)\n",
    "train_norm = normalize(train_Aug)\n",
    "# change the last day and next day \n",
    "X_train, Y_train = buildTrain(train_norm, 1, 5)\n",
    "X_train, Y_train = shuffle(X_train, Y_train)\n",
    "X_train, Y_train, X_val, Y_val = splitData(X_train, Y_train, 0.1)\n",
    "\n",
    "# from 2 dimmension to 3 dimension\n",
    "Y_train = Y_train[:,:,np.newaxis]\n",
    "Y_val = Y_val[:,:,np.newaxis]\n",
    "\n",
    "model = buildOneToManyModel(X_train.shape)\n",
    "callback = EarlyStopping(monitor=\"loss\", patience=10, verbose=1, mode=\"auto\")\n",
    "model.fit(X_train, Y_train, epochs=1000, batch_size=128, validation_data=(X_val, Y_val), callbacks=[callback])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多對多模型 (輸入與輸出相同長度)\n",
    "\n",
    "將return_sequences 設為True ，再用TimeDistributed(Dense(1)) 將輸出調整為(5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildManyToManyModel(shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(10, input_length=shape[1], input_dim=shape[2], return_sequences=True))\n",
    "    # output shape: (5, 1)\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將pastDay 以及futureDay 設為相同長度5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GuQiang\\AppData\\Local\\conda\\conda\\envs\\finance35\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\GuQiang\\AppData\\Local\\conda\\conda\\envs\\finance35\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(10, return_sequences=True, input_shape=(5, 9))`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 5, 10)             800       \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 5, 1)              11        \n",
      "=================================================================\n",
      "Total params: 811\n",
      "Trainable params: 811\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2640 samples, validate on 293 samples\n",
      "Epoch 1/1000\n",
      "2640/2640 [==============================] - ETA: 17s - loss: 0.06 - ETA: 0s - loss: 0.0498 - 1s 395us/step - loss: 0.0482 - val_loss: 0.0419\n",
      "Epoch 2/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 0.031 - ETA: 0s - loss: 0.032 - 0s 27us/step - loss: 0.0320 - val_loss: 0.0275\n",
      "Epoch 3/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 0.025 - ETA: 0s - loss: 0.021 - 0s 29us/step - loss: 0.0204 - val_loss: 0.0168\n",
      "Epoch 4/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 0.014 - ETA: 0s - loss: 0.012 - 0s 28us/step - loss: 0.0123 - val_loss: 0.0109\n",
      "Epoch 5/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 0.007 - ETA: 0s - loss: 0.008 - 0s 30us/step - loss: 0.0084 - val_loss: 0.0087\n",
      "Epoch 6/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 0.009 - ETA: 0s - loss: 0.007 - 0s 32us/step - loss: 0.0070 - val_loss: 0.0076\n",
      "Epoch 7/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.006 - 0s 31us/step - loss: 0.0063 - val_loss: 0.0068\n",
      "Epoch 8/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.005 - 0s 33us/step - loss: 0.0057 - val_loss: 0.0061\n",
      "Epoch 9/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.005 - 0s 29us/step - loss: 0.0052 - val_loss: 0.0056\n",
      "Epoch 10/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 0.005 - ETA: 0s - loss: 0.004 - 0s 29us/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 11/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 0.004 - ETA: 0s - loss: 0.004 - 0s 27us/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 12/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 0.004 - ETA: 0s - loss: 0.004 - 0s 27us/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 13/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 0.004 - ETA: 0s - loss: 0.003 - 0s 27us/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 14/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 0.003 - ETA: 0s - loss: 0.003 - 0s 26us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 15/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 0.003 - ETA: 0s - loss: 0.003 - 0s 26us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 16/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 0.003 - ETA: 0s - loss: 0.002 - 0s 27us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 17/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 0.002 - ETA: 0s - loss: 0.002 - 0s 28us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 18/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 0.002 - ETA: 0s - loss: 0.002 - 0s 28us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 19/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 0.002 - ETA: 0s - loss: 0.002 - 0s 28us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 20/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 0.001 - ETA: 0s - loss: 0.002 - 0s 28us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 21/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 0.001 - ETA: 0s - loss: 0.001 - 0s 27us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 22/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 0.001 - ETA: 0s - loss: 0.001 - 0s 27us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 23/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 0.001 - ETA: 0s - loss: 0.001 - 0s 30us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 24/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 0.002 - ETA: 0s - loss: 0.001 - 0s 28us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 25/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 0.002 - ETA: 0s - loss: 0.001 - 0s 28us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 26/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 0.001 - ETA: 0s - loss: 0.001 - 0s 30us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 27/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 0.001 - ETA: 0s - loss: 0.001 - 0s 31us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 28/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 0.001 - ETA: 0s - loss: 0.001 - 0s 30us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 29/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 0.001 - ETA: 0s - loss: 0.001 - 0s 27us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 30/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 0.001 - ETA: 0s - loss: 0.001 - 0s 28us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 31/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 0.001 - ETA: 0s - loss: 0.001 - 0s 27us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 32/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 0.001 - ETA: 0s - loss: 0.001 - 0s 28us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 33/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.5176e-0 - ETA: 0s - loss: 9.9695e-0 - 0s 27us/step - loss: 9.9979e-04 - val_loss: 0.0010\n",
      "Epoch 34/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 8.8822e-0 - ETA: 0s - loss: 9.9391e-0 - 0s 29us/step - loss: 9.7645e-04 - val_loss: 9.9428e-04\n",
      "Epoch 35/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 0.001 - ETA: 0s - loss: 9.5301e-0 - 0s 33us/step - loss: 9.5474e-04 - val_loss: 9.7398e-04\n",
      "Epoch 36/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 9.9710e-0 - ETA: 0s - loss: 9.2130e-0 - 0s 29us/step - loss: 9.3647e-04 - val_loss: 9.5237e-04\n",
      "Epoch 37/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.7900e-0 - ETA: 0s - loss: 9.3802e-0 - 0s 29us/step - loss: 9.2138e-04 - val_loss: 9.3809e-04\n",
      "Epoch 38/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 9.1712e-0 - ETA: 0s - loss: 9.1909e-0 - 0s 28us/step - loss: 9.0561e-04 - val_loss: 9.1926e-04\n",
      "Epoch 39/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 0.001 - ETA: 0s - loss: 8.6895e-0 - 0s 30us/step - loss: 8.9167e-04 - val_loss: 9.0894e-04\n",
      "Epoch 40/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 8.1864e-0 - ETA: 0s - loss: 8.9007e-0 - 0s 30us/step - loss: 8.7986e-04 - val_loss: 8.9335e-04\n",
      "Epoch 41/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 8.7723e-0 - ETA: 0s - loss: 8.7212e-0 - 0s 28us/step - loss: 8.6805e-04 - val_loss: 8.8311e-04\n",
      "Epoch 42/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 9.1558e-0 - ETA: 0s - loss: 8.4448e-0 - 0s 28us/step - loss: 8.5771e-04 - val_loss: 8.7024e-04\n",
      "Epoch 43/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 8.5265e-0 - ETA: 0s - loss: 8.6048e-0 - 0s 27us/step - loss: 8.4753e-04 - val_loss: 8.6320e-04\n",
      "Epoch 44/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 8.3831e-0 - ETA: 0s - loss: 8.5866e-0 - 0s 27us/step - loss: 8.4199e-04 - val_loss: 8.5461e-04\n",
      "Epoch 45/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.7630e-0 - ETA: 0s - loss: 8.2565e-0 - 0s 27us/step - loss: 8.3238e-04 - val_loss: 8.4536e-04\n",
      "Epoch 46/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.9148e-0 - ETA: 0s - loss: 8.4062e-0 - 0s 26us/step - loss: 8.2697e-04 - val_loss: 8.3710e-04\n",
      "Epoch 47/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.7259e-0 - ETA: 0s - loss: 8.3939e-0 - 0s 27us/step - loss: 8.2112e-04 - val_loss: 8.2906e-04\n",
      "Epoch 48/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2640/2640 [==============================] - ETA: 0s - loss: 6.9608e-0 - ETA: 0s - loss: 8.0318e-0 - 0s 29us/step - loss: 8.1100e-04 - val_loss: 8.2247e-04\n",
      "Epoch 49/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.1296e-0 - ETA: 0s - loss: 8.0051e-0 - 0s 26us/step - loss: 8.0467e-04 - val_loss: 8.1558e-04\n",
      "Epoch 50/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.8597e-0 - ETA: 0s - loss: 8.0393e-0 - 0s 27us/step - loss: 7.9973e-04 - val_loss: 8.1101e-04\n",
      "Epoch 51/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 8.2273e-0 - ETA: 0s - loss: 7.9029e-0 - 0s 27us/step - loss: 7.9261e-04 - val_loss: 8.0265e-04\n",
      "Epoch 52/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 9.5178e-0 - ETA: 0s - loss: 7.8065e-0 - 0s 27us/step - loss: 7.8728e-04 - val_loss: 7.9954e-04\n",
      "Epoch 53/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.5801e-0 - ETA: 0s - loss: 7.6372e-0 - 0s 28us/step - loss: 7.8289e-04 - val_loss: 7.9220e-04\n",
      "Epoch 54/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.1125e-0 - ETA: 0s - loss: 7.8208e-0 - 0s 27us/step - loss: 7.7763e-04 - val_loss: 7.8715e-04\n",
      "Epoch 55/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 8.0734e-0 - ETA: 0s - loss: 7.6065e-0 - 0s 28us/step - loss: 7.7285e-04 - val_loss: 7.8673e-04\n",
      "Epoch 56/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.4306e-0 - ETA: 0s - loss: 7.6630e-0 - 0s 27us/step - loss: 7.6933e-04 - val_loss: 7.7942e-04\n",
      "Epoch 57/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 8.5543e-0 - ETA: 0s - loss: 7.3957e-0 - 0s 31us/step - loss: 7.6480e-04 - val_loss: 7.7240e-04\n",
      "Epoch 58/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.6144e-0 - ETA: 0s - loss: 7.8033e-0 - 0s 27us/step - loss: 7.6145e-04 - val_loss: 7.7845e-04\n",
      "Epoch 59/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.6573e-0 - ETA: 0s - loss: 7.6433e-0 - 0s 27us/step - loss: 7.5815e-04 - val_loss: 7.6526e-04\n",
      "Epoch 60/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 8.8347e-0 - ETA: 0s - loss: 7.7391e-0 - 0s 28us/step - loss: 7.5311e-04 - val_loss: 7.6126e-04\n",
      "Epoch 61/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.8270e-0 - ETA: 0s - loss: 7.7786e-0 - 0s 29us/step - loss: 7.5002e-04 - val_loss: 7.5782e-04\n",
      "Epoch 62/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.4889e-0 - ETA: 0s - loss: 7.4476e-0 - 0s 27us/step - loss: 7.4741e-04 - val_loss: 7.6003e-04\n",
      "Epoch 63/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 8.9160e-0 - ETA: 0s - loss: 7.3266e-0 - 0s 27us/step - loss: 7.4374e-04 - val_loss: 7.5059e-04\n",
      "Epoch 64/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.8920e-0 - ETA: 0s - loss: 7.5992e-0 - 0s 31us/step - loss: 7.3927e-04 - val_loss: 7.4627e-04\n",
      "Epoch 65/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.8505e-0 - ETA: 0s - loss: 7.6190e-0 - 0s 28us/step - loss: 7.3705e-04 - val_loss: 7.4447e-04\n",
      "Epoch 66/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 8.5157e-0 - ETA: 0s - loss: 7.3485e-0 - 0s 26us/step - loss: 7.3691e-04 - val_loss: 7.4085e-04\n",
      "Epoch 67/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.4198e-0 - ETA: 0s - loss: 7.4157e-0 - 0s 26us/step - loss: 7.3347e-04 - val_loss: 7.3791e-04\n",
      "Epoch 68/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.7791e-0 - ETA: 0s - loss: 7.3519e-0 - 0s 27us/step - loss: 7.2884e-04 - val_loss: 7.3409e-04\n",
      "Epoch 69/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.0595e-0 - ETA: 0s - loss: 7.1668e-0 - 0s 26us/step - loss: 7.2643e-04 - val_loss: 7.3522e-04\n",
      "Epoch 70/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.2539e-0 - ETA: 0s - loss: 7.3547e-0 - 0s 26us/step - loss: 7.2404e-04 - val_loss: 7.3045e-04\n",
      "Epoch 71/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.7684e-0 - ETA: 0s - loss: 7.2883e-0 - 0s 26us/step - loss: 7.2162e-04 - val_loss: 7.2779e-04\n",
      "Epoch 72/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 8.6908e-0 - ETA: 0s - loss: 7.1575e-0 - 0s 26us/step - loss: 7.2010e-04 - val_loss: 7.2654e-04\n",
      "Epoch 73/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 0.001 - ETA: 0s - loss: 7.1546e-0 - 0s 26us/step - loss: 7.1770e-04 - val_loss: 7.2490e-04\n",
      "Epoch 74/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.1781e-0 - ETA: 0s - loss: 6.9546e-0 - 0s 28us/step - loss: 7.1560e-04 - val_loss: 7.2111e-04\n",
      "Epoch 75/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 8.0330e-0 - ETA: 0s - loss: 7.1217e-0 - 0s 26us/step - loss: 7.1421e-04 - val_loss: 7.1838e-04\n",
      "Epoch 76/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.4933e-0 - ETA: 0s - loss: 7.2917e-0 - 0s 26us/step - loss: 7.1462e-04 - val_loss: 7.1735e-04\n",
      "Epoch 77/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.2070e-0 - ETA: 0s - loss: 6.9107e-0 - 0s 27us/step - loss: 7.1088e-04 - val_loss: 7.1532e-04\n",
      "Epoch 78/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.8730e-0 - ETA: 0s - loss: 6.8894e-0 - 0s 28us/step - loss: 7.1070e-04 - val_loss: 7.1658e-04\n",
      "Epoch 79/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 8.5713e-0 - ETA: 0s - loss: 7.0811e-0 - 0s 28us/step - loss: 7.0585e-04 - val_loss: 7.1144e-04\n",
      "Epoch 80/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.9904e-0 - ETA: 0s - loss: 7.0534e-0 - 0s 28us/step - loss: 7.0642e-04 - val_loss: 7.1929e-04\n",
      "Epoch 81/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.4636e-0 - ETA: 0s - loss: 6.8334e-0 - 0s 27us/step - loss: 7.0423e-04 - val_loss: 7.0629e-04\n",
      "Epoch 82/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.9525e-0 - ETA: 0s - loss: 6.9875e-0 - 0s 27us/step - loss: 7.0244e-04 - val_loss: 7.0814e-04\n",
      "Epoch 83/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 9.6316e-0 - ETA: 0s - loss: 7.0890e-0 - 0s 27us/step - loss: 7.0092e-04 - val_loss: 7.0620e-04\n",
      "Epoch 84/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.0567e-0 - ETA: 0s - loss: 6.8178e-0 - 0s 28us/step - loss: 6.9872e-04 - val_loss: 7.0713e-04\n",
      "Epoch 85/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.0826e-0 - ETA: 0s - loss: 6.9362e-0 - 0s 26us/step - loss: 6.9741e-04 - val_loss: 7.0740e-04\n",
      "Epoch 86/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.9519e-0 - ETA: 0s - loss: 6.9322e-0 - 0s 29us/step - loss: 6.9793e-04 - val_loss: 7.0214e-04\n",
      "Epoch 87/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.5880e-0 - ETA: 0s - loss: 6.9657e-0 - 0s 28us/step - loss: 6.9508e-04 - val_loss: 7.0480e-04\n",
      "Epoch 88/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.5674e-0 - ETA: 0s - loss: 6.9599e-0 - 0s 27us/step - loss: 6.9618e-04 - val_loss: 7.0545e-04\n",
      "Epoch 89/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 8.3191e-0 - ETA: 0s - loss: 7.2120e-0 - 0s 27us/step - loss: 6.9735e-04 - val_loss: 6.9909e-04\n",
      "Epoch 90/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.3731e-0 - ETA: 0s - loss: 6.9992e-0 - 0s 27us/step - loss: 6.9324e-04 - val_loss: 6.9815e-04\n",
      "Epoch 91/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.7771e-0 - ETA: 0s - loss: 6.9104e-0 - 0s 29us/step - loss: 6.9133e-04 - val_loss: 6.9930e-04\n",
      "Epoch 92/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.4572e-0 - ETA: 0s - loss: 6.6904e-0 - 0s 28us/step - loss: 6.9075e-04 - val_loss: 6.9494e-04\n",
      "Epoch 93/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.4241e-0 - ETA: 0s - loss: 6.7635e-0 - 0s 28us/step - loss: 6.8920e-04 - val_loss: 6.9646e-04\n",
      "Epoch 94/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.8813e-0 - ETA: 0s - loss: 6.8530e-0 - 0s 28us/step - loss: 6.8771e-04 - val_loss: 6.9527e-04\n",
      "Epoch 95/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.2943e-0 - ETA: 0s - loss: 6.7577e-0 - 0s 27us/step - loss: 6.8695e-04 - val_loss: 6.9421e-04\n",
      "Epoch 96/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2640/2640 [==============================] - ETA: 0s - loss: 6.1441e-0 - ETA: 0s - loss: 6.7348e-0 - 0s 28us/step - loss: 6.8568e-04 - val_loss: 6.9519e-04\n",
      "Epoch 97/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.6144e-0 - ETA: 0s - loss: 6.9574e-0 - 0s 27us/step - loss: 6.8614e-04 - val_loss: 6.9174e-04\n",
      "Epoch 98/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.8923e-0 - ETA: 0s - loss: 6.7858e-0 - 0s 26us/step - loss: 6.8423e-04 - val_loss: 6.9230e-04\n",
      "Epoch 99/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.6761e-0 - ETA: 0s - loss: 6.9774e-0 - 0s 26us/step - loss: 6.8610e-04 - val_loss: 6.9178e-04\n",
      "Epoch 100/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 9.3960e-0 - ETA: 0s - loss: 7.1287e-0 - 0s 29us/step - loss: 6.8701e-04 - val_loss: 6.9279e-04\n",
      "Epoch 101/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.5278e-0 - ETA: 0s - loss: 6.6142e-0 - 0s 28us/step - loss: 6.8269e-04 - val_loss: 6.8979e-04\n",
      "Epoch 102/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 9.1887e-0 - ETA: 0s - loss: 6.9451e-0 - 0s 30us/step - loss: 6.8300e-04 - val_loss: 6.9190e-04\n",
      "Epoch 103/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.0684e-0 - ETA: 0s - loss: 6.7031e-0 - 0s 28us/step - loss: 6.8241e-04 - val_loss: 6.9129e-04\n",
      "Epoch 104/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.1812e-0 - ETA: 0s - loss: 6.6458e-0 - 0s 28us/step - loss: 6.8255e-04 - val_loss: 6.8875e-04\n",
      "Epoch 105/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.8996e-0 - ETA: 0s - loss: 6.7706e-0 - 0s 28us/step - loss: 6.7992e-04 - val_loss: 6.8965e-04\n",
      "Epoch 106/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.5460e-0 - ETA: 0s - loss: 6.5294e-0 - 0s 28us/step - loss: 6.8015e-04 - val_loss: 6.8691e-04\n",
      "Epoch 107/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.1832e-0 - ETA: 0s - loss: 6.8616e-0 - 0s 27us/step - loss: 6.7914e-04 - val_loss: 6.9001e-04\n",
      "Epoch 108/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.4838e-0 - ETA: 0s - loss: 6.7734e-0 - 0s 27us/step - loss: 6.8197e-04 - val_loss: 6.8569e-04\n",
      "Epoch 109/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 8.3907e-0 - ETA: 0s - loss: 6.4886e-0 - 0s 31us/step - loss: 6.8124e-04 - val_loss: 6.9922e-04\n",
      "Epoch 110/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.6915e-0 - ETA: 0s - loss: 6.8009e-0 - 0s 28us/step - loss: 6.7760e-04 - val_loss: 6.8792e-04\n",
      "Epoch 111/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 8.3401e-0 - ETA: 0s - loss: 6.6474e-0 - 0s 29us/step - loss: 6.7684e-04 - val_loss: 6.8839e-04\n",
      "Epoch 112/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.3927e-0 - ETA: 0s - loss: 6.8511e-0 - 0s 30us/step - loss: 6.7711e-04 - val_loss: 6.9210e-04\n",
      "Epoch 113/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 8.1403e-0 - ETA: 0s - loss: 6.8066e-0 - 0s 28us/step - loss: 6.7859e-04 - val_loss: 6.9165e-04\n",
      "Epoch 114/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.1386e-0 - ETA: 0s - loss: 6.7484e-0 - 0s 27us/step - loss: 6.7608e-04 - val_loss: 6.8287e-04\n",
      "Epoch 115/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.9016e-0 - ETA: 0s - loss: 6.2878e-0 - 0s 28us/step - loss: 6.7408e-04 - val_loss: 6.8759e-04\n",
      "Epoch 116/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.2837e-0 - ETA: 0s - loss: 6.6036e-0 - 0s 28us/step - loss: 6.7630e-04 - val_loss: 6.9612e-04\n",
      "Epoch 117/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.4429e-0 - ETA: 0s - loss: 6.9218e-0 - 0s 27us/step - loss: 6.7709e-04 - val_loss: 6.8350e-04\n",
      "Epoch 118/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.8534e-0 - ETA: 0s - loss: 6.7774e-0 - 0s 28us/step - loss: 6.7298e-04 - val_loss: 6.8381e-04\n",
      "Epoch 119/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.9132e-0 - ETA: 0s - loss: 6.5259e-0 - 0s 26us/step - loss: 6.7163e-04 - val_loss: 6.8760e-04\n",
      "Epoch 120/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.8842e-0 - ETA: 0s - loss: 6.7144e-0 - 0s 27us/step - loss: 6.7279e-04 - val_loss: 6.8711e-04\n",
      "Epoch 121/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 8.5515e-0 - ETA: 0s - loss: 6.6978e-0 - 0s 26us/step - loss: 6.7799e-04 - val_loss: 6.9533e-04\n",
      "Epoch 122/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 8.7271e-0 - ETA: 0s - loss: 6.3503e-0 - ETA: 0s - loss: 6.6961e-0 - 0s 45us/step - loss: 6.7077e-04 - val_loss: 6.8332e-04\n",
      "Epoch 123/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.7311e-0 - ETA: 0s - loss: 6.7839e-0 - 0s 33us/step - loss: 6.7026e-04 - val_loss: 6.8227e-04\n",
      "Epoch 124/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 3.6397e-0 - ETA: 0s - loss: 6.9027e-0 - 0s 35us/step - loss: 6.7015e-04 - val_loss: 6.8068e-04\n",
      "Epoch 125/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 8.0429e-0 - ETA: 0s - loss: 6.3950e-0 - 0s 33us/step - loss: 6.7320e-04 - val_loss: 6.9343e-04\n",
      "Epoch 126/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.0518e-0 - ETA: 0s - loss: 6.7719e-0 - 0s 34us/step - loss: 6.7284e-04 - val_loss: 6.8418e-04\n",
      "Epoch 127/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.8370e-0 - ETA: 0s - loss: 6.5336e-0 - 0s 32us/step - loss: 6.6996e-04 - val_loss: 6.8587e-04\n",
      "Epoch 128/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.2196e-0 - ETA: 0s - loss: 6.6676e-0 - 0s 34us/step - loss: 6.7166e-04 - val_loss: 6.8160e-04\n",
      "Epoch 129/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 8.7067e-0 - ETA: 0s - loss: 6.6717e-0 - 0s 36us/step - loss: 6.6895e-04 - val_loss: 6.8337e-04\n",
      "Epoch 130/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.1177e-0 - ETA: 0s - loss: 6.5480e-0 - 0s 32us/step - loss: 6.6994e-04 - val_loss: 6.8304e-04\n",
      "Epoch 131/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.8611e-0 - ETA: 0s - loss: 6.7856e-0 - 0s 29us/step - loss: 6.6986e-04 - val_loss: 6.8223e-04\n",
      "Epoch 132/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.8960e-0 - ETA: 0s - loss: 6.7586e-0 - 0s 35us/step - loss: 6.6785e-04 - val_loss: 6.8063e-04\n",
      "Epoch 133/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 8.0877e-0 - ETA: 0s - loss: 6.5416e-0 - 0s 34us/step - loss: 6.6762e-04 - val_loss: 6.8231e-04\n",
      "Epoch 134/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.5292e-0 - ETA: 0s - loss: 6.6776e-0 - 0s 35us/step - loss: 6.6613e-04 - val_loss: 6.8200e-04\n",
      "Epoch 135/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.2646e-0 - ETA: 0s - loss: 6.6629e-0 - 0s 31us/step - loss: 6.6669e-04 - val_loss: 6.8053e-04\n",
      "Epoch 136/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.1143e-0 - ETA: 0s - loss: 6.5427e-0 - 0s 31us/step - loss: 6.6846e-04 - val_loss: 6.8393e-04\n",
      "Epoch 137/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.5848e-0 - ETA: 0s - loss: 6.7243e-0 - 0s 30us/step - loss: 6.6741e-04 - val_loss: 6.8149e-04\n",
      "Epoch 138/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.1726e-0 - ETA: 0s - loss: 6.6297e-0 - 0s 30us/step - loss: 6.6776e-04 - val_loss: 6.8453e-04\n",
      "Epoch 139/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.7936e-0 - ETA: 0s - loss: 6.9042e-0 - 0s 29us/step - loss: 6.6682e-04 - val_loss: 6.8024e-04\n",
      "Epoch 140/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.9580e-0 - ETA: 0s - loss: 6.7349e-0 - 0s 28us/step - loss: 6.6555e-04 - val_loss: 6.8131e-04\n",
      "Epoch 141/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.7703e-0 - ETA: 0s - loss: 6.5968e-0 - 0s 28us/step - loss: 6.6610e-04 - val_loss: 6.7826e-04\n",
      "Epoch 142/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.4700e-0 - ETA: 0s - loss: 6.6025e-0 - 0s 28us/step - loss: 6.6803e-04 - val_loss: 6.8727e-04\n",
      "Epoch 143/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 8.1146e-0 - ETA: 0s - loss: 6.8181e-0 - 0s 29us/step - loss: 6.6705e-04 - val_loss: 6.8671e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.4550e-0 - ETA: 0s - loss: 6.7259e-0 - 0s 29us/step - loss: 6.6659e-04 - val_loss: 6.7762e-04\n",
      "Epoch 145/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.7537e-0 - ETA: 0s - loss: 6.7986e-0 - 0s 28us/step - loss: 6.6520e-04 - val_loss: 6.8166e-04\n",
      "Epoch 146/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.1694e-0 - ETA: 0s - loss: 6.7533e-0 - 0s 29us/step - loss: 6.6528e-04 - val_loss: 6.7840e-04\n",
      "Epoch 147/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.7428e-0 - ETA: 0s - loss: 6.7299e-0 - 0s 27us/step - loss: 6.6641e-04 - val_loss: 6.8948e-04\n",
      "Epoch 148/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.3013e-0 - ETA: 0s - loss: 6.5591e-0 - 0s 29us/step - loss: 6.6466e-04 - val_loss: 6.7857e-04\n",
      "Epoch 149/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 8.0610e-0 - ETA: 0s - loss: 6.8733e-0 - 0s 30us/step - loss: 6.6633e-04 - val_loss: 6.8052e-04\n",
      "Epoch 150/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.4922e-0 - ETA: 0s - loss: 6.5090e-0 - 0s 33us/step - loss: 6.6401e-04 - val_loss: 7.0666e-04\n",
      "Epoch 151/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.8865e-0 - ETA: 0s - loss: 6.7361e-0 - 0s 32us/step - loss: 6.7358e-04 - val_loss: 6.7991e-04\n",
      "Epoch 152/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.9312e-0 - ETA: 0s - loss: 6.3881e-0 - 0s 31us/step - loss: 6.6201e-04 - val_loss: 6.7710e-04\n",
      "Epoch 153/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.7610e-0 - ETA: 0s - loss: 6.5058e-0 - 0s 30us/step - loss: 6.6059e-04 - val_loss: 6.7977e-04\n",
      "Epoch 154/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.4024e-0 - ETA: 0s - loss: 6.5307e-0 - 0s 29us/step - loss: 6.6633e-04 - val_loss: 6.7696e-04\n",
      "Epoch 155/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.8326e-0 - ETA: 0s - loss: 6.6759e-0 - 0s 29us/step - loss: 6.5980e-04 - val_loss: 6.8772e-04\n",
      "Epoch 156/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.7753e-0 - ETA: 0s - loss: 6.7608e-0 - 0s 30us/step - loss: 6.6126e-04 - val_loss: 6.7998e-04\n",
      "Epoch 157/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.7896e-0 - ETA: 0s - loss: 6.3003e-0 - 0s 28us/step - loss: 6.6012e-04 - val_loss: 6.7542e-04\n",
      "Epoch 158/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.4078e-0 - ETA: 0s - loss: 6.5638e-0 - 0s 35us/step - loss: 6.5961e-04 - val_loss: 6.8209e-04\n",
      "Epoch 159/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.6844e-0 - ETA: 0s - loss: 6.3186e-0 - 0s 33us/step - loss: 6.6068e-04 - val_loss: 6.7642e-04\n",
      "Epoch 160/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.0431e-0 - ETA: 0s - loss: 6.6121e-0 - 0s 31us/step - loss: 6.5801e-04 - val_loss: 6.8646e-04\n",
      "Epoch 161/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.7417e-0 - ETA: 0s - loss: 6.6398e-0 - 0s 30us/step - loss: 6.6038e-04 - val_loss: 6.7528e-04\n",
      "Epoch 162/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.0051e-0 - ETA: 0s - loss: 6.7803e-0 - 0s 30us/step - loss: 6.6426e-04 - val_loss: 6.8387e-04\n",
      "Epoch 163/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 8.5633e-0 - ETA: 0s - loss: 6.6698e-0 - 0s 29us/step - loss: 6.5769e-04 - val_loss: 6.7698e-04\n",
      "Epoch 164/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.8495e-0 - ETA: 0s - loss: 6.8436e-0 - 0s 28us/step - loss: 6.5643e-04 - val_loss: 6.7540e-04\n",
      "Epoch 165/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.9074e-0 - ETA: 0s - loss: 6.3123e-0 - 0s 33us/step - loss: 6.5673e-04 - val_loss: 6.7956e-04\n",
      "Epoch 166/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 8.6471e-0 - ETA: 0s - loss: 6.7130e-0 - 0s 30us/step - loss: 6.5690e-04 - val_loss: 6.7566e-04\n",
      "Epoch 167/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.2341e-0 - ETA: 0s - loss: 6.6329e-0 - 0s 33us/step - loss: 6.5708e-04 - val_loss: 6.7580e-04\n",
      "Epoch 168/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.6650e-0 - ETA: 0s - loss: 6.5036e-0 - 0s 35us/step - loss: 6.5818e-04 - val_loss: 6.8044e-04\n",
      "Epoch 169/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 8.7029e-0 - ETA: 0s - loss: 6.5816e-0 - 0s 35us/step - loss: 6.5928e-04 - val_loss: 6.8304e-04\n",
      "Epoch 170/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.1604e-0 - ETA: 0s - loss: 6.3183e-0 - 0s 31us/step - loss: 6.5848e-04 - val_loss: 6.7890e-04\n",
      "Epoch 171/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.4235e-0 - ETA: 0s - loss: 6.6064e-0 - 0s 28us/step - loss: 6.5459e-04 - val_loss: 6.7558e-04\n",
      "Epoch 172/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.0731e-0 - ETA: 0s - loss: 6.5807e-0 - 0s 29us/step - loss: 6.5573e-04 - val_loss: 6.7928e-04\n",
      "Epoch 173/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.6157e-0 - ETA: 0s - loss: 6.4570e-0 - 0s 30us/step - loss: 6.5401e-04 - val_loss: 6.7527e-04\n",
      "Epoch 174/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.6079e-0 - ETA: 0s - loss: 6.4144e-0 - 0s 30us/step - loss: 6.5559e-04 - val_loss: 6.8678e-04\n",
      "Epoch 175/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.2912e-0 - ETA: 0s - loss: 6.6781e-0 - 0s 29us/step - loss: 6.5458e-04 - val_loss: 6.7646e-04\n",
      "Epoch 176/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.3085e-0 - ETA: 0s - loss: 6.4811e-0 - 0s 28us/step - loss: 6.5690e-04 - val_loss: 6.8201e-04\n",
      "Epoch 177/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.2134e-0 - ETA: 0s - loss: 6.7083e-0 - 0s 27us/step - loss: 6.5339e-04 - val_loss: 6.8098e-04\n",
      "Epoch 178/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.7632e-0 - ETA: 0s - loss: 6.5357e-0 - 0s 30us/step - loss: 6.5678e-04 - val_loss: 6.7818e-04\n",
      "Epoch 179/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.5306e-0 - ETA: 0s - loss: 6.4147e-0 - 0s 31us/step - loss: 6.5722e-04 - val_loss: 6.7553e-04\n",
      "Epoch 180/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.3428e-0 - ETA: 0s - loss: 6.3397e-0 - 0s 32us/step - loss: 6.5324e-04 - val_loss: 6.7856e-04\n",
      "Epoch 181/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.6316e-0 - ETA: 0s - loss: 6.6651e-0 - 0s 33us/step - loss: 6.5170e-04 - val_loss: 6.7769e-04\n",
      "Epoch 182/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.5191e-0 - ETA: 0s - loss: 6.6201e-0 - 0s 30us/step - loss: 6.5126e-04 - val_loss: 6.7759e-04\n",
      "Epoch 183/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.1572e-0 - ETA: 0s - loss: 6.4036e-0 - 0s 31us/step - loss: 6.5207e-04 - val_loss: 6.8012e-04\n",
      "Epoch 184/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 8.0427e-0 - ETA: 0s - loss: 6.4855e-0 - 0s 31us/step - loss: 6.4863e-04 - val_loss: 6.7467e-04\n",
      "Epoch 185/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.4517e-0 - ETA: 0s - loss: 6.3617e-0 - 0s 30us/step - loss: 6.5373e-04 - val_loss: 6.8353e-04\n",
      "Epoch 186/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.2564e-0 - ETA: 0s - loss: 5.8194e-0 - 0s 36us/step - loss: 6.4870e-04 - val_loss: 6.8041e-04\n",
      "Epoch 187/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.9345e-0 - ETA: 0s - loss: 6.2538e-0 - 0s 32us/step - loss: 6.5005e-04 - val_loss: 6.8882e-04\n",
      "Epoch 188/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.6868e-0 - ETA: 0s - loss: 6.6805e-0 - 0s 33us/step - loss: 6.5155e-04 - val_loss: 6.7450e-04\n",
      "Epoch 189/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.0023e-0 - ETA: 0s - loss: 6.3549e-0 - 0s 34us/step - loss: 6.5185e-04 - val_loss: 6.7266e-04\n",
      "Epoch 190/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.4226e-0 - ETA: 0s - loss: 6.6230e-0 - 0s 31us/step - loss: 6.4824e-04 - val_loss: 6.7545e-04\n",
      "Epoch 191/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.4600e-0 - ETA: 0s - loss: 6.2844e-0 - 0s 32us/step - loss: 6.4721e-04 - val_loss: 6.8019e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.3990e-0 - ETA: 0s - loss: 6.5401e-0 - 0s 36us/step - loss: 6.5194e-04 - val_loss: 6.7322e-04\n",
      "Epoch 193/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 8.8303e-0 - ETA: 0s - loss: 6.6631e-0 - 0s 32us/step - loss: 6.4852e-04 - val_loss: 6.7650e-04\n",
      "Epoch 194/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.3133e-0 - ETA: 0s - loss: 6.3406e-0 - 0s 35us/step - loss: 6.4951e-04 - val_loss: 6.7169e-04\n",
      "Epoch 195/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.9975e-0 - ETA: 0s - loss: 6.3082e-0 - 0s 32us/step - loss: 6.4628e-04 - val_loss: 6.7256e-04\n",
      "Epoch 196/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.9714e-0 - ETA: 0s - loss: 6.4605e-0 - 0s 37us/step - loss: 6.4441e-04 - val_loss: 6.7205e-04\n",
      "Epoch 197/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.6785e-0 - ETA: 0s - loss: 6.5175e-0 - 0s 31us/step - loss: 6.4647e-04 - val_loss: 6.8696e-04\n",
      "Epoch 198/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.3347e-0 - ETA: 0s - loss: 6.5781e-0 - 0s 29us/step - loss: 6.4372e-04 - val_loss: 6.7222e-04\n",
      "Epoch 199/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.2418e-0 - ETA: 0s - loss: 6.2918e-0 - 0s 35us/step - loss: 6.4487e-04 - val_loss: 6.7182e-04\n",
      "Epoch 200/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.9385e-0 - ETA: 0s - loss: 6.6500e-0 - 0s 32us/step - loss: 6.4366e-04 - val_loss: 6.8218e-04\n",
      "Epoch 201/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.7478e-0 - ETA: 0s - loss: 6.4686e-0 - 0s 34us/step - loss: 6.4608e-04 - val_loss: 6.7274e-04\n",
      "Epoch 202/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.2008e-0 - ETA: 0s - loss: 6.4432e-0 - 0s 39us/step - loss: 6.4321e-04 - val_loss: 6.7406e-04\n",
      "Epoch 203/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.8194e-0 - ETA: 0s - loss: 6.4123e-0 - 0s 38us/step - loss: 6.4335e-04 - val_loss: 6.7165e-04\n",
      "Epoch 204/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.5724e-0 - ETA: 0s - loss: 6.3635e-0 - 0s 31us/step - loss: 6.4859e-04 - val_loss: 6.9375e-04\n",
      "Epoch 205/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.0789e-0 - ETA: 0s - loss: 6.3857e-0 - 0s 31us/step - loss: 6.4249e-04 - val_loss: 6.7335e-04\n",
      "Epoch 206/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.1467e-0 - ETA: 0s - loss: 6.1044e-0 - 0s 32us/step - loss: 6.4124e-04 - val_loss: 6.7538e-04\n",
      "Epoch 207/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 9.7893e-0 - ETA: 0s - loss: 6.6317e-0 - 0s 32us/step - loss: 6.3878e-04 - val_loss: 6.7379e-04\n",
      "Epoch 208/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.4596e-0 - ETA: 0s - loss: 6.5008e-0 - 0s 32us/step - loss: 6.3990e-04 - val_loss: 6.7404e-04\n",
      "Epoch 209/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.6662e-0 - ETA: 0s - loss: 6.3417e-0 - 0s 30us/step - loss: 6.4012e-04 - val_loss: 6.7509e-04\n",
      "Epoch 210/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.3973e-0 - ETA: 0s - loss: 6.5440e-0 - 0s 30us/step - loss: 6.4310e-04 - val_loss: 6.7220e-04\n",
      "Epoch 211/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.1121e-0 - ETA: 0s - loss: 6.1564e-0 - 0s 30us/step - loss: 6.3920e-04 - val_loss: 6.7735e-04\n",
      "Epoch 212/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.3985e-0 - ETA: 0s - loss: 6.5386e-0 - 0s 34us/step - loss: 6.4150e-04 - val_loss: 6.7345e-04\n",
      "Epoch 213/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 8.5119e-0 - ETA: 0s - loss: 6.5491e-0 - 0s 34us/step - loss: 6.3925e-04 - val_loss: 6.7527e-04\n",
      "Epoch 214/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.7893e-0 - ETA: 0s - loss: 5.9900e-0 - 0s 33us/step - loss: 6.3898e-04 - val_loss: 6.8061e-04\n",
      "Epoch 215/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.9287e-0 - ETA: 0s - loss: 6.3998e-0 - 0s 33us/step - loss: 6.3533e-04 - val_loss: 6.7777e-04\n",
      "Epoch 216/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.1079e-0 - ETA: 0s - loss: 6.2509e-0 - 0s 42us/step - loss: 6.3772e-04 - val_loss: 6.7602e-04\n",
      "Epoch 217/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.6220e-0 - ETA: 0s - loss: 6.8445e-0 - 0s 38us/step - loss: 6.4180e-04 - val_loss: 6.8126e-04\n",
      "Epoch 218/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.0013e-0 - ETA: 0s - loss: 6.4412e-0 - 0s 32us/step - loss: 6.4232e-04 - val_loss: 6.8474e-04\n",
      "Epoch 219/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.4753e-0 - ETA: 0s - loss: 6.3310e-0 - 0s 36us/step - loss: 6.4372e-04 - val_loss: 6.8690e-04\n",
      "Epoch 220/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.1594e-0 - ETA: 0s - loss: 5.9798e-0 - 0s 32us/step - loss: 6.4157e-04 - val_loss: 7.0069e-04\n",
      "Epoch 221/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 8.3404e-0 - ETA: 0s - loss: 6.3562e-0 - 0s 33us/step - loss: 6.3637e-04 - val_loss: 6.7709e-04\n",
      "Epoch 222/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.5466e-0 - ETA: 0s - loss: 6.7087e-0 - 0s 34us/step - loss: 6.4709e-04 - val_loss: 6.7649e-04\n",
      "Epoch 223/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.8918e-0 - ETA: 0s - loss: 6.6091e-0 - 0s 34us/step - loss: 6.5223e-04 - val_loss: 6.9047e-04\n",
      "Epoch 224/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.2185e-0 - ETA: 0s - loss: 5.8722e-0 - 0s 38us/step - loss: 6.3756e-04 - val_loss: 6.7388e-04\n",
      "Epoch 225/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.6682e-0 - ETA: 0s - loss: 6.4593e-0 - 0s 34us/step - loss: 6.3455e-04 - val_loss: 6.7487e-04\n",
      "Epoch 226/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.8758e-0 - ETA: 0s - loss: 6.5559e-0 - 0s 31us/step - loss: 6.3647e-04 - val_loss: 6.7273e-04\n",
      "Epoch 227/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.1192e-0 - ETA: 0s - loss: 6.1093e-0 - 0s 35us/step - loss: 6.3217e-04 - val_loss: 6.7840e-04\n",
      "Epoch 228/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.3131e-0 - ETA: 0s - loss: 6.2874e-0 - 0s 34us/step - loss: 6.3932e-04 - val_loss: 6.7170e-04\n",
      "Epoch 229/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.0595e-0 - ETA: 0s - loss: 6.3798e-0 - 0s 32us/step - loss: 6.3638e-04 - val_loss: 6.7300e-04\n",
      "Epoch 230/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.0083e-0 - ETA: 0s - loss: 6.3208e-0 - 0s 33us/step - loss: 6.3680e-04 - val_loss: 6.7416e-04\n",
      "Epoch 231/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.9881e-0 - ETA: 0s - loss: 6.3190e-0 - 0s 34us/step - loss: 6.3106e-04 - val_loss: 6.7584e-04\n",
      "Epoch 232/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.0637e-0 - ETA: 0s - loss: 6.3034e-0 - 0s 30us/step - loss: 6.3021e-04 - val_loss: 6.7663e-04\n",
      "Epoch 233/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.0898e-0 - ETA: 0s - loss: 6.1980e-0 - 0s 33us/step - loss: 6.3849e-04 - val_loss: 6.7841e-04\n",
      "Epoch 234/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.1023e-0 - ETA: 0s - loss: 6.4551e-0 - 0s 36us/step - loss: 6.2997e-04 - val_loss: 6.7841e-04\n",
      "Epoch 235/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.5113e-0 - ETA: 0s - loss: 6.0933e-0 - 0s 33us/step - loss: 6.3669e-04 - val_loss: 6.7264e-04\n",
      "Epoch 236/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.1992e-0 - ETA: 0s - loss: 6.3977e-0 - 0s 34us/step - loss: 6.3302e-04 - val_loss: 6.8181e-04\n",
      "Epoch 237/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.0394e-0 - ETA: 0s - loss: 6.2342e-0 - 0s 31us/step - loss: 6.2886e-04 - val_loss: 6.7213e-04\n",
      "Epoch 238/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.6053e-0 - ETA: 0s - loss: 6.1064e-0 - 0s 32us/step - loss: 6.3128e-04 - val_loss: 6.7248e-04\n",
      "Epoch 239/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.7045e-0 - ETA: 0s - loss: 6.4581e-0 - 0s 34us/step - loss: 6.3163e-04 - val_loss: 6.8611e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 8.2608e-0 - ETA: 0s - loss: 6.5004e-0 - 0s 31us/step - loss: 6.3004e-04 - val_loss: 6.7441e-04\n",
      "Epoch 241/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.1017e-0 - ETA: 0s - loss: 6.2367e-0 - 0s 32us/step - loss: 6.2864e-04 - val_loss: 6.7393e-04\n",
      "Epoch 242/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.2484e-0 - ETA: 0s - loss: 6.3586e-0 - 0s 33us/step - loss: 6.3254e-04 - val_loss: 6.7186e-04\n",
      "Epoch 243/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.6271e-0 - ETA: 0s - loss: 6.2214e-0 - 0s 31us/step - loss: 6.3222e-04 - val_loss: 6.7523e-04\n",
      "Epoch 244/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.3694e-0 - ETA: 0s - loss: 6.2123e-0 - 0s 33us/step - loss: 6.3031e-04 - val_loss: 6.7776e-04\n",
      "Epoch 245/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.0944e-0 - ETA: 0s - loss: 6.3853e-0 - 0s 33us/step - loss: 6.3429e-04 - val_loss: 6.8625e-04\n",
      "Epoch 246/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.9206e-0 - ETA: 0s - loss: 6.2706e-0 - 0s 30us/step - loss: 6.3280e-04 - val_loss: 6.7299e-04\n",
      "Epoch 247/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.8646e-0 - ETA: 0s - loss: 6.2219e-0 - 0s 30us/step - loss: 6.2711e-04 - val_loss: 6.7053e-04\n",
      "Epoch 248/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 8.3563e-0 - ETA: 0s - loss: 6.2714e-0 - 0s 30us/step - loss: 6.2601e-04 - val_loss: 6.7114e-04\n",
      "Epoch 249/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.0518e-0 - ETA: 0s - loss: 6.4221e-0 - 0s 31us/step - loss: 6.2855e-04 - val_loss: 6.6933e-04\n",
      "Epoch 250/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.2909e-0 - ETA: 0s - loss: 6.0196e-0 - 0s 31us/step - loss: 6.2674e-04 - val_loss: 6.7223e-04\n",
      "Epoch 251/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.3683e-0 - ETA: 0s - loss: 6.0826e-0 - 0s 31us/step - loss: 6.2668e-04 - val_loss: 6.7262e-04\n",
      "Epoch 252/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.3586e-0 - ETA: 0s - loss: 5.8832e-0 - 0s 32us/step - loss: 6.2482e-04 - val_loss: 6.8880e-04\n",
      "Epoch 253/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.0548e-0 - ETA: 0s - loss: 6.3991e-0 - 0s 33us/step - loss: 6.2769e-04 - val_loss: 6.7271e-04\n",
      "Epoch 254/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.8867e-0 - ETA: 0s - loss: 5.9639e-0 - 0s 31us/step - loss: 6.2378e-04 - val_loss: 6.7298e-04\n",
      "Epoch 255/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 9.4383e-0 - ETA: 0s - loss: 6.2696e-0 - 0s 34us/step - loss: 6.2657e-04 - val_loss: 6.7208e-04\n",
      "Epoch 256/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.3242e-0 - ETA: 0s - loss: 6.0659e-0 - 0s 35us/step - loss: 6.3026e-04 - val_loss: 6.7225e-04\n",
      "Epoch 257/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.9196e-0 - ETA: 0s - loss: 6.1510e-0 - 0s 31us/step - loss: 6.2465e-04 - val_loss: 6.6812e-04\n",
      "Epoch 258/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.4883e-0 - ETA: 0s - loss: 6.4485e-0 - 0s 31us/step - loss: 6.2632e-04 - val_loss: 6.7059e-04\n",
      "Epoch 259/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.9657e-0 - ETA: 0s - loss: 6.4589e-0 - 0s 32us/step - loss: 6.2833e-04 - val_loss: 6.8639e-04\n",
      "Epoch 260/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 3.6129e-0 - ETA: 0s - loss: 6.0544e-0 - 0s 31us/step - loss: 6.2548e-04 - val_loss: 6.7420e-04\n",
      "Epoch 261/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.5443e-0 - ETA: 0s - loss: 6.2291e-0 - 0s 33us/step - loss: 6.2616e-04 - val_loss: 6.7108e-04\n",
      "Epoch 262/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.1845e-0 - ETA: 0s - loss: 6.1058e-0 - 0s 31us/step - loss: 6.2796e-04 - val_loss: 6.7132e-04\n",
      "Epoch 263/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 8.2309e-0 - ETA: 0s - loss: 6.3806e-0 - 0s 31us/step - loss: 6.2224e-04 - val_loss: 6.7042e-04\n",
      "Epoch 264/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 9.3381e-0 - ETA: 0s - loss: 6.0669e-0 - 0s 32us/step - loss: 6.2120e-04 - val_loss: 6.6954e-04\n",
      "Epoch 265/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.2712e-0 - ETA: 0s - loss: 6.1486e-0 - 0s 32us/step - loss: 6.2078e-04 - val_loss: 6.7642e-04\n",
      "Epoch 266/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 8.3315e-0 - ETA: 0s - loss: 6.1925e-0 - 0s 32us/step - loss: 6.2622e-04 - val_loss: 6.6754e-04\n",
      "Epoch 267/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 8.7108e-0 - ETA: 0s - loss: 6.3084e-0 - 0s 34us/step - loss: 6.2828e-04 - val_loss: 6.6777e-04\n",
      "Epoch 268/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.4740e-0 - ETA: 0s - loss: 6.5507e-0 - 0s 30us/step - loss: 6.2669e-04 - val_loss: 6.6832e-04\n",
      "Epoch 269/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.2519e-0 - ETA: 0s - loss: 6.2377e-0 - 0s 31us/step - loss: 6.2135e-04 - val_loss: 6.6761e-04\n",
      "Epoch 270/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.8223e-0 - ETA: 0s - loss: 6.1826e-0 - 0s 31us/step - loss: 6.2215e-04 - val_loss: 6.7743e-04\n",
      "Epoch 271/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.7576e-0 - ETA: 0s - loss: 6.4288e-0 - 0s 31us/step - loss: 6.3580e-04 - val_loss: 6.7522e-04\n",
      "Epoch 272/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.8811e-0 - ETA: 0s - loss: 6.5472e-0 - 0s 31us/step - loss: 6.2415e-04 - val_loss: 6.7061e-04\n",
      "Epoch 273/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.7237e-0 - ETA: 0s - loss: 6.3859e-0 - 0s 30us/step - loss: 6.2184e-04 - val_loss: 6.6745e-04\n",
      "Epoch 274/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.4472e-0 - ETA: 0s - loss: 6.1240e-0 - 0s 29us/step - loss: 6.1926e-04 - val_loss: 6.7212e-04\n",
      "Epoch 275/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.3332e-0 - ETA: 0s - loss: 6.0522e-0 - 0s 31us/step - loss: 6.2061e-04 - val_loss: 6.6703e-04\n",
      "Epoch 276/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.3838e-0 - ETA: 0s - loss: 6.0989e-0 - 0s 32us/step - loss: 6.1989e-04 - val_loss: 6.6564e-04\n",
      "Epoch 277/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.9833e-0 - ETA: 0s - loss: 6.2324e-0 - 0s 32us/step - loss: 6.2098e-04 - val_loss: 6.7048e-04\n",
      "Epoch 278/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.8206e-0 - ETA: 0s - loss: 6.3440e-0 - 0s 31us/step - loss: 6.2303e-04 - val_loss: 6.6673e-04\n",
      "Epoch 279/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.4814e-0 - ETA: 0s - loss: 6.0676e-0 - 0s 31us/step - loss: 6.1768e-04 - val_loss: 6.6667e-04\n",
      "Epoch 280/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.8587e-0 - ETA: 0s - loss: 6.3403e-0 - 0s 34us/step - loss: 6.1990e-04 - val_loss: 6.7461e-04\n",
      "Epoch 281/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.3160e-0 - ETA: 0s - loss: 6.3748e-0 - 0s 34us/step - loss: 6.1895e-04 - val_loss: 6.7097e-04\n",
      "Epoch 282/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.7012e-0 - ETA: 0s - loss: 5.7064e-0 - 0s 35us/step - loss: 6.1856e-04 - val_loss: 6.7100e-04\n",
      "Epoch 283/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.6767e-0 - ETA: 0s - loss: 6.0042e-0 - 0s 36us/step - loss: 6.1857e-04 - val_loss: 6.7352e-04\n",
      "Epoch 284/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.4945e-0 - ETA: 0s - loss: 5.9587e-0 - 0s 38us/step - loss: 6.1857e-04 - val_loss: 6.6848e-04\n",
      "Epoch 285/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.9289e-0 - ETA: 0s - loss: 6.2063e-0 - 0s 33us/step - loss: 6.1765e-04 - val_loss: 6.7051e-04\n",
      "Epoch 286/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.8653e-0 - ETA: 0s - loss: 6.1561e-0 - 0s 35us/step - loss: 6.1754e-04 - val_loss: 6.6513e-04\n",
      "Epoch 287/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.1383e-0 - ETA: 0s - loss: 6.0164e-0 - ETA: 0s - loss: 6.1789e-0 - 0s 49us/step - loss: 6.1603e-04 - val_loss: 6.7293e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 288/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.1198e-0 - ETA: 0s - loss: 6.2273e-0 - 0s 32us/step - loss: 6.2075e-04 - val_loss: 6.6364e-04\n",
      "Epoch 289/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.2401e-0 - ETA: 0s - loss: 6.0977e-0 - 0s 32us/step - loss: 6.1484e-04 - val_loss: 6.6512e-04\n",
      "Epoch 290/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.2434e-0 - ETA: 0s - loss: 6.1335e-0 - 0s 30us/step - loss: 6.1515e-04 - val_loss: 6.6568e-04\n",
      "Epoch 291/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.7124e-0 - ETA: 0s - loss: 6.0240e-0 - 0s 30us/step - loss: 6.1783e-04 - val_loss: 6.6593e-04\n",
      "Epoch 292/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.6566e-0 - ETA: 0s - loss: 6.4297e-0 - 0s 30us/step - loss: 6.2118e-04 - val_loss: 6.6899e-04\n",
      "Epoch 293/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.5650e-0 - ETA: 0s - loss: 6.1978e-0 - 0s 30us/step - loss: 6.1507e-04 - val_loss: 6.6267e-04\n",
      "Epoch 294/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 8.1237e-0 - ETA: 0s - loss: 6.1790e-0 - 0s 30us/step - loss: 6.1405e-04 - val_loss: 6.6820e-04\n",
      "Epoch 295/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.0419e-0 - ETA: 0s - loss: 6.2954e-0 - 0s 32us/step - loss: 6.1624e-04 - val_loss: 6.6462e-04\n",
      "Epoch 296/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.4801e-0 - ETA: 0s - loss: 6.2460e-0 - 0s 30us/step - loss: 6.1332e-04 - val_loss: 6.6651e-04\n",
      "Epoch 297/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.8874e-0 - ETA: 0s - loss: 6.0506e-0 - 0s 32us/step - loss: 6.1625e-04 - val_loss: 6.6563e-04\n",
      "Epoch 298/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.2563e-0 - ETA: 0s - loss: 6.1566e-0 - 0s 34us/step - loss: 6.1829e-04 - val_loss: 6.6614e-04\n",
      "Epoch 299/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.1210e-0 - ETA: 0s - loss: 5.9149e-0 - 0s 38us/step - loss: 6.1461e-04 - val_loss: 6.7289e-04\n",
      "Epoch 300/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.0914e-0 - ETA: 0s - loss: 6.2878e-0 - 0s 33us/step - loss: 6.1902e-04 - val_loss: 6.6764e-04\n",
      "Epoch 301/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 8.0666e-0 - ETA: 0s - loss: 6.1427e-0 - 0s 30us/step - loss: 6.1644e-04 - val_loss: 6.6700e-04\n",
      "Epoch 302/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.1626e-0 - ETA: 0s - loss: 6.3940e-0 - 0s 32us/step - loss: 6.1700e-04 - val_loss: 6.6336e-04\n",
      "Epoch 303/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.2368e-0 - ETA: 0s - loss: 5.9456e-0 - 0s 33us/step - loss: 6.1186e-04 - val_loss: 6.6481e-04\n",
      "Epoch 304/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.6911e-0 - ETA: 0s - loss: 6.1651e-0 - 0s 31us/step - loss: 6.1259e-04 - val_loss: 6.6343e-04\n",
      "Epoch 305/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.0368e-0 - ETA: 0s - loss: 6.3320e-0 - 0s 31us/step - loss: 6.1285e-04 - val_loss: 6.6610e-04\n",
      "Epoch 306/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.9194e-0 - ETA: 0s - loss: 6.2550e-0 - 0s 31us/step - loss: 6.1565e-04 - val_loss: 6.6787e-04\n",
      "Epoch 307/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 3.2043e-0 - ETA: 0s - loss: 6.0350e-0 - 0s 32us/step - loss: 6.1247e-04 - val_loss: 6.6490e-04\n",
      "Epoch 308/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.8753e-0 - ETA: 0s - loss: 6.3289e-0 - 0s 32us/step - loss: 6.1131e-04 - val_loss: 6.6495e-04\n",
      "Epoch 309/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.0191e-0 - ETA: 0s - loss: 5.9332e-0 - 0s 32us/step - loss: 6.1958e-04 - val_loss: 6.6345e-04\n",
      "Epoch 310/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.9648e-0 - ETA: 0s - loss: 6.2120e-0 - 0s 34us/step - loss: 6.1077e-04 - val_loss: 6.6037e-04\n",
      "Epoch 311/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 9.4537e-0 - ETA: 0s - loss: 5.9890e-0 - 0s 30us/step - loss: 6.1310e-04 - val_loss: 6.5962e-04\n",
      "Epoch 312/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.3789e-0 - ETA: 0s - loss: 6.0985e-0 - 0s 31us/step - loss: 6.1217e-04 - val_loss: 6.7099e-04\n",
      "Epoch 313/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.4081e-0 - ETA: 0s - loss: 6.1026e-0 - 0s 31us/step - loss: 6.1787e-04 - val_loss: 6.6331e-04\n",
      "Epoch 314/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.0082e-0 - ETA: 0s - loss: 6.2266e-0 - 0s 33us/step - loss: 6.1086e-04 - val_loss: 6.6197e-04\n",
      "Epoch 315/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.4297e-0 - ETA: 0s - loss: 6.1434e-0 - 0s 31us/step - loss: 6.1464e-04 - val_loss: 6.6263e-04\n",
      "Epoch 316/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.7328e-0 - ETA: 0s - loss: 6.1906e-0 - 0s 31us/step - loss: 6.1060e-04 - val_loss: 6.6338e-04\n",
      "Epoch 317/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 9.5575e-0 - ETA: 0s - loss: 6.1256e-0 - 0s 31us/step - loss: 6.1112e-04 - val_loss: 6.5910e-04\n",
      "Epoch 318/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.0261e-0 - ETA: 0s - loss: 6.2316e-0 - 0s 30us/step - loss: 6.1022e-04 - val_loss: 6.6064e-04\n",
      "Epoch 319/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 8.0553e-0 - ETA: 0s - loss: 6.2213e-0 - 0s 33us/step - loss: 6.1364e-04 - val_loss: 6.7086e-04\n",
      "Epoch 320/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.0265e-0 - ETA: 0s - loss: 6.2145e-0 - 0s 31us/step - loss: 6.1547e-04 - val_loss: 6.6833e-04\n",
      "Epoch 321/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.5301e-0 - ETA: 0s - loss: 6.3398e-0 - 0s 36us/step - loss: 6.1120e-04 - val_loss: 6.6334e-04\n",
      "Epoch 322/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.1250e-0 - ETA: 0s - loss: 6.0294e-0 - 0s 30us/step - loss: 6.1128e-04 - val_loss: 6.6824e-04\n",
      "Epoch 323/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.0373e-0 - ETA: 0s - loss: 6.1343e-0 - 0s 30us/step - loss: 6.1345e-04 - val_loss: 6.7014e-04\n",
      "Epoch 324/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.1306e-0 - ETA: 0s - loss: 6.2181e-0 - 0s 29us/step - loss: 6.1052e-04 - val_loss: 6.5839e-04\n",
      "Epoch 325/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.4782e-0 - ETA: 0s - loss: 5.9572e-0 - 0s 32us/step - loss: 6.0903e-04 - val_loss: 6.5953e-04\n",
      "Epoch 326/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.2329e-0 - ETA: 0s - loss: 6.0584e-0 - 0s 31us/step - loss: 6.0922e-04 - val_loss: 6.5806e-04\n",
      "Epoch 327/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.3977e-0 - ETA: 0s - loss: 6.0734e-0 - 0s 33us/step - loss: 6.0928e-04 - val_loss: 6.5830e-04\n",
      "Epoch 328/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.3930e-0 - ETA: 0s - loss: 6.0752e-0 - 0s 30us/step - loss: 6.0927e-04 - val_loss: 6.6154e-04\n",
      "Epoch 329/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.8025e-0 - ETA: 0s - loss: 6.2223e-0 - 0s 30us/step - loss: 6.1060e-04 - val_loss: 6.6415e-04\n",
      "Epoch 330/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.5500e-0 - ETA: 0s - loss: 6.0736e-0 - 0s 31us/step - loss: 6.1404e-04 - val_loss: 6.7009e-04\n",
      "Epoch 331/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.7595e-0 - ETA: 0s - loss: 6.0737e-0 - 0s 32us/step - loss: 6.1164e-04 - val_loss: 6.6284e-04\n",
      "Epoch 332/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.2574e-0 - ETA: 0s - loss: 6.4087e-0 - 0s 33us/step - loss: 6.0815e-04 - val_loss: 6.5865e-04\n",
      "Epoch 333/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.6414e-0 - ETA: 0s - loss: 6.0595e-0 - 0s 31us/step - loss: 6.1092e-04 - val_loss: 6.6107e-04\n",
      "Epoch 334/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.5356e-0 - ETA: 0s - loss: 6.0395e-0 - 0s 30us/step - loss: 6.0817e-04 - val_loss: 6.6286e-04\n",
      "Epoch 335/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.7088e-0 - ETA: 0s - loss: 6.0079e-0 - 0s 32us/step - loss: 6.0744e-04 - val_loss: 6.6570e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 336/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.5328e-0 - ETA: 0s - loss: 6.0778e-0 - 0s 29us/step - loss: 6.1154e-04 - val_loss: 6.6365e-04\n",
      "Epoch 337/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.7536e-0 - ETA: 0s - loss: 6.2533e-0 - 0s 29us/step - loss: 6.0733e-04 - val_loss: 6.5727e-04\n",
      "Epoch 338/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.7124e-0 - ETA: 0s - loss: 5.8352e-0 - 0s 30us/step - loss: 6.0499e-04 - val_loss: 6.5524e-04\n",
      "Epoch 339/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.4019e-0 - ETA: 0s - loss: 6.0896e-0 - 0s 30us/step - loss: 6.0469e-04 - val_loss: 6.5757e-04\n",
      "Epoch 340/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.8996e-0 - ETA: 0s - loss: 6.0582e-0 - 0s 31us/step - loss: 6.0716e-04 - val_loss: 6.5756e-04\n",
      "Epoch 341/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.2398e-0 - ETA: 0s - loss: 6.1767e-0 - 0s 29us/step - loss: 6.1389e-04 - val_loss: 6.5902e-04\n",
      "Epoch 342/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.4539e-0 - ETA: 0s - loss: 6.1512e-0 - 0s 30us/step - loss: 6.0871e-04 - val_loss: 6.6226e-04\n",
      "Epoch 343/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.7127e-0 - ETA: 0s - loss: 6.0821e-0 - 0s 30us/step - loss: 6.0748e-04 - val_loss: 6.5474e-04\n",
      "Epoch 344/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.1996e-0 - ETA: 0s - loss: 5.9127e-0 - 0s 32us/step - loss: 6.0870e-04 - val_loss: 6.6739e-04\n",
      "Epoch 345/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.1721e-0 - ETA: 0s - loss: 6.0668e-0 - 0s 29us/step - loss: 6.1114e-04 - val_loss: 6.7544e-04\n",
      "Epoch 346/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.8305e-0 - ETA: 0s - loss: 6.0314e-0 - 0s 30us/step - loss: 6.0465e-04 - val_loss: 6.5609e-04\n",
      "Epoch 347/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.1528e-0 - ETA: 0s - loss: 6.2055e-0 - 0s 30us/step - loss: 6.0329e-04 - val_loss: 6.5619e-04\n",
      "Epoch 348/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.2154e-0 - ETA: 0s - loss: 6.0526e-0 - 0s 30us/step - loss: 6.0443e-04 - val_loss: 6.6179e-04\n",
      "Epoch 349/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.1310e-0 - ETA: 0s - loss: 6.1270e-0 - 0s 30us/step - loss: 6.0747e-04 - val_loss: 6.6581e-04\n",
      "Epoch 350/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.6073e-0 - ETA: 0s - loss: 6.0533e-0 - 0s 30us/step - loss: 6.0482e-04 - val_loss: 6.5708e-04\n",
      "Epoch 351/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.1648e-0 - ETA: 0s - loss: 6.0489e-0 - 0s 30us/step - loss: 6.0363e-04 - val_loss: 6.5462e-04\n",
      "Epoch 352/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.5252e-0 - ETA: 0s - loss: 6.0304e-0 - 0s 30us/step - loss: 6.0820e-04 - val_loss: 6.5673e-04\n",
      "Epoch 353/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.7646e-0 - ETA: 0s - loss: 6.0383e-0 - 0s 30us/step - loss: 6.0208e-04 - val_loss: 6.5533e-04\n",
      "Epoch 354/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.9718e-0 - ETA: 0s - loss: 6.1835e-0 - 0s 28us/step - loss: 6.0158e-04 - val_loss: 6.5516e-04\n",
      "Epoch 355/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.5062e-0 - ETA: 0s - loss: 6.0244e-0 - 0s 33us/step - loss: 6.0574e-04 - val_loss: 6.6632e-04\n",
      "Epoch 356/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.4165e-0 - ETA: 0s - loss: 5.9320e-0 - 0s 29us/step - loss: 6.0484e-04 - val_loss: 6.5681e-04\n",
      "Epoch 357/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.6574e-0 - ETA: 0s - loss: 6.0422e-0 - 0s 31us/step - loss: 6.0180e-04 - val_loss: 6.5986e-04\n",
      "Epoch 358/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.5898e-0 - ETA: 0s - loss: 5.8692e-0 - 0s 31us/step - loss: 6.0176e-04 - val_loss: 6.5694e-04\n",
      "Epoch 359/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 9.1420e-0 - ETA: 0s - loss: 6.0602e-0 - 0s 30us/step - loss: 6.0088e-04 - val_loss: 6.5770e-04\n",
      "Epoch 360/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.3230e-0 - ETA: 0s - loss: 5.9014e-0 - 0s 32us/step - loss: 6.0308e-04 - val_loss: 6.5584e-04\n",
      "Epoch 361/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.7731e-0 - ETA: 0s - loss: 6.1608e-0 - 0s 31us/step - loss: 6.0507e-04 - val_loss: 6.5378e-04\n",
      "Epoch 362/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.9645e-0 - ETA: 0s - loss: 6.1656e-0 - 0s 34us/step - loss: 5.9903e-04 - val_loss: 6.5362e-04\n",
      "Epoch 363/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.7224e-0 - ETA: 0s - loss: 6.0298e-0 - 0s 34us/step - loss: 5.9835e-04 - val_loss: 6.5331e-04\n",
      "Epoch 364/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.3270e-0 - ETA: 0s - loss: 5.9174e-0 - 0s 36us/step - loss: 5.9801e-04 - val_loss: 6.5898e-04\n",
      "Epoch 365/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.5667e-0 - ETA: 0s - loss: 5.8670e-0 - 0s 33us/step - loss: 6.0174e-04 - val_loss: 6.5510e-04\n",
      "Epoch 366/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.1896e-0 - ETA: 0s - loss: 6.1033e-0 - 0s 35us/step - loss: 5.9925e-04 - val_loss: 6.6248e-04\n",
      "Epoch 367/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.3585e-0 - ETA: 0s - loss: 5.9171e-0 - 0s 31us/step - loss: 6.0085e-04 - val_loss: 6.5764e-04\n",
      "Epoch 368/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.9000e-0 - ETA: 0s - loss: 6.0010e-0 - 0s 32us/step - loss: 6.0122e-04 - val_loss: 6.5869e-04\n",
      "Epoch 369/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.4569e-0 - ETA: 0s - loss: 6.1070e-0 - 0s 33us/step - loss: 6.0446e-04 - val_loss: 6.5499e-04\n",
      "Epoch 370/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.3325e-0 - ETA: 0s - loss: 6.2554e-0 - 0s 32us/step - loss: 6.0331e-04 - val_loss: 6.6010e-04\n",
      "Epoch 371/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.5466e-0 - ETA: 0s - loss: 6.1507e-0 - 0s 31us/step - loss: 5.9966e-04 - val_loss: 6.5832e-04\n",
      "Epoch 372/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.1052e-0 - ETA: 0s - loss: 6.1512e-0 - 0s 33us/step - loss: 5.9905e-04 - val_loss: 6.4953e-04\n",
      "Epoch 373/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.2050e-0 - ETA: 0s - loss: 6.0487e-0 - 0s 32us/step - loss: 5.9967e-04 - val_loss: 6.5103e-04\n",
      "Epoch 374/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.3898e-0 - ETA: 0s - loss: 5.9905e-0 - 0s 31us/step - loss: 5.9713e-04 - val_loss: 6.5898e-04\n",
      "Epoch 375/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.6792e-0 - ETA: 0s - loss: 6.1208e-0 - 0s 33us/step - loss: 6.0349e-04 - val_loss: 6.5288e-04\n",
      "Epoch 376/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.8193e-0 - ETA: 0s - loss: 6.1852e-0 - 0s 31us/step - loss: 6.0264e-04 - val_loss: 6.5910e-04\n",
      "Epoch 377/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.4959e-0 - ETA: 0s - loss: 6.2052e-0 - 0s 33us/step - loss: 5.9994e-04 - val_loss: 6.5581e-04\n",
      "Epoch 378/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.9907e-0 - ETA: 0s - loss: 6.0593e-0 - 0s 31us/step - loss: 5.9998e-04 - val_loss: 6.5472e-04\n",
      "Epoch 379/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.1451e-0 - ETA: 0s - loss: 5.9787e-0 - 0s 30us/step - loss: 6.0162e-04 - val_loss: 6.5033e-04\n",
      "Epoch 380/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.0832e-0 - ETA: 0s - loss: 6.1331e-0 - 0s 31us/step - loss: 5.9836e-04 - val_loss: 6.5410e-04\n",
      "Epoch 381/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.0340e-0 - ETA: 0s - loss: 5.9968e-0 - 0s 30us/step - loss: 5.9622e-04 - val_loss: 6.4917e-04\n",
      "Epoch 382/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.3711e-0 - ETA: 0s - loss: 6.0056e-0 - 0s 34us/step - loss: 5.9664e-04 - val_loss: 6.4956e-04\n",
      "Epoch 383/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.3047e-0 - ETA: 0s - loss: 5.9460e-0 - 0s 31us/step - loss: 5.9758e-04 - val_loss: 6.4761e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 384/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.3179e-0 - ETA: 0s - loss: 6.2135e-0 - 0s 31us/step - loss: 5.9675e-04 - val_loss: 6.4818e-04\n",
      "Epoch 385/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.9366e-0 - ETA: 0s - loss: 5.7127e-0 - 0s 32us/step - loss: 5.9317e-04 - val_loss: 6.5131e-04\n",
      "Epoch 386/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.0057e-0 - ETA: 0s - loss: 5.7648e-0 - 0s 30us/step - loss: 5.9353e-04 - val_loss: 6.4776e-04\n",
      "Epoch 387/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.2237e-0 - ETA: 0s - loss: 5.9934e-0 - 0s 31us/step - loss: 5.9545e-04 - val_loss: 6.4882e-04\n",
      "Epoch 388/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.6566e-0 - ETA: 0s - loss: 5.9908e-0 - 0s 31us/step - loss: 5.9611e-04 - val_loss: 6.4850e-04\n",
      "Epoch 389/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.1443e-0 - ETA: 0s - loss: 5.9417e-0 - 0s 30us/step - loss: 5.9735e-04 - val_loss: 6.5542e-04\n",
      "Epoch 390/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.1780e-0 - ETA: 0s - loss: 6.1690e-0 - 0s 31us/step - loss: 5.9665e-04 - val_loss: 6.5316e-04\n",
      "Epoch 391/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.8410e-0 - ETA: 0s - loss: 5.9321e-0 - 0s 31us/step - loss: 5.9907e-04 - val_loss: 6.5609e-04\n",
      "Epoch 392/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.9879e-0 - ETA: 0s - loss: 6.0116e-0 - 0s 42us/step - loss: 5.9793e-04 - val_loss: 6.5152e-04\n",
      "Epoch 393/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.3281e-0 - ETA: 0s - loss: 5.9998e-0 - 0s 33us/step - loss: 5.9631e-04 - val_loss: 6.5212e-04\n",
      "Epoch 394/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.1057e-0 - ETA: 0s - loss: 6.0323e-0 - 0s 29us/step - loss: 5.9253e-04 - val_loss: 6.5016e-04\n",
      "Epoch 395/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.8140e-0 - ETA: 0s - loss: 5.9828e-0 - 0s 29us/step - loss: 5.9220e-04 - val_loss: 6.5258e-04\n",
      "Epoch 396/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.5245e-0 - ETA: 0s - loss: 5.9978e-0 - 0s 30us/step - loss: 5.9655e-04 - val_loss: 6.4507e-04\n",
      "Epoch 397/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.6320e-0 - ETA: 0s - loss: 5.9364e-0 - 0s 31us/step - loss: 5.9165e-04 - val_loss: 6.4978e-04\n",
      "Epoch 398/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.3413e-0 - ETA: 0s - loss: 5.8767e-0 - 0s 30us/step - loss: 5.9488e-04 - val_loss: 6.5016e-04\n",
      "Epoch 399/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.0080e-0 - ETA: 0s - loss: 6.0408e-0 - 0s 36us/step - loss: 5.9597e-04 - val_loss: 6.5664e-04\n",
      "Epoch 400/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.7028e-0 - ETA: 0s - loss: 6.0030e-0 - 0s 30us/step - loss: 5.9489e-04 - val_loss: 6.4930e-04\n",
      "Epoch 401/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.0424e-0 - ETA: 0s - loss: 5.7441e-0 - 0s 30us/step - loss: 5.9065e-04 - val_loss: 6.5009e-04\n",
      "Epoch 402/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.6606e-0 - ETA: 0s - loss: 5.9983e-0 - 0s 40us/step - loss: 5.9047e-04 - val_loss: 6.4830e-04\n",
      "Epoch 403/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.0413e-0 - ETA: 0s - loss: 5.8154e-0 - 0s 33us/step - loss: 5.9076e-04 - val_loss: 6.5316e-04\n",
      "Epoch 404/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.7562e-0 - ETA: 0s - loss: 5.9501e-0 - 0s 28us/step - loss: 5.9100e-04 - val_loss: 6.4530e-04\n",
      "Epoch 405/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.2329e-0 - ETA: 0s - loss: 5.9054e-0 - 0s 31us/step - loss: 5.9196e-04 - val_loss: 6.4930e-04\n",
      "Epoch 406/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.8130e-0 - ETA: 0s - loss: 5.7662e-0 - 0s 31us/step - loss: 5.8745e-04 - val_loss: 6.4381e-04\n",
      "Epoch 407/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.7685e-0 - ETA: 0s - loss: 5.9773e-0 - 0s 31us/step - loss: 5.9005e-04 - val_loss: 6.4335e-04\n",
      "Epoch 408/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.5173e-0 - ETA: 0s - loss: 6.0291e-0 - 0s 31us/step - loss: 5.9947e-04 - val_loss: 6.5897e-04\n",
      "Epoch 409/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.5661e-0 - ETA: 0s - loss: 5.9081e-0 - 0s 31us/step - loss: 5.9126e-04 - val_loss: 6.4564e-04\n",
      "Epoch 410/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.0038e-0 - ETA: 0s - loss: 5.9687e-0 - 0s 34us/step - loss: 5.9314e-04 - val_loss: 6.4039e-04\n",
      "Epoch 411/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.6790e-0 - ETA: 0s - loss: 6.0143e-0 - 0s 33us/step - loss: 5.9049e-04 - val_loss: 6.4406e-04\n",
      "Epoch 412/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.8326e-0 - ETA: 0s - loss: 5.9406e-0 - 0s 35us/step - loss: 5.8686e-04 - val_loss: 6.4518e-04\n",
      "Epoch 413/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.0133e-0 - ETA: 0s - loss: 5.8292e-0 - 0s 35us/step - loss: 5.9128e-04 - val_loss: 6.4118e-04\n",
      "Epoch 414/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.7416e-0 - ETA: 0s - loss: 5.7785e-0 - 0s 35us/step - loss: 5.9262e-04 - val_loss: 6.4788e-04\n",
      "Epoch 415/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.3895e-0 - ETA: 0s - loss: 5.6080e-0 - ETA: 0s - loss: 5.6983e-0 - 0s 56us/step - loss: 5.8944e-04 - val_loss: 6.4540e-04\n",
      "Epoch 416/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.6811e-0 - ETA: 0s - loss: 5.7312e-0 - 0s 30us/step - loss: 5.8709e-04 - val_loss: 6.4140e-04\n",
      "Epoch 417/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.2161e-0 - ETA: 0s - loss: 6.0403e-0 - 0s 28us/step - loss: 5.8767e-04 - val_loss: 6.4956e-04\n",
      "Epoch 418/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.4948e-0 - ETA: 0s - loss: 5.7999e-0 - 0s 29us/step - loss: 5.9081e-04 - val_loss: 6.4154e-04\n",
      "Epoch 419/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.5167e-0 - ETA: 0s - loss: 5.9506e-0 - 0s 30us/step - loss: 5.8914e-04 - val_loss: 6.4607e-04\n",
      "Epoch 420/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.0174e-0 - ETA: 0s - loss: 5.8274e-0 - 0s 31us/step - loss: 5.8522e-04 - val_loss: 6.4963e-04\n",
      "Epoch 421/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.9147e-0 - ETA: 0s - loss: 5.8796e-0 - 0s 30us/step - loss: 5.8745e-04 - val_loss: 6.4780e-04\n",
      "Epoch 422/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.2179e-0 - ETA: 0s - loss: 5.9147e-0 - 0s 27us/step - loss: 5.8515e-04 - val_loss: 6.4537e-04\n",
      "Epoch 423/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.7817e-0 - ETA: 0s - loss: 5.8044e-0 - 0s 27us/step - loss: 5.8412e-04 - val_loss: 6.3755e-04\n",
      "Epoch 424/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.7618e-0 - ETA: 0s - loss: 5.8734e-0 - 0s 27us/step - loss: 5.8561e-04 - val_loss: 6.4004e-04\n",
      "Epoch 425/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.1316e-0 - ETA: 0s - loss: 5.8633e-0 - 0s 27us/step - loss: 5.8460e-04 - val_loss: 6.3590e-04\n",
      "Epoch 426/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.1318e-0 - ETA: 0s - loss: 5.7574e-0 - 0s 26us/step - loss: 5.8205e-04 - val_loss: 6.4034e-04\n",
      "Epoch 427/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.3968e-0 - ETA: 0s - loss: 5.8634e-0 - 0s 26us/step - loss: 5.8383e-04 - val_loss: 6.3670e-04\n",
      "Epoch 428/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.2984e-0 - ETA: 0s - loss: 5.8356e-0 - 0s 26us/step - loss: 5.8536e-04 - val_loss: 6.3448e-04\n",
      "Epoch 429/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.2190e-0 - ETA: 0s - loss: 5.9209e-0 - 0s 26us/step - loss: 5.8144e-04 - val_loss: 6.4193e-04\n",
      "Epoch 430/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.8023e-0 - ETA: 0s - loss: 5.7966e-0 - 0s 28us/step - loss: 5.8091e-04 - val_loss: 6.4109e-04\n",
      "Epoch 431/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.3212e-0 - ETA: 0s - loss: 5.7805e-0 - 0s 31us/step - loss: 5.8264e-04 - val_loss: 6.3771e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 432/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.2214e-0 - ETA: 0s - loss: 5.8427e-0 - 0s 31us/step - loss: 5.7951e-04 - val_loss: 6.3568e-04\n",
      "Epoch 433/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.5160e-0 - ETA: 0s - loss: 5.7980e-0 - 0s 29us/step - loss: 5.8015e-04 - val_loss: 6.3950e-04\n",
      "Epoch 434/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.0040e-0 - ETA: 0s - loss: 5.8329e-0 - 0s 26us/step - loss: 5.8023e-04 - val_loss: 6.3696e-04\n",
      "Epoch 435/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.5161e-0 - ETA: 0s - loss: 5.7033e-0 - 0s 27us/step - loss: 5.8198e-04 - val_loss: 6.3588e-04\n",
      "Epoch 436/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.2038e-0 - ETA: 0s - loss: 5.9035e-0 - 0s 27us/step - loss: 5.8190e-04 - val_loss: 6.3839e-04\n",
      "Epoch 437/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.1581e-0 - ETA: 0s - loss: 5.8361e-0 - 0s 29us/step - loss: 5.8044e-04 - val_loss: 6.3332e-04\n",
      "Epoch 438/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.6543e-0 - ETA: 0s - loss: 5.7733e-0 - 0s 28us/step - loss: 5.7958e-04 - val_loss: 6.3285e-04\n",
      "Epoch 439/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.6000e-0 - ETA: 0s - loss: 5.7800e-0 - 0s 28us/step - loss: 5.7934e-04 - val_loss: 6.3129e-04\n",
      "Epoch 440/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.8038e-0 - ETA: 0s - loss: 5.6486e-0 - 0s 32us/step - loss: 5.7782e-04 - val_loss: 6.3231e-04\n",
      "Epoch 441/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.9263e-0 - ETA: 0s - loss: 5.7828e-0 - 0s 31us/step - loss: 5.8081e-04 - val_loss: 6.3077e-04\n",
      "Epoch 442/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.6894e-0 - ETA: 0s - loss: 5.6464e-0 - 0s 29us/step - loss: 5.7797e-04 - val_loss: 6.3014e-04\n",
      "Epoch 443/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.3247e-0 - ETA: 0s - loss: 5.8142e-0 - 0s 26us/step - loss: 5.7523e-04 - val_loss: 6.4064e-04\n",
      "Epoch 444/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.0845e-0 - ETA: 0s - loss: 5.8491e-0 - 0s 25us/step - loss: 5.7802e-04 - val_loss: 6.3203e-04\n",
      "Epoch 445/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.8985e-0 - ETA: 0s - loss: 5.6808e-0 - 0s 26us/step - loss: 5.7471e-04 - val_loss: 6.3577e-04\n",
      "Epoch 446/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.3063e-0 - ETA: 0s - loss: 5.6068e-0 - 0s 28us/step - loss: 5.7837e-04 - val_loss: 6.3678e-04\n",
      "Epoch 447/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.0258e-0 - ETA: 0s - loss: 5.7222e-0 - 0s 27us/step - loss: 5.8367e-04 - val_loss: 6.3094e-04\n",
      "Epoch 448/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.7773e-0 - ETA: 0s - loss: 5.6068e-0 - 0s 26us/step - loss: 5.8130e-04 - val_loss: 6.3769e-04\n",
      "Epoch 449/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.0988e-0 - ETA: 0s - loss: 5.8304e-0 - 0s 28us/step - loss: 5.8148e-04 - val_loss: 6.3988e-04\n",
      "Epoch 450/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.1999e-0 - ETA: 0s - loss: 5.8677e-0 - 0s 28us/step - loss: 5.7908e-04 - val_loss: 6.3098e-04\n",
      "Epoch 451/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.7891e-0 - ETA: 0s - loss: 5.6390e-0 - 0s 28us/step - loss: 5.7486e-04 - val_loss: 6.3182e-04\n",
      "Epoch 452/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.6581e-0 - ETA: 0s - loss: 5.7504e-0 - 0s 28us/step - loss: 5.7587e-04 - val_loss: 6.2790e-04\n",
      "Epoch 453/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.3112e-0 - ETA: 0s - loss: 5.6516e-0 - 0s 28us/step - loss: 5.7183e-04 - val_loss: 6.3286e-04\n",
      "Epoch 454/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.1946e-0 - ETA: 0s - loss: 5.8460e-0 - 0s 28us/step - loss: 5.7576e-04 - val_loss: 6.2864e-04\n",
      "Epoch 455/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.6065e-0 - ETA: 0s - loss: 5.6251e-0 - 0s 30us/step - loss: 5.8123e-04 - val_loss: 6.2761e-04\n",
      "Epoch 456/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.4623e-0 - ETA: 0s - loss: 5.7618e-0 - 0s 31us/step - loss: 5.7601e-04 - val_loss: 6.2325e-04\n",
      "Epoch 457/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.6934e-0 - ETA: 0s - loss: 5.4662e-0 - 0s 30us/step - loss: 5.7455e-04 - val_loss: 6.2463e-04\n",
      "Epoch 458/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.5215e-0 - ETA: 0s - loss: 5.4862e-0 - 0s 32us/step - loss: 5.7257e-04 - val_loss: 6.2507e-04\n",
      "Epoch 459/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.0626e-0 - ETA: 0s - loss: 5.8523e-0 - 0s 30us/step - loss: 5.7168e-04 - val_loss: 6.2240e-04\n",
      "Epoch 460/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.0467e-0 - ETA: 0s - loss: 5.8554e-0 - 0s 30us/step - loss: 5.6851e-04 - val_loss: 6.3468e-04\n",
      "Epoch 461/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.5606e-0 - ETA: 0s - loss: 5.6227e-0 - 0s 30us/step - loss: 5.7495e-04 - val_loss: 6.2794e-04\n",
      "Epoch 462/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.8480e-0 - ETA: 0s - loss: 5.7165e-0 - 0s 28us/step - loss: 5.7131e-04 - val_loss: 6.2528e-04\n",
      "Epoch 463/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.7914e-0 - ETA: 0s - loss: 5.6579e-0 - 0s 27us/step - loss: 5.7269e-04 - val_loss: 6.3075e-04\n",
      "Epoch 464/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.2841e-0 - ETA: 0s - loss: 5.7289e-0 - 0s 27us/step - loss: 5.7087e-04 - val_loss: 6.2670e-04\n",
      "Epoch 465/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.3435e-0 - ETA: 0s - loss: 5.7589e-0 - 0s 28us/step - loss: 5.7702e-04 - val_loss: 6.2955e-04\n",
      "Epoch 466/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.1856e-0 - ETA: 0s - loss: 5.7078e-0 - 0s 27us/step - loss: 5.6966e-04 - val_loss: 6.2267e-04\n",
      "Epoch 467/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.6547e-0 - ETA: 0s - loss: 5.5820e-0 - 0s 28us/step - loss: 5.6884e-04 - val_loss: 6.2151e-04\n",
      "Epoch 468/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.1288e-0 - ETA: 0s - loss: 5.6333e-0 - 0s 30us/step - loss: 5.7002e-04 - val_loss: 6.1797e-04\n",
      "Epoch 469/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.1829e-0 - ETA: 0s - loss: 5.7613e-0 - 0s 29us/step - loss: 5.6758e-04 - val_loss: 6.1954e-04\n",
      "Epoch 470/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.7701e-0 - ETA: 0s - loss: 5.6488e-0 - 0s 30us/step - loss: 5.6598e-04 - val_loss: 6.1970e-04\n",
      "Epoch 471/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.3046e-0 - ETA: 0s - loss: 5.7524e-0 - 0s 33us/step - loss: 5.6859e-04 - val_loss: 6.2322e-04\n",
      "Epoch 472/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.2881e-0 - ETA: 0s - loss: 5.6844e-0 - 0s 27us/step - loss: 5.6759e-04 - val_loss: 6.1972e-04\n",
      "Epoch 473/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.8267e-0 - ETA: 0s - loss: 5.6655e-0 - 0s 27us/step - loss: 5.7004e-04 - val_loss: 6.1794e-04\n",
      "Epoch 474/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.8417e-0 - ETA: 0s - loss: 5.7326e-0 - 0s 27us/step - loss: 5.6975e-04 - val_loss: 6.1576e-04\n",
      "Epoch 475/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.6731e-0 - ETA: 0s - loss: 5.5317e-0 - 0s 26us/step - loss: 5.6794e-04 - val_loss: 6.1544e-04\n",
      "Epoch 476/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.3145e-0 - ETA: 0s - loss: 5.8554e-0 - 0s 27us/step - loss: 5.6828e-04 - val_loss: 6.2046e-04\n",
      "Epoch 477/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.7068e-0 - ETA: 0s - loss: 5.4316e-0 - 0s 29us/step - loss: 5.6951e-04 - val_loss: 6.2156e-04\n",
      "Epoch 478/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.4450e-0 - ETA: 0s - loss: 5.8318e-0 - 0s 30us/step - loss: 5.6545e-04 - val_loss: 6.1495e-04\n",
      "Epoch 479/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.3431e-0 - ETA: 0s - loss: 5.7604e-0 - 0s 30us/step - loss: 5.6580e-04 - val_loss: 6.2018e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 480/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.7384e-0 - ETA: 0s - loss: 5.5209e-0 - 0s 29us/step - loss: 5.6604e-04 - val_loss: 6.1677e-04\n",
      "Epoch 481/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.1916e-0 - ETA: 0s - loss: 5.7754e-0 - 0s 27us/step - loss: 5.6505e-04 - val_loss: 6.1529e-04\n",
      "Epoch 482/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.7553e-0 - ETA: 0s - loss: 5.6438e-0 - 0s 31us/step - loss: 5.6530e-04 - val_loss: 6.2088e-04\n",
      "Epoch 483/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.9782e-0 - ETA: 0s - loss: 5.9429e-0 - 0s 34us/step - loss: 5.7339e-04 - val_loss: 6.2078e-04\n",
      "Epoch 484/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.0180e-0 - ETA: 0s - loss: 5.7838e-0 - 0s 31us/step - loss: 5.6662e-04 - val_loss: 6.1405e-04\n",
      "Epoch 485/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.7396e-0 - ETA: 0s - loss: 5.5173e-0 - 0s 31us/step - loss: 5.6430e-04 - val_loss: 6.1726e-04\n",
      "Epoch 486/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.6608e-0 - ETA: 0s - loss: 5.6875e-0 - 0s 30us/step - loss: 5.6614e-04 - val_loss: 6.1441e-04\n",
      "Epoch 487/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.9726e-0 - ETA: 0s - loss: 5.6988e-0 - 0s 30us/step - loss: 5.6284e-04 - val_loss: 6.1542e-04\n",
      "Epoch 488/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.2366e-0 - ETA: 0s - loss: 5.5783e-0 - 0s 27us/step - loss: 5.6438e-04 - val_loss: 6.1681e-04\n",
      "Epoch 489/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.1927e-0 - ETA: 0s - loss: 5.5682e-0 - 0s 26us/step - loss: 5.6744e-04 - val_loss: 6.1412e-04\n",
      "Epoch 490/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.9417e-0 - ETA: 0s - loss: 5.5020e-0 - 0s 27us/step - loss: 5.6153e-04 - val_loss: 6.1439e-04\n",
      "Epoch 491/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.1348e-0 - ETA: 0s - loss: 5.6143e-0 - 0s 27us/step - loss: 5.6421e-04 - val_loss: 6.1060e-04\n",
      "Epoch 492/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.3132e-0 - ETA: 0s - loss: 5.6426e-0 - 0s 27us/step - loss: 5.5970e-04 - val_loss: 6.1144e-04\n",
      "Epoch 493/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.4899e-0 - ETA: 0s - loss: 5.6076e-0 - 0s 26us/step - loss: 5.6269e-04 - val_loss: 6.1080e-04\n",
      "Epoch 494/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.3356e-0 - ETA: 0s - loss: 5.5935e-0 - 0s 27us/step - loss: 5.6170e-04 - val_loss: 6.3829e-04\n",
      "Epoch 495/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.6659e-0 - ETA: 0s - loss: 5.6211e-0 - 0s 27us/step - loss: 5.6907e-04 - val_loss: 6.1111e-04\n",
      "Epoch 496/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.7303e-0 - ETA: 0s - loss: 5.5541e-0 - 0s 26us/step - loss: 5.5976e-04 - val_loss: 6.1355e-04\n",
      "Epoch 497/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.7625e-0 - ETA: 0s - loss: 5.6459e-0 - 0s 27us/step - loss: 5.6071e-04 - val_loss: 6.0910e-04\n",
      "Epoch 498/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.2913e-0 - ETA: 0s - loss: 5.6480e-0 - 0s 26us/step - loss: 5.6306e-04 - val_loss: 6.1360e-04\n",
      "Epoch 499/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.7760e-0 - ETA: 0s - loss: 5.6031e-0 - 0s 26us/step - loss: 5.6012e-04 - val_loss: 6.0880e-04\n",
      "Epoch 500/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.8619e-0 - ETA: 0s - loss: 5.5224e-0 - 0s 27us/step - loss: 5.5808e-04 - val_loss: 6.1140e-04\n",
      "Epoch 501/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.6196e-0 - ETA: 0s - loss: 5.7716e-0 - 0s 27us/step - loss: 5.5869e-04 - val_loss: 6.1081e-04\n",
      "Epoch 502/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.7327e-0 - ETA: 0s - loss: 5.6383e-0 - 0s 27us/step - loss: 5.6117e-04 - val_loss: 6.1145e-04\n",
      "Epoch 503/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.7212e-0 - ETA: 0s - loss: 5.6322e-0 - 0s 27us/step - loss: 5.6244e-04 - val_loss: 6.1980e-04\n",
      "Epoch 504/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.3301e-0 - ETA: 0s - loss: 5.6807e-0 - 0s 27us/step - loss: 5.6211e-04 - val_loss: 6.1000e-04\n",
      "Epoch 505/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.5868e-0 - ETA: 0s - loss: 5.7592e-0 - 0s 26us/step - loss: 5.5941e-04 - val_loss: 6.1128e-04\n",
      "Epoch 506/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.1304e-0 - ETA: 0s - loss: 5.6140e-0 - 0s 26us/step - loss: 5.5854e-04 - val_loss: 6.3067e-04\n",
      "Epoch 507/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 6.0374e-0 - ETA: 0s - loss: 5.4680e-0 - 0s 27us/step - loss: 5.5909e-04 - val_loss: 6.0779e-04\n",
      "Epoch 508/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 4.5543e-0 - ETA: 0s - loss: 5.5908e-0 - 0s 26us/step - loss: 5.5872e-04 - val_loss: 6.1065e-04\n",
      "Epoch 509/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 7.3452e-0 - ETA: 0s - loss: 5.6115e-0 - 0s 28us/step - loss: 5.6066e-04 - val_loss: 6.0762e-04\n",
      "Epoch 510/1000\n",
      "2640/2640 [==============================] - ETA: 0s - loss: 5.9772e-0 - ETA: 0s - loss: 5.5574e-0 - 0s 26us/step - loss: 5.5898e-04 - val_loss: 6.0706e-04\n",
      "Epoch 00510: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a518e0da58>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = data_raw.drop(columns=['code','amount','preclose','adj'])\n",
    "train_Aug = augFeatures(train)\n",
    "train_norm = normalize(train_Aug)\n",
    "# change the last day and next day \n",
    "X_train, Y_train = buildTrain(train_norm, 5, 5)\n",
    "X_train, Y_train = shuffle(X_train, Y_train)\n",
    "X_train, Y_train, X_val, Y_val = splitData(X_train, Y_train, 0.1)\n",
    "\n",
    "# from 2 dimmension to 3 dimension\n",
    "Y_train = Y_train[:,:,np.newaxis]\n",
    "Y_val = Y_val[:,:,np.newaxis]\n",
    "\n",
    "model = buildManyToManyModel(X_train.shape)\n",
    "callback = EarlyStopping(monitor=\"loss\", patience=10, verbose=1, mode=\"auto\")\n",
    "model.fit(X_train, Y_train, epochs=1000, batch_size=128, validation_data=(X_val, Y_val), callbacks=[callback])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference\n",
    "1. [李弘毅 — 機器學習 RNN](http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2017/Lecture/RNN.pdf)\n",
    "\n",
    "2. [Keras關於LSTM的units參數，還是不理解?](https://www.zhihu.com/question/64470274)\n",
    "\n",
    "3. [Many to one and many to many LSTM examples in Keras](https://stackoverflow.com/questions/43034960/many-to-one-and-many-to-many-lstm-examples-in-keras)\n",
    "\n",
    "4. [Wiki — 長短期記憶](https://zh.wikipedia.org/wiki/%E9%95%B7%E7%9F%AD%E6%9C%9F%E8%A8%98%E6%86%B6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "finance_py_35",
   "language": "python",
   "name": "finance35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
